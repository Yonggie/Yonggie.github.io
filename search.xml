<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>联邦学习框架23.10.19</title>
      <link href="/2023/10/19/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6/"/>
      <url>/2023/10/19/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6/</url>
      
        <content type="html"><![CDATA[<p>2023年10月已经基本上不更新的框架：</p><p>字节 <a href="https://github.com/bytedance/fedlearner">https://github.com/bytedance/fedlearner</a><br>京东 <a href="https://github.com/cyqclark/fedlearn-algo">https://github.com/cyqclark/fedlearn-algo</a><br>百度 <a href="https://github.com/PaddlePaddle/PaddleFL">https://github.com/PaddlePaddle/PaddleFL</a><br>九数 <a href="https://github.com/jd-9n/9nfl">https://github.com/jd-9n/9nfl</a><br>rosetta <a href="https://github.com/LatticeX-Foundation/Rosetta">https://github.com/LatticeX-Foundation/Rosetta</a>  （基于tensorflow）<br><a href="https://github.com/scaleoutsystems/fedn">https://github.com/scaleoutsystems/fedn</a><br>meta <a href="https://github.com/facebookresearch/FLSim">https://github.com/facebookresearch/FLSim</a>  （只是模拟FL）<br>上述框架基本上是死了。</p><p>还在持续更新的框架<br>openfl <a href="https://github.com/securefederatedai/openfl">https://github.com/securefederatedai/openfl</a><br>阿里 <a href="https://github.com/alibaba/FederatedScope">https://github.com/alibaba/FederatedScope</a><br>隐私保护联邦 <a href="https://github.com/APPFL/APPFL">https://github.com/APPFL/APPFL</a><br>边缘计算 华为 <a href="https://github.com/mindspore-ai/mindspore/tree/master">https://github.com/mindspore-ai/mindspore/tree/master</a><br>不仅联邦学习fedml： <a href="https://github.com/FedML-AI/FedML">https://github.com/FedML-AI/FedML</a><br>谷歌TTF  <a href="https://tensorflow.google.cn/federated?hl=zh-cn">https://tensorflow.google.cn/federated?hl=zh-cn</a>   （基于tensorflow）</p><p>算法集合库（应该是几乎不能落地的那种）：<a href="https://github.com/SMILELab-FL/FedLab">https://github.com/SMILELab-FL/FedLab</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> federated learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2023/10/11/%E9%9F%B3%E4%B9%90%E5%9F%BA%E6%9C%AC%E5%8A%9F/"/>
      <url>/2023/10/11/%E9%9F%B3%E4%B9%90%E5%9F%BA%E6%9C%AC%E5%8A%9F/</url>
      
        <content type="html"><![CDATA[<h1 id="大小调关系"><a href="#大小调关系" class="headerlink" title="大小调关系"></a>大小调关系</h1><p>C大调关系调a小调。<br>大调找小调：下行小三度<br>小调找大调，上行小三度</p><h1 id="基本功1"><a href="#基本功1" class="headerlink" title="基本功1"></a>基本功1</h1><p>以单音为最低音，寻找合适和弦。<br>寻找的和弦包括三和弦及其转位和七和弦及其转位。</p><p>例子：</p><ol><li>以C为固定最低音，寻找包含C的三和弦第一转位。</li><li>以C为固定最低音，寻找包含C的七和弦第二转位。</li></ol><p>要点：<br>转位是所有要移动的音的平移，保持原关系。比如第二转位后，变化的音的排列自下而上仍然是1音和3音。<br>三和弦：</p><ol><li>不转位略过</li><li>第一转位 = 26和弦，即最低音与上方音的距离是2度和6度：以C为固定音的二六和弦（或者说以C为最低音的三和弦第一转位），其根音是<strong>下行2度</strong>（与2 6中的6对应，2+6=8）</li><li>第二转位 = 46和弦，即最低音与上方音的距离是4度和6度：以C为固定音的四六和弦（或者说以C为最低音的三和弦第二转位），其根音是<strong>上行4度</strong>（与2 6中的4对应）</li></ol><p>七和弦</p><ol><li>不转位略过</li><li>第一转位，56和弦（从最低音起，音排列不是1357而是1356了，取56为特征），其根音<strong>下行2度</strong>。（与三和弦第一转位同）</li><li>第二转位，34和弦（音列1346），其根音<strong>上行4度</strong>或者<strong>下行5度</strong>都行，都比较远。</li><li>第三转位，2和弦（音列1246），根音<strong>上行2度</strong></li></ol><h1 id="复习"><a href="#复习" class="headerlink" title="复习"></a>复习</h1><p>三和弦根音和高音共5度。</p><p>大三和弦：大三度+小三度<br>小三和弦：小三度+大三度<br>增三和弦：大三度+大三度<br>减三和弦：小三度+小三度</p><p>七和弦根音和高音共7度<br><img src="https://img2023.cnblogs.com/blog/3281074/202310/3281074-20231014001021998-1007328967.webp" alt=""><br>从上往下以此是：<br>大大七和弦<br>大小七和弦<br>小小七和弦<br>减小七和弦<br>减减七和弦<br>小打七和弦<br>增小七和弦<br>增大七和弦<br><img src="https://img2023.cnblogs.com/blog/3281074/202310/3281074-20231014000909525-1485875164.webp" alt=""></p><h1 id="基本功2"><a href="#基本功2" class="headerlink" title="基本功2"></a>基本功2</h1><h2 id="判断音程"><a href="#判断音程" class="headerlink" title="判断音程"></a>判断音程</h2><p>举例：<br>对给定音程判断大小几度。</p><p>做法：<br>只需要记住4度以内的音程即可，高度音程可由低度对应。对应规律a+b=9，大对小，增对减，纯对纯。<br>4度内只需记住 </p><ul><li>31 46 57三对的大三度，其余三度都是小三度；</li><li>47是增四度，其余都是纯四度；</li></ul><h2 id="以固定音寻找上方-下方音"><a href="#以固定音寻找上方-下方音" class="headerlink" title="以固定音寻找上方/下方音"></a>以固定音寻找上方/下方音</h2><p>举例：<br>寻找D的上方三度音；寻找E的下方六度音。</p><p>做法：<br>先确定度数，超过四度反向找。<br>再确定大小纯增减，根据需要升降号。</p><p>参考：<a href="https://www.bilibili.com/video/BV1cT411g7kd">https://www.bilibili.com/video/BV1cT411g7kd</a></p><h1 id="五线谱调号记法-识别"><a href="#五线谱调号记法-识别" class="headerlink" title="五线谱调号记法/识别"></a>五线谱调号记法/识别</h1><h2 id="升号"><a href="#升号" class="headerlink" title="升号"></a>升号</h2><p><strong>最后的升号</strong>的位置的所在音名+1个全音。 比如最后的升号在F线上，F+1=G，则此谱号是1=G的调；最后的升号在B线上，F+1全音=#C，则此谱号是1=#C的调；<br>升号的排列：4 1 5 2 6 3 7，即1-7个升号会在这些位置上标出来。</p><h2 id="降号"><a href="#降号" class="headerlink" title="降号"></a>降号</h2><p>看倒数第二个降号在何处，即此谱是1=降什么调。<br>（只有一个降号的是F调）</p><p>降号的排列7 3 6 2 5 1 4。</p><h1 id="调号性质"><a href="#调号性质" class="headerlink" title="调号性质"></a>调号性质</h1><p>主音和弦是大和弦即此调为大调；主音和弦是小和弦即此调为小调。<br>再引申<br>主音上方三度是大三度，即此调为大调；主音上方三度是大小度，即此调为小调。</p><p>参考：<a href="https://www.bilibili.com/video/BV1Kr4y1G7B7">https://www.bilibili.com/video/BV1Kr4y1G7B7</a></p><h1 id="调式分析"><a href="#调式分析" class="headerlink" title="调式分析"></a>调式分析</h1><p>是什么：判别一段旋律是什么调号、什么调式。比如判别结果是  A和声大调、B旋律小调等。</p><p>常见调式：<br>大调 自然、旋律、和声<br>小调 自然、旋律、和声<br>五声调式 宫商角徵羽五声</p><p>做题时，试题只选取特征旋律，并且尝尝以主音结尾，以便于快速辨别调式。<br>在实际上，判别时需要人自己听声辩主音，和主音上方三度音，以及上下行音，并且要自行抓住特征旋律才能判别出调式。</p><h1 id="中古调"><a href="#中古调" class="headerlink" title="中古调"></a>中古调</h1><p>视角：各种其他调式=特征音/特征和弦元素。</p><h2 id="和声调"><a href="#和声调" class="headerlink" title="和声调"></a>和声调</h2><p>主要是降六级级。多用特征音就可以。另外还有四级小和弦也是特征和弦。</p><p>参考：<a href="https://www.bilibili.com/video/BV1C34y1q7px，这个视频关于流行乐中的和声。">https://www.bilibili.com/video/BV1C34y1q7px，这个视频关于流行乐中的和声。</a></p><h2 id="dorian"><a href="#dorian" class="headerlink" title="dorian"></a>dorian</h2>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2023/07/26/docker%E9%80%82%E7%94%A8%E5%9C%BA%E6%99%AF/"/>
      <url>/2023/07/26/docker%E9%80%82%E7%94%A8%E5%9C%BA%E6%99%AF/</url>
      
        <content type="html"><![CDATA[<p>参考材料：<a href="https://zhuanlan.zhihu.com/p/465877731">https://zhuanlan.zhihu.com/p/465877731</a></p><p>我之前服务的公司是一家深耕于ToB领域的业界招牌，为大量的企业提供了私有化的企业服务软件。而我在该公司的七年时间，经历了公司对于新技术的两次尝试，给我留下了深刻的印象。</p><p>第一次尝试是公司开发了一套完全基于微服务架构的产品，只需要一个启动脚本就可以在一台机器上拉起几十个微服务。但是这款产品在客户现场遇到了无数的兼容性问题，导致研发中心的工程师全部被拖入无穷无尽的用户投诉中。最后这个产品经历了短暂的辉煌后默默下线，变成了我的同事们不再愿意提及的伤痛。戏剧性的是，在这个产品被公司砍掉后的半年，整个行业突然迎来了容器化技术的大爆发，这时候我们很不甘心的意识到，如果容器化技术可以早两年，哪怕早一年出现，我们的这个产品就会有一个完全不一样的结果。而这也是容器化技术第一次进入我的视野，并让我对它有了一种莫名的信任。</p><p>在接下来的一两年里，容器化技术以非常恐怖的速度成长，社区群雄并起，硝烟弥漫，彼时容器化无所不能的言论甚嚣尘上。而容器化技术对我前司的冲击，在某个技术负责人利用业余时间，以非常小的代价把我司一整套ToB产品全部塞进了k8s集群时，达到了顶峰。技术团队以上一个失败的产品作为参考，评估了整套容器环境的兼容性易用性以及技术难度以后，毅然决定将公司产品线全面转型容器化。自此开始，我用我不算太短的职业生涯，把容器化能踩的坑全部踩了一遍……因此，当有人希望我可以聊一聊“容器化的可用场景和不可用场景”这个话题的时候，我感到心中有万千沟壑，不吐不快。</p><p>关于这个话题，我尝试用我之前的经历，给出一些不太适合使用容器化技术的场景，权当讨论：</p><ol><li><p>如果你的应用场景中，程序需要频繁的和一些需要特殊驱动的硬件资源交互或者内核交互，那么这个应用是不适合放在容器中运行的。虽然我们可以把设备pass through到容器，但是如果需要涉及到修改内核参数，或者内核交互，就不行，容器内无法做到这些，需要宿主机修改。</p></li><li><p>容器的优势之一对于资源的精细化管理。如果服务本身需要超大资源（CPU或者内存接近宿主机本身资源大小），那么这个服务更适合放在裸机上运行。因为容器本身的资源调度也是需要消耗性能的，把重资源的服务放在容器中跑并不能提速，对于资源的精细化管理也没有任何帮助。如果这种服务有强烈的容器化需求，建议先拆分成微服务，再分批容器化。</p></li><li><p>对读写和存储有强需求的服务，比如早些时候，数据库是不推荐放在容器中运行的。哪怕docker volumes可以提供持久存储，但是容器本身只是进程级别的运行，一旦容器崩溃，很容易导致数据库非正常关闭进而损坏数据。近两年，关于容器化数据库技术日益完善，但即使我们把数据库放在容器执行，并且保证无状态，但是由于对存储性能要求很高，在具体实现过程中，对容器调度依然有一定要求。当然，作为缓存数据库的Redis因为并不需要数据落地，即使服务崩溃也不会有很大的影响，它就是很适合放在容器中运行的。</p></li><li><p>对于需要调用图形接口的应用，或者Windows平台特定程序，容器化也是不合适的。虽然业界有Nano作为解决方案，但是这个解决方案也并不是完全可靠。</p></li><li><p>如果你的服务需要把安全性作为第一优先级考虑，那么容器化方案通常不是最优解。因为集群中运行的容器某种意义上共享机器的内存和磁盘资源，会有潜在的安全风险。虽然我们可以用不同的命名空间实现绝大部分的隔离，但是并不一定安全。</p></li></ol><p>时至今日，容器化社区依然在高速发展，以上这些不适合的场景在社区中也在慢慢的改进，也许不久的将来甚至当下，就会有更合适的容器化解决方案产生。</p><p>当然，相对不适合容器化的场景，有些业务非常适合容器化，在做好清晰的系统规划和架构设计后，容器化可以极大的降低业务的运维成本，以下给出一些具体的案例：</p><ol><li><p>Web应用服务。容器化的飞速成长和这些年互联网业务的大规模发展有着直接关系。容器服务的快速启动，统一管理，易于监控，弹性伸缩，都是互联网业务的强需求。因此也有无数的互联网公司在积极回馈容器社区，促成的整个生态的良性循环。</p></li><li><p>微服务架构下的容器化使用。就像我前文提到的，微服务的解耦性和小模块服务运行/升级，和容器化方案本身的特性非常契合，因此容器化技术和微服务架构可以说是相互成就彼此的最佳典范。</p></li><li><p>精细化资源分配业务，容器服务由于其特殊的资源调度机制，对于计算资源的分配可以精细到小数点。因此容器化技术很适合让企业告别粗犷的资源分配模式，从成本控制上更好的帮助业务发展。</p></li><li><p>精细化资源分配业务的另一个场景是一次性业务。容器由于其即用即销毁的灵活特征，避免了计算资源的大量浪费。</p></li><li><p>持续集成和持续部署。容器化技术可以基于同一套镜像提供一致化的编译部署环境，并且配合k8s的优秀编排能力，无缝升级模式，快速完成服务的自动化升级，最大程度的简化运维成本，并且保持环境的绝对一致性。</p></li><li><p>强横向扩容业务，比如游戏行业：在联网游戏中，传统模式下游戏公司需要准备大量物理机器，随时热备等待玩家接入。再游戏结束后又要及时释放资源重新启动新的服务器进入热备队列，资源调度和管理非常麻烦。而使用容器化集群，可以非常容易的解决这个问题。</p></li></ol><p>作为一个工程师，我避免使用非黑即白的二元论断来肯定或者否定容器化的使用场景。站在技术发展前沿的我们，对于新兴的容器化技术，既不应该盲目迷信容器化的无所不能，也不应该妖魔化容器技术的局限和不稳定性。没有业务支撑的技术只是屠龙之术，而没有技术支持的业务也不会有长远的发展，因此，让业务和技术相互成就，才是工程师该选择的道路。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>FATE高度定制</title>
      <link href="/2023/05/15/FATE%E9%AB%98%E5%BA%A6%E5%AE%9A%E5%88%B6/"/>
      <url>/2023/05/15/FATE%E9%AB%98%E5%BA%A6%E5%AE%9A%E5%88%B6/</url>
      
        <content type="html"><![CDATA[<h1 id="使用自己的数据集"><a href="#使用自己的数据集" class="headerlink" title="使用自己的数据集"></a>使用自己的数据集</h1><p>homo场景： <a href="https://fate.readthedocs.io/en/latest/tutorial/pipeline/nn_tutorial/Homo-NN-Customize-your-Dataset/">https://fate.readthedocs.io/en/latest/tutorial/pipeline/nn_tutorial/Homo-NN-Customize-your-Dataset/</a><br>hetero场景：<a href="https://fate.readthedocs.io/en/latest/tutorial/pipeline/nn_tutorial/Hetero-NN-Customize-Dataset/">https://fate.readthedocs.io/en/latest/tutorial/pipeline/nn_tutorial/Hetero-NN-Customize-Dataset/</a></p><p>速记：在<code>federatedml/nn/dataset</code>加入自己的数据集.py</p><h1 id="使用自己的模型"><a href="#使用自己的模型" class="headerlink" title="使用自己的模型"></a>使用自己的模型</h1><p>homo场景：<a href="https://fate.readthedocs.io/en/latest/tutorial/pipeline/nn_tutorial/Homo-NN-Customize-Model/">https://fate.readthedocs.io/en/latest/tutorial/pipeline/nn_tutorial/Homo-NN-Customize-Model/</a><br>hetero需要自定义upper layer和bottom layer的模型，所以自带customization。</p><p>速记：在<code>federatedml/nn/model_zoo</code>加入自己的模型.py</p><h1 id="使用自己的loss"><a href="#使用自己的loss" class="headerlink" title="使用自己的loss"></a>使用自己的loss</h1><p><a href="https://fate.readthedocs.io/en/latest/tutorial/pipeline/nn_tutorial/Homo-NN-Customize-Loss/">https://fate.readthedocs.io/en/latest/tutorial/pipeline/nn_tutorial/Homo-NN-Customize-Loss/</a></p><h1 id="自己控制训练过程"><a href="#自己控制训练过程" class="headerlink" title="自己控制训练过程"></a>自己控制训练过程</h1><p>homo场景 basic：<a href="https://fate.readthedocs.io/en/latest/tutorial/pipeline/nn_tutorial/Homo-NN-Quick-Start/#trainerparam-trainer-parameter-and-trainer">https://fate.readthedocs.io/en/latest/tutorial/pipeline/nn_tutorial/Homo-NN-Quick-Start/#trainerparam-trainer-parameter-and-trainer</a><br>homo场景高度定制：<a href="https://fate.readthedocs.io/en/latest/tutorial/pipeline/nn_tutorial/Homo-NN-Customize-Trainer/">https://fate.readthedocs.io/en/latest/tutorial/pipeline/nn_tutorial/Homo-NN-Customize-Trainer/</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2023/05/15/%E7%95%99%E5%AD%A6%E9%9B%86%E5%90%88/"/>
      <url>/2023/05/15/%E7%95%99%E5%AD%A6%E9%9B%86%E5%90%88/</url>
      
        <content type="html"><![CDATA[<p>以下部分来自：<a href="https://zhuanlan.zhihu.com/p/355718522">https://zhuanlan.zhihu.com/p/355718522</a></p><h1 id="瑞典"><a href="#瑞典" class="headerlink" title="瑞典"></a>瑞典</h1><h2 id="KTH"><a href="#KTH" class="headerlink" title="KTH"></a>KTH</h2><p>皇家理工学院（KTH）是位于瑞典首都斯德哥尔摩的顶尖理工大学。KTH成立于1827年，该校为瑞典国内规模最大、历史最悠久的理工院校，专注于工程技术领域的人才培养与科学研究，在欧洲乃至世界都享有卓越的声誉。</p><p>KTH位于瑞典全国第一大城，首都斯德哥尔摩，这里风景秀丽，城市临湖和滨海一带的风光尤为秀美。学院在斯德哥尔摩地区有四个校区，皇家工学院的主校区位于东城的Valhallavägen，此外还有还有Kista、Sodertalje、Flemingsberg、Solna等校区。</p><p>KTH在硕士阶段有超过60个分布在五大学院的英语授课型Programs，其在电气工程、机械、土木、计算机、能源、化工、医学数学、统计、工业工程、船舶、力学、船舶、铁路等专业方向都有很强的学术资源和前沿的实验设备。</p><p>留学费用：硕士两年的学费基本在20-25万人民币，生活费两年大约也要15万上下。</p><p>语言要求：入学要求IELTS 6.5+或TOEFL 90+。</p><h2 id="Chalmers"><a href="#Chalmers" class="headerlink" title="Chalmers"></a>Chalmers</h2><p>查尔姆斯理工大学（Chalmers University of Technology，简称：Chalmers或CTH），位于北欧瑞典-哥德堡，成立于1829年，是一所以工程技术、自然科学和建筑学的教育与研究为主旨的欧洲顶尖理工院校。Chalmers为瑞典唯一的私立理工大学，其为瑞典输送了近四成的工程师与建筑师。在2020年QS世界大学就业竞争力排行榜中，其位列北欧第2位。</p><p>学校所在的哥德堡是瑞典第二大城市，地处瑞典美丽的西海岸，是北欧地区最大也是最重要的港口城市。</p><p>作为瑞典和欧洲的顶尖工科选校，CTH很多项目都颇有吸引力，具体包括建筑和环境、城市设计、自动控制、生物科技、噪音与振动、土木、结构工程、计算机科学、通信工程、嵌入式系统、电气、声学、光学、纳米、物理、供应链、软件工程、材料科学、力学、交通运输、海洋与船舶等方向。</p><p>正常消费的话35-40万RMB可以读完两年硕士（学费两年22万+衣食住行费用15万左右）</p><p>大多数英语授课的项目要求IELTS 6.5+或TOEFL 90+。</p><p>2.申请时间：</p><p>1.15 要提交志愿。</p><p>2.1要提交材料。</p><p>4.9会公布结果。但是在此之前基本就知道自己是不是qualify了。</p><p>3.申请方式及选校：官方申请网站：<a href="https://www.universityadmissions.se/intl/start">https://www.universityadmissions.se/intl/start</a></p><p>大标题：Chalmers不是CTH，CTH不是Chalmers！</p><p>KTH＋Chalmers几乎概括了所有工科专业。今年Chalmers调整了自己的专业配置，把车船专业都放到了Mo这个大类里面。但是还是几乎所有专业都可以申请。而Lund Uppsala则把传媒，金融，法律等都包含的差不多了。想去瑞典的同学，选不到自己的专业几乎是不可能的。</p><p>documents一定要上传完整。每个学校、每个专业都有自己的特殊要求。</p><p>瑞典可以选择的学校包括：<br><img src="https://pic3.zhimg.com/80/v2-0a1e9d3f857aed0f0f2f8cd81d5629fe_720w.webp" alt=""></p><p>瑞典是所有学校加一起交900克朗的申请费就好了，我觉得还是很便宜的</p><h1 id="荷兰"><a href="#荷兰" class="headerlink" title="荷兰"></a>荷兰</h1><p>荷兰的大学主要分为研究型大学（Research University，RU）和应用技术型大学（University of Applied Science，UAS）。其中，RU的课程侧重于学术，而UAS侧重于知识的实践应用，如果你想继续攻读博士的话，那最好选择RU。RU开设学士、硕士和博士阶段的学习，而UAS一般只开设学士和硕士。学制的话，荷兰高校的学士一般3-4年，硕士1-2年（RU的大部分是两年），博士3-5年不等。目前在册的两种类型大学清单如下：<br>研究型大学：<br>!()[<a href="https://pic3.zhimg.com/80/v2-5bd06058341a1f922df96b2a839c5b9e_720w.webp">https://pic3.zhimg.com/80/v2-5bd06058341a1f922df96b2a839c5b9e_720w.webp</a>]<br>应用技术型大学：<br>!()[<a href="https://pic2.zhimg.com/80/v2-66a0cad2058292837f7b67d0ef1adc11_720w.webp">https://pic2.zhimg.com/80/v2-66a0cad2058292837f7b67d0ef1adc11_720w.webp</a>]’</p><p>荷兰的申请分为两个步骤，这里我觉得可以看阿姆斯特丹自由大学VU的视频，介绍的非常清楚：</p><p><a href="https://www.youtube.com/watch?v=mhdkpc5g45k">https://www.youtube.com/watch?v=mhdkpc5g45k</a></p><p>6.荷兰名校</p><p>供老铁们选校参考！不用给我小红花，给我点个赞同就好。</p><p>（1）代尔夫特理工大学(Technische Universiteit Delft)<br>（2）埃因霍芬理工大学(Edinhoven University of Technology, TU/e)<br>（3） 特文特大学（University of Twente， UT）<br> 瓦格宁根大学（Wageningen University &amp; Research）</p><h1 id="挪威和芬兰"><a href="#挪威和芬兰" class="headerlink" title="挪威和芬兰"></a>挪威和芬兰</h1><p>1.选校</p><p>这哥俩放一起是因为，优秀！就特别冷那种优秀！性价比高，而且非常良心。以前都是免学费的，现在很多还是免学费的，不免学费的也有充足的奖学金，是非常好的求学的地方。</p><h1 id="硕士所有花费-年"><a href="#硕士所有花费-年" class="headerlink" title="硕士所有花费/年"></a>硕士所有花费/年</h1><p>香港：15万</p><p>新加坡：25万</p><p>丹麦：15万</p><p>瑞典：2年 30-40万</p><p>荷兰：25万</p><p>挪威：15万（近期又收费了，可能更高）</p><p>欧元区：</p><pre><code>学费免费。包括很多国家法国：30万德国：硕士 2年 40万（加延毕的花费）</code></pre><p>加拿大：</p><pre><code>最贵：温哥华地区，不解释，28～30万RMB超贵：安大略省的多伦多地区，25～28万RMB稍贵：魁北克省的蒙特利尔地区，20～25万RMB正常：阿尔伯塔省等其他地区，15～20万RMB</code></pre><p>英国、美国、澳洲：贵</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>【极简】windows下，vuejs打包，用Nginx部署http服务</title>
      <link href="/2023/04/17/vue%E6%89%93%E5%8C%85/"/>
      <url>/2023/04/17/vue%E6%89%93%E5%8C%85/</url>
      
        <content type="html"><![CDATA[<h1 id="做法"><a href="#做法" class="headerlink" title="做法"></a>做法</h1><p>首先在vue项目下<code>npm run build</code>，在项目目录会出现<code>dist</code>文件夹。</p><p>然后下载Nginx，看其<a href="https://nginx.org/en/docs/windows.html">官网</a>是http服务和反向代理服务的实现程序。解压后可以看到目录结构中有一个html目录，删掉原有的，复制进去<code>dist</code>目录的所有内容（是dist文件里面的内容，不是dist文件夹）。<br><img src="https://img-blog.csdnimg.cn/a706f10af7c14f6489040f03e0b6dff2.png" alt="在这里插入图片描述"><img src="https://img-blog.csdnimg.cn/4f2a5e6667d7409e8bd9f63a7344a27d.png" alt="在这里插入图片描述"></p><p>然后可以双击<code>nginx.exe</code>，在浏览器访问<code>localhost:80</code>就可以了。</p><h1 id="解释"><a href="#解释" class="headerlink" title="解释"></a>解释</h1><p>可以看到Nginx很简单，就是一个服务程序。<br>下载解压后，可以看到<code>conf</code>目录是Nginx的配置文件夹、<code>logs</code>是运行日志，html是网页的根目录，只要放入vue打包好的html就可以了。</p><p>不过大家显然都在Linux下使用http服务了，不过操作都差不多。</p><p>当然除了这种“双击运行”，windows下官网也给了old style命令：<br><img src="https://img-blog.csdnimg.cn/295734f9e0c1415f9c14f290d6f4d6e7.png" alt="在这里插入图片描述"></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>贝叶斯派 先验分布、后验分布、似然分布、似然估计，通俗解释</title>
      <link href="/2023/04/17/%E5%85%88%E9%AA%8C%E5%90%8E%E9%AA%8C/"/>
      <url>/2023/04/17/%E5%85%88%E9%AA%8C%E5%90%8E%E9%AA%8C/</url>
      
        <content type="html"><![CDATA[<p>先验分布、后验分布、似然分布三个应该在一起，似然估计应该分开。</p><p>前三个一起出现在贝叶斯公式，</p><script type="math/tex; mode=display">P(\theta|X)=\frac{P(X|\theta)P(\theta)}{P(X)}</script><p>$\theta$是分布参数，$X$是所见数据，<br>$P(\theta|X)$是后验，即见过数据$X$影响后的分布；<br>$P(\theta)$是先验，没受$X$影响前的分布；<br>$P(X|\theta)$是似然，即在已知分布参数$\theta$下，度量生成某个样本/事件的分布</p><p>===================================<br>而后面的<strong>似然估计</strong>，是参数估计的<strong>思想</strong>，是求参的思想。一般都是极大似然估计，也就是怎样改变参数才能使得分布的结果更加符合所观测的数据（或者说训练数据），而具体的方法有有：</p><ol><li>贝叶斯估计，也就是上述的朴素贝叶斯</li><li>（ 解析解的）极大似然估计，一般求解是：<blockquote><p>求最大似然函数估计值的一般步骤：<br>（1）写出似然函数；<br>（2）对似然函数取对数，并整理；<br>（3）求导数，令导数为0，得到似然方程；<br>（4）解似然方程，得到的参数即为所求；</p></blockquote></li><li>期望最大（EM）方法，即没办法求解析解的参数估计</li><li>以及很多深度学习加持的模型</li></ol>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>docx顺序遍历所有</title>
      <link href="/2023/04/01/docx%E7%9A%84%E9%81%8D%E5%8E%86/"/>
      <url>/2023/04/01/docx%E7%9A%84%E9%81%8D%E5%8E%86/</url>
      
        <content type="html"><![CDATA[<p>table paragraph的基类都是相同的，可以利用这一点。<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">doc.tables[<span class="number">0</span>].__class__.__bases__</span><br><span class="line">(&lt;<span class="keyword">class</span> <span class="string">&#x27;docx.shared.Parented&#x27;</span>&gt;,)</span><br><span class="line"></span><br><span class="line">doc.paragraphs[<span class="number">0</span>].__class__.__bases__</span><br><span class="line">(&lt;<span class="keyword">class</span> <span class="string">&#x27;docx.shared.Parented&#x27;</span>&gt;,)</span><br></pre></td></tr></table></figure></p><p>基类相同，但是子类不同，由此可以区分，所以这样写：<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> docx.shared <span class="keyword">import</span> Parented</span><br><span class="line"><span class="keyword">from</span> docx.table <span class="keyword">import</span> Table</span><br><span class="line"><span class="keyword">from</span> docx.text.paragraph <span class="keyword">import</span> Paragraph</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> element <span class="keyword">in</span> doc.element.body:</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(element,Table):</span><br><span class="line">        <span class="comment">#对表格处理</span></span><br><span class="line">    <span class="keyword">elif</span> <span class="built_in">isinstance</span>(element,Paragraph):</span><br><span class="line">        <span class="comment">#对文字处理</span></span><br></pre></td></tr></table></figure></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>rdkit 使用集合</title>
      <link href="/2023/04/01/rdkit-usage/"/>
      <url>/2023/04/01/rdkit-usage/</url>
      
        <content type="html"><![CDATA[<p>document： <a href="https://rdkit.org/docs/index.html，更新于2022.9">https://rdkit.org/docs/index.html，更新于2022.9</a><br>github：<a href="https://github.com/rdkit/rdkit，依然很活跃">https://github.com/rdkit/rdkit，依然很活跃</a></p><h1 id="examples-of-constructing-molecules"><a href="#examples-of-constructing-molecules" class="headerlink" title="examples of constructing molecules"></a>examples of constructing molecules</h1><p>Chem.MolfFromMol2File, etc, </p><h1 id="mol2-file-explanation"><a href="#mol2-file-explanation" class="headerlink" title="mol2 file explanation"></a>mol2 file explanation</h1><p>refer: <a href="http://sobereva.com/655">http://sobereva.com/655</a><br>官方文档：<a href="http://sobereva.com/attach/655/Tripos_Mol2_File_Format.pdf">http://sobereva.com/attach/655/Tripos_Mol2_File_Format.pdf</a><br><img src="http://sobereva.com/images/655/1.png" alt=""></p><h1 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h1><p> @<TRIPOS>MOLECULE<br>benzaldehyde.pdb<br> 14 14 0 0 0<br>SMALL<br>GASTEIGER</p><p>@<TRIPOS>ATOM<br>      1  C          1.9920    0.4700   -0.0000 C.2     0  UNK0        0.1502<br>      2  C          0.5340    0.2150   -0.0000 C.ar    0  UNK0        0.0142<br>      3  C         -0.3610    1.2920   -0.0000 C.ar    0  UNK0       -0.0515<br>      4  C         -1.7360    1.0600    0.0000 C.ar    0  UNK0       -0.0611<br>      5  C         -2.2160   -0.2520    0.0000 C.ar    0  UNK0       -0.0617<br>      6  C         -1.3250   -1.3310   -0.0000 C.ar    0  UNK0       -0.0611<br>      7  C          0.0460   -1.1010   -0.0000 C.ar    0  UNK0       -0.0515<br>      8  O          2.8450   -0.3960    0.0000 O.2     0  UNK0       -0.2957<br>      9  H          2.2730    1.5470    0.0000 H       0  UNK0        0.1081<br>     10  H          0.0250    2.3090   -0.0000 H       0  UNK0        0.0624<br>     11  H         -2.4300    1.8950    0.0000 H       0  UNK0        0.0618<br>     12  H         -3.2860   -0.4350    0.0000 H       0  UNK0        0.0618<br>     13  H         -1.7060   -2.3480   -0.0000 H       0  UNK0        0.0618<br>     14  H          0.7610   -1.9170   -0.0000 H       0  UNK0        0.0624<br>@<TRIPOS>BOND<br>     1     1     2    1<br>     2     1     8    2<br>     3     1     9    1<br>     4     2     3   ar<br>     5     2     7   ar<br>     6     3     4   ar<br>     7     3    10    1<br>     8     4     5   ar<br>     9     4    11    1<br>    10     5     6   ar<br>    11     5    12    1<br>    12     6     7   ar<br>    13     6    13    1<br>    14     7    14    1</p><p>首先要知道mol2文件里以#作为第一列的是注释行，空行也被完全无视。mol2文件是自由格式，因此空格数目完全随意。</p><p>第一列以@开头的叫做字段，从上面的benzaldehyde.mol2可见，当前文件有@<TRIPOS>MOLECULE、@<TRIPOS>ATOM、@<TRIPOS>BOND三个字段。一般来说这三个字段都是必须出现的，一起提供了描述一个分子最起码的信息。</p><h1 id="2-1-MOLECULE字段"><a href="#2-1-MOLECULE字段" class="headerlink" title="2.1 MOLECULE字段"></a>2.1 MOLECULE字段</h1><p>@<TRIPOS>MOLECULE字段记录了体系的基本信息，包括：<br>第1行：体系的名字。可见OpenBabel把转换出mol2文件的源文件的名字benzaldehyde.pdb当做了当前体系的名字<br>第2行：五个数字分别是体系中的原子数、化学键数、子结构数、特征数、set数。对于单纯记录体系结构信息，只要提供前两者就够了，后三个可以省略。所谓的子结构是指体系中的一个部分，比如每个分子、每个残基、蛋白质的每条链等等都可以在@<TRIPOS>SUBSTRUCTURE字段里定义为一个子结构。所谓的set是指基于体系中的一些原子/键/子结构根据特定规则和需要定义的集合，可以在@<TRIPOS>SET里具体定义。<br>第3行：体系的类型。可以为SMALL（小分子）、BIOPOLYMER、PROTEIN、NUCLEIC_ACID、SACCHARIDE<br>第4行：原子电荷。如果mol2文件没记录原子电荷信息这里就为NO_CHARGES。而在产生当前benzaldehyde.mol2文件的时候OpenBabel自动计算了Gasteiger电荷，因此此处写的是GASTEIGER。还可以为MULLIKEN_CHARGES（Mulliken电荷）、MMFF94_CHARGES（MMFF94力场定义的电荷）等等，不同种类电荷都有固定名字。如果记录的原子电荷是比如Multiwfn算的ADCH、RESP、1.2*CM5等电荷，在mol2格式规范中没有对应的名字，则这里应当写USER_CHARGES。</p><h1 id="2-2-ATOM字段"><a href="#2-2-ATOM字段" class="headerlink" title="2.2 ATOM字段"></a>2.2 ATOM字段</h1><p>@<TRIPOS>ATOM字段每一行定义一个原子的信息，每一列记录的信息为：<br>(1)原子序号（整数）<br>(2)原子名（字符串）<br>(3)X坐标（埃）<br>(4)Y坐标（埃）<br>(5)Z坐标（埃）<br>(6)原子类型（atom type。字符串）<br>(7)原子所属的子结构序号（整数），可省略<br>(8)原子所述的子结构名字（字符串），可省略<br>(9)原子电荷（浮点数），可省略</p><p>原子名部分可以为比如C2、H4等等，完全随意。记录生物分子结构时通常用IUPAC定义的各种残基中的原子名。</p><p>原子类型部分可以记录做分子模拟用的力场中此原子实际对应的原子类型。mol2格式自己也有一套原子类型定义，见前述的Tripos_Mol2_File_Format.pdf文档的末尾，比如<strong>sp3杂化的碳的原子类型是C.3，C.ar代表芳香碳，Any代表任意，Hal泛指卤素，Cl代表氯，Ca代表钙，H代表氢，H.spc特指SPC水模型的氢，LP代表孤对电子（lone pair），Du代表虚原子（dummy）</strong>，等等。</p><p>一定要特别注意，mol2格式虽然定义了一大堆字段，但（居然）没有一个地方是专门用来记录元素的，这在我来看是mol2格式的严重不足！！！mol2记录的原子名和原子类型信息可以与元素名相同也可以不同，不同程序产生的mol2文件的情况各有不同。例如如此例可见，OpenBabel产生的这个mol2文件里原子名恰等于元素名，原子类型是根据mol2格式自己定义的原子类型指认的。而在GaussView产生的mol2文件中，原子名是给元素名后面加了数字（因此不会有重名的原子），而原子类型恰等于元素名。由于情况混乱，所以一个程序在读取mol2文件的时候并没有严格的办法能准确判断元素，只能靠猜。Multiwfn和Sobtop在读取mol2文件时是根据原子类型的字符串判断元素的：如果字符串中没有.，就直接将之当做元素名来判断元素；如果有.，比如是C.3，就把.前面的内容当做元素名判断元素。因此，读者应该知道Multiwfn和Sobtop没判断对元素时该怎么办了，最简单的做法就是手动修改mol2文件以让@<TRIPOS>ATOM字段每一行的第6列对应元素名。</p><p>由于子结构信息在原子电荷前面，因此即便你不想定义原子所属的子结构信息而只想定义原子电荷，也必须随便写上子结构序号和子结构名字来占位，比如此例用0  UNK0来占位。</p><h1 id="2-3-BOND字段"><a href="#2-3-BOND字段" class="headerlink" title="2.3 BOND字段"></a>2.3 BOND字段</h1><p>@<TRIPOS>BOND字段每一行定义一个键的信息，其每一列记录的信息为：<br>(1)键的序号（整数）<br>(2)第1个原子的序号<br>(3)第2个原子的序号<br>(4)键的类型</p><p>键的类型有以下这些<br>• 1 = 单键<br>• 2 = 双键<br>• 3 = 三键<br>• am = 酰胺的N-C键（这种键有一定pi共轭作用，这是为什么mol2格式里特意用am来与单键区分）<br>• ar = 芳香环（aromatic）上的键，以下简称芳香键<br>• du = 虚键<br>• un = 未知/无法判断<br>• nc = 不相连（俩原子不成键就没必要在BOND字段出现，但可以靠nc强调某两个原子间就是没成键）<br>绝大多数程序产生的mol2文件里没有du、un、nc。</p><p>有的程序产生的键的类型名不规矩。比如GaussView对于芳香环上的键（具体来说，是图形窗口里看到一个实线+一个虚线的那种键）用的类型是Ar，但按照mol2规范应当是ar，因此这会导致一些程序无法识别（而Sobtop在读取时已经考虑到了GaussView的这个bug，因此用户不用自己做替换）。GaussView还自行给mol2格式做了扩展，把图形窗口里看到是一个虚键的那种键记录为Wk代表Weak，而这可能导致很多程序无法正常识别和载入。</p><p>不同程序对成键的指认也往往有很大不同。比如甲酰胺，Avogadro产生的它的mol2里把N-C键记录为am，严格符合mol2格式的要求。而GaussView则无法将之记录为am，而是可能记录为单键也可能记录为Ar（取决于当前图形窗口里显示的成键方式）。另外，我之前在《谈谈原子间是否成键的判断问题》（<a href="http://sobereva.com/414）中说过GaussView是根据原子半径和原子间距离判断成键形式的，导致很有可能判断出的成键方式很不“经典”，甚至很违背化学常识，比如可能显示一个碳原子连着一个双键和两个单+虚键。而如果把结构保存成pdb然后再用OpenBabel转成mol2格式，则成键方式就很经典了，因为OpenBabel能够自动让成键方式满足经典Lewis式且同时识别芳香区域。">http://sobereva.com/414）中说过GaussView是根据原子半径和原子间距离判断成键形式的，导致很有可能判断出的成键方式很不“经典”，甚至很违背化学常识，比如可能显示一个碳原子连着一个双键和两个单+虚键。而如果把结构保存成pdb然后再用OpenBabel转成mol2格式，则成键方式就很经典了，因为OpenBabel能够自动让成键方式满足经典Lewis式且同时识别芳香区域。</a></p><p>VMD程序里如果载入了xyz、gro、pdb等不含成键关系信息的文件（虽然pdb有CONECT字段，但VMD不利用），保存出的mol2文件将没有BOND字段，明显是不符合规范的。在同时载入拓扑文件以提供拓扑信息后，保存出的mol2文件才是有BOND字段的（与此同时也有了原子类型、原子电荷、原子所属的残基号和残基名信息）。VMD如果载入的是mol2文件，也可以从中获取成键信息，使得保存出的mol2文件里也有BOND部分。但是VMD并不能记录芳香键，而且它自己也没有像OpenBabel那样根据几何结构和元素就能判断出芳香区域的能力，因此即便载入的是本例的benzaldehyde.mol2，保存出的mol2里苯环上的键也都会简单地记录成单键。</p><p>还值得顺带一提的是有个叫mol的格式，介绍见<a href="https://en.wikipedia.org/wiki/Chemical_table_file。不要将它和mol2混淆，二者格式截然不同。mol也能像mol2一样记录键的存在性及其类型。GaussView产生的mol文件中会把芳香键用4来记录，这正是mol标准格式中的芳香键的类型序号，而OpenBabel在产生mol文件时则会把芳香环描述成单双键交替的形式。">https://en.wikipedia.org/wiki/Chemical_table_file。不要将它和mol2混淆，二者格式截然不同。mol也能像mol2一样记录键的存在性及其类型。GaussView产生的mol文件中会把芳香键用4来记录，这正是mol标准格式中的芳香键的类型序号，而OpenBabel在产生mol文件时则会把芳香环描述成单双键交替的形式。</a> </p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>【极简】vue+flask简单代码</title>
      <link href="/2023/03/29/vue-flask-md/"/>
      <url>/2023/03/29/vue-flask-md/</url>
      
        <content type="html"><![CDATA[<p>看了很多，所谓的“初体验、实战”，里面统统都是先做什么后座什么，连为什么都不解释，每个组件是干什么的为什么要这样做，再不就是后面买课，再不就是事无巨细全部截图，大段大段的图片，篇幅巨长，真的很难把握重点，再不就是操作一些跟这个问题完全无关的下载什么包什么插件之类的，甚至项目都是臃肿as fuck的代码，乱七八糟的，真的糟心。</p><p>这分明是【很简单】的一个【小问题】，何必整那么复杂。</p><p>我默认读者入门vue，也入门flask，但是不了解他们俩的交互怎么写法。</p><h1 id="思想"><a href="#思想" class="headerlink" title="思想"></a>思想</h1><p>我自己是之前写过Flask，每个函数都对应一个路由，去渲染界面，适应这种“路由思想”，但是那种情况只适合小平快的小项目。都用vue了，前后端要真正“分离”了，所以<strong>后端是不管界面跳转和路由的</strong>。</p><p>前端要“包揽路由”。vue有vue-router包，能够管理前端网页页面的各种“跳转”，所以真正跟后端flask交互的，只是一些ajax，所以flask那一端只写与ajax交互的逻辑就可以了，每个请求url不再需要<code>render_template</code>，而是直接返回json data。</p><p>vue如何实现页面的跳转？可以<a href="https://yonggie.blog.csdn.net/article/details/130019754">参考这个demo</a>和<a href="https://router.vuejs.org/zh/guide/">官方文档</a></p><h1 id="交互"><a href="#交互" class="headerlink" title="交互"></a>交互</h1><h2 id="写一写后端"><a href="#写一写后端" class="headerlink" title="写一写后端"></a>写一写后端</h2><p>安装Flask<code>pip install Flask</code>，新建python文件后，直接复制粘贴最简单的flask服务.<br><strong>下面代码的路径要自行修改！</strong><br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> flask <span class="keyword">import</span> Flask, jsonify</span><br><span class="line"></span><br><span class="line">DEBUG = <span class="literal">True</span></span><br><span class="line"> </span><br><span class="line">app = Flask(__name__)</span><br><span class="line"></span><br><span class="line">dir_path_base=<span class="string">&#x27;../web1/&#x27;</span></span><br><span class="line">app = Flask(__name__,</span><br><span class="line">static_folder=dir_path_base+<span class="string">&#x27;dist/assets&#x27;</span>,  </span><br><span class="line">template_folder = dir_path_base+<span class="string">&quot;dist&quot;</span>)  <span class="comment"># 这里其实写不写都无所谓</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@app.route(<span class="params"><span class="string">&#x27;/axios&#x27;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">handle_ajax</span>():</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;good&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    app.run()```</span><br></pre></td></tr></table></figure><br>开启，后端默认在<code>127.0.0.1:5000</code>上服务的</p><h2 id="前端写一写"><a href="#前端写一写" class="headerlink" title="前端写一写"></a>前端写一写</h2><p>vue的ajax使用<code>axios</code>包，相当简单，导入组件后直接<code>axios.post(url,data)</code>就可以了。对axios的使用可以参考<a href="https://www.axios-http.cn/">官方文档</a><br>如果没有安装的话，在前端项目那里安装下<code>npm install axios</code><br>然后随便在一个能前端能看到的页面，根据下方vue代码添加：<br>在什么里面就加什么。下面<code>console.log</code>为了调试用的。<br><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">&lt;script setup&gt;</span><br><span class="line"><span class="keyword">import</span> axios <span class="keyword">from</span> <span class="string">&#x27;axios&#x27;</span></span><br><span class="line">&lt;/script&gt;</span><br><span class="line"></span><br><span class="line"><span class="language-xml"><span class="tag">&lt;<span class="name">script</span>&gt;</span><span class="language-javascript"></span></span></span><br><span class="line"><span class="language-javascript"><span class="language-xml"><span class="keyword">export</span> <span class="keyword">default</span>&#123;</span></span></span><br><span class="line"><span class="language-javascript"><span class="language-xml">  <span class="attr">methods</span>:&#123;</span></span></span><br><span class="line"><span class="language-javascript"><span class="language-xml">    <span class="title function_">test</span>(<span class="params"></span>)&#123;</span></span></span><br><span class="line"><span class="language-javascript"><span class="language-xml">    <span class="keyword">let</span> data=&#123;</span></span></span><br><span class="line"><span class="language-javascript"><span class="language-xml">    <span class="string">&quot;1231&quot;</span>:<span class="string">&quot;123&quot;</span></span></span></span><br><span class="line"><span class="language-javascript"><span class="language-xml">    &#125;</span></span></span><br><span class="line"><span class="language-javascript"><span class="language-xml">      axios.<span class="title function_">post</span>(<span class="string">&#x27;http://127.0.0.1:5000/axios&#x27;</span>,data)</span></span></span><br><span class="line"><span class="language-javascript"><span class="language-xml">      .<span class="title function_">then</span>(<span class="function"><span class="params">res</span>=&gt;</span>&#123;</span></span></span><br><span class="line"><span class="language-javascript"><span class="language-xml">      <span class="comment">//console里面打印后端来的response数据</span></span></span></span><br><span class="line"><span class="language-javascript"><span class="language-xml">        <span class="variable language_">console</span>.<span class="title function_">log</span>(res.<span class="property">data</span>);</span></span></span><br><span class="line"><span class="language-javascript"><span class="language-xml">      &#125;)</span></span></span><br><span class="line"><span class="language-javascript"><span class="language-xml">    &#125;</span></span></span><br><span class="line"><span class="language-javascript"><span class="language-xml">  &#125;</span></span></span><br><span class="line"><span class="language-javascript"><span class="language-xml">&#125;</span></span></span><br><span class="line"><span class="language-javascript"><span class="language-xml"></span></span></span><br><span class="line"><span class="language-javascript"><span class="language-xml"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span></span><br><span class="line"><span class="language-xml"><span class="tag">&lt;<span class="name">template</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    Click <span class="tag">&lt;<span class="name">button</span> @<span class="attr">click</span>=<span class="string">&quot;test()&quot;</span>&gt;</span>here<span class="tag">&lt;/<span class="name">button</span>&gt;</span>   </span></span><br><span class="line"><span class="language-xml"><span class="tag">&lt;/<span class="name">template</span>&gt;</span></span></span><br></pre></td></tr></table></figure><br>然后<code>npm dev run</code>，服务vue的程序会在<code>127.0.0.1:5173</code>服务。</p><h2 id="交互-1"><a href="#交互-1" class="headerlink" title="交互"></a>交互</h2><p>此时在页面点击button，console会提示</p><blockquote><p>“已拦截跨源请求：同源策略禁止读取位于 <a href="http://127.0.0.1:5000/">http://127.0.0.1:5000/</a> 的远程资源。（原因：CORS 请求未能成功）。状态码：(null)。”</p></blockquote><p>因为一般浏览器把跨域请求的localhost的cors禁止了。。这个CORS（Cross-Origin Resource Sharing），网络有详解，先按下不表。因为axios如果不写具体url路径只写相对路径的话，默认是在同一个socket下请求的，我们axios post那里写的是5000端口，但是vue项目本身是在5173端口，这是<strong>跨域</strong>了，所以被浏览器拦下了。</p><p>那要开放这个很简单，可以调整浏览器设置，可以添加插件等。我使用的添加插件，使用了火狐浏览器的<code>CORS Everywhere</code>。chrome应该也有类似的，查一下安装就行。</p><p>插件弄好后，点击按钮，出现<br><img src="https://img-blog.csdnimg.cn/6a13e61549c64dbd997bcae3fbe133d5.png" alt="在这里插入图片描述"><br>浏览器console那边应该也会出现 data ok<br>那这样前端后端就交互成功了。</p><h2 id="后端获取数据"><a href="#后端获取数据" class="headerlink" title="后端获取数据"></a>后端获取数据</h2><p>刚刚我们用axios post了data，里面是一个json。<br>在后端用<code>requests.get_json()[key]</code>可以获取数据。</p><p>然后你拿到post的东西，该怎么处理就怎么处理就行了。</p><h1 id="更多交互"><a href="#更多交互" class="headerlink" title="更多交互"></a>更多交互</h1><p>那更多的交互自然是看axios文档了，axios能干什么，交互就能干什么。</p><blockquote><p>axios.request(config)<br>axios.get(url[, config])<br>axios.delete(url[, config])<br>axios.head(url[, config])<br>axios.options(url[, config])<br>axios.post(url[, data[, config]])<br>axios.put(url[, data[, config]])<br>axios.patch(url[, data[, config]])</p></blockquote>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>SimpleGUI简单例子</title>
      <link href="/2023/03/20/simpleGUI/"/>
      <url>/2023/03/20/simpleGUI/</url>
      
        <content type="html"><![CDATA[<p>官方文档：<a href="https://www.pysimplegui.org/en/latest/#button-click-events">https://www.pysimplegui.org/en/latest/#button-click-events</a></p><p>基本例子：</p><ul><li>It uses a list [] to represent a simple UI.</li><li>Button event is the plain text on the button, can handle these events in the while loop in the final.</li></ul><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> PySimpleGUI <span class="keyword">as</span> sg</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">sg.theme(<span class="string">&#x27;DarkAmber&#x27;</span>)   <span class="comment"># 设置当前主题</span></span><br><span class="line"><span class="comment"># 界面布局，将会按照列表顺序从上往下依次排列，二级列表中，从左往右依此排列</span></span><br><span class="line">layout = [  [sg.Text(<span class="string">&#x27;Federated Client1 &#x27;</span>)],</span><br><span class="line">            [sg.Text(<span class="string">&#x27; &#x27;</span>)],</span><br><span class="line">            [sg.Button(<span class="string">&#x27;upload my data&#x27;</span>)],</span><br><span class="line">            [sg.Button(<span class="string">&#x27;request federated training&#x27;</span>),sg.Text(<span class="string">&#x27;Steps: Data Aggeragation - Federated Training - Model&#x27;</span>)],</span><br><span class="line">            [sg.Button(<span class="string">&#x27;federated model prediction save&#x27;</span>)],</span><br><span class="line">            [sg.Text(<span class="string">&#x27; &#x27;</span>)],</span><br><span class="line">            [sg.Text(<span class="string">&#x27; &#x27;</span>)],</span><br><span class="line">            [sg.Text(<span class="string">&#x27;There are &#x27;</span>),sg.Text(<span class="string">&#x27;Images √ Labels √&#x27;</span>,font=<span class="string">&#x27;bold&#x27;</span>), sg.Text(<span class="string">&#x27; in my data&#x27;</span>),],<span class="comment"># ×</span></span><br><span class="line">            [sg.Text(<span class="string">&#x27; &#x27;</span>)],</span><br><span class="line">            [sg.Text(<span class="string">&#x27;Data Sample:&#x27;</span>),],</span><br><span class="line">            [ sg.Image(<span class="string">&quot;mnist.png&quot;</span>) ]</span><br><span class="line">              ]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创造窗口</span></span><br><span class="line">window = sg.Window(<span class="string">&#x27;MNIST HeteroFedTraining demo&#x27;</span>, layout)</span><br><span class="line"><span class="comment"># 事件循环并获取输入值</span></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    event, values = window.read()</span><br><span class="line">    <span class="keyword">if</span> event==<span class="string">&#x27;upload my data&#x27;</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;data uploaded!&#x27;</span>)</span><br><span class="line">    <span class="keyword">elif</span> event==<span class="string">&#x27;request federated training&#x27;</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="number">2</span>)</span><br><span class="line">        pipeline_img.fit()</span><br><span class="line">    <span class="keyword">elif</span> event==<span class="string">&#x27;federated model prediction save&#x27;</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="number">3</span>)</span><br><span class="line">        <span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">        results=pd.DataFrame(pipeline_img.get_component(<span class="string">&#x27;hetero_nn_0&#x27;</span>).get_output_data())</span><br><span class="line">        results.to_csv(<span class="string">&#x27;hetero_prediction.csv&#x27;</span>)</span><br><span class="line">    <span class="keyword">elif</span> event <span class="keyword">in</span> (<span class="literal">None</span>, <span class="string">&#x27;Cancel&#x27;</span>):   <span class="comment"># 如果用户关闭窗口或点击`Cancel`</span></span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">window.close()</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> python GUI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>联邦学习不止横向和纵向场景</title>
      <link href="/2023/03/20/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%E4%B8%8D%E6%AD%A2%E6%A8%AA%E5%90%91%E5%92%8C%E7%BA%B5%E5%90%91%E5%9C%BA%E6%99%AF/"/>
      <url>/2023/03/20/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%E4%B8%8D%E6%AD%A2%E6%A8%AA%E5%90%91%E5%92%8C%E7%BA%B5%E5%90%91%E5%9C%BA%E6%99%AF/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
        <tags>
            
            <tag> federated learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Vue3.x资源</title>
      <link href="/2023/03/03/vue_resources/"/>
      <url>/2023/03/03/vue_resources/</url>
      
        <content type="html"><![CDATA[<h1 id="个人开源分享"><a href="#个人开源分享" class="headerlink" title="个人开源分享"></a>个人开源分享</h1><ul><li><p><a href="https://meadmin-cn.gitee.io/meadmin-template-doc/">https://meadmin-cn.gitee.io/meadmin-template-doc/</a></p></li><li><p><a href="https://gitee.com/chu1204505056/vue-admin-better">https://gitee.com/chu1204505056/vue-admin-better</a></p></li><li><a href="https://gitee.com/chu1204505056/vue-admin-beautiful">https://gitee.com/chu1204505056/vue-admin-beautiful</a><h2 id="基于element-plus的"><a href="#基于element-plus的" class="headerlink" title="基于element plus的"></a>基于element plus的</h2>前身element ui，但是其是基于vue2的，改vue3后改名为element plus，是饿了么搞的UI</li><li><p><a href="https://gitee.com/kailong110120130/vue-element-plus-admin#%E6%96%87%E6%A1%A3">https://gitee.com/kailong110120130/vue-element-plus-admin#%E6%96%87%E6%A1%A3</a></p></li><li><p><a href="https://gitee.com/newbee-ltd/vue3-admin">https://gitee.com/newbee-ltd/vue3-admin</a></p></li></ul><h1 id="ant-design"><a href="#ant-design" class="headerlink" title="ant design"></a>ant design</h1><p>蚂蚁的。<br><a href="https://store.antdv.com/home">官网本身有store资源</a></p><h1 id="一些vue2的"><a href="#一些vue2的" class="headerlink" title="一些vue2的"></a>一些vue2的</h1><p>Tdesign，腾讯<br>element ui，饿了么<br>vue admin<br>bootstrapvue</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>fateboard的使用</title>
      <link href="/2023/03/01/fateboard%E4%BD%BF%E7%94%A8/"/>
      <url>/2023/03/01/fateboard%E4%BD%BF%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<p>fateboard文档 <a href="https://fate.fedai.org/fateboard/">https://fate.fedai.org/fateboard/</a><br>github Fateboard文档 <a href="https://github.com/FederatedAI/FATE-Board/blob/master/README-CN.md">https://github.com/FederatedAI/FATE-Board/blob/master/README-CN.md</a></p><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>Fateboard是FATE框架的任务看板。<br>在配置FATE时，Fateboard一般是被安装好了的，安装过程查看<a href="">这里</a><br>ATEBoard代码使用spring-boot框架并嵌入在tomcat容器中，默认的网络端口是8080，所以还要稍微懂点java。<br>我自己并没有深究springboot，按我的理解，</p><h1 id="启动fateboard服务"><a href="#启动fateboard服务" class="headerlink" title="启动fateboard服务"></a>启动fateboard服务</h1><p>因为我是standalone安装的FATE，已经直接安装好了，根据文档<a href="https://fate.fedai.org/fateboard/">https://fate.fedai.org/fateboard/</a><br>输入以下可启动Fateboard<br><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java -Dspring.config.location=FATE/fateboard/src/main/resources/application.properties -DFATE_DEPLOY_PREFIX=FATE/logs/ -Dssh_config_file=FATE/fateboard/src/main/resources/ -Xmx2048m -Xms2048m -XX:+PrintGCDetails -XX:+PrintGCDateStamps -Xloggc:gc.log -XX:+HeapDumpOnOutOfMemoryError -jar FATE/fateboard/target/fateboard-1.0.jar &gt;/dev/null 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure><br>一些参数解释<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">-Dspring.config.location path of application.properties of fateboard</span><br><span class="line">-Dssh_config_file path of directory which ssh.properties lies in</span><br><span class="line">-DFATE_DEPLOY_PREFIX path of logs directory which produced by fate_flow</span><br></pre></td></tr></table></figure><br>所以看上去挺长，其实就是输入了一些路径，有点长。<br>拆解一下就是用java启动了springboot的一个服务，<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java -A a -B b</span><br></pre></td></tr></table></figure><br>还有一些杂项，列在下面了，基本上是java的相关的一些参数（我不是很熟悉java，有错请评论指出</p><ul><li>-Xms2048m ：代表最小堆要2048MiB</li><li>-XX:+PrintGCDetails ：开启了jvm的Garage Collector的日志输出</li><li>-XX:+PrintGCDateStamps ：输出GC的时间戳（以日期的形式，如 2013-05-04T21:53:59.2）参考<a href="https://blog.csdn.net/yinni11/article/details/102591431">这个</a></li><li>-Xloggc:gc.log : 输出GC日志到文件</li><li>-XX:+HeapDumpOnOutOfMemoryError : 表示当JVM发生OOM时，自动生成DUMP文件。啥是DUMP文件？</li><li>-jar FATE/fateboard/target/fateboard-1.0.jar </li><li><blockquote><p>/dev/null 2&gt;&amp;1 &amp; ： 这些就是linux运维基本知识了，直接把输出的信息不要了，把stderr错误信息输出给到stdout来，参考<a href="https://blog.csdn.net/ggxiaobai/article/details/53507530">这个</a></p></blockquote></li></ul><p>停止服务<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ps -ef|grep java|grep fateboard-1.1.jar|grep -v grep|awk ‘&#123;print $2&#125;’</span><br><span class="line">kill -9 $&#123;pid&#125;</span><br></pre></td></tr></table></figure></p><h1 id="启动服务后，网页访问"><a href="#启动服务后，网页访问" class="headerlink" title="启动服务后，网页访问"></a>启动服务后，网页访问</h1><p><a href="http://{fateboard-ip}:8080，一般就可以了，如果8080端口没有被别人占了的话。想要直接换端口应该可以在启动的时候往java那命令里加参数就可以。standalone的话一般是``127.0.0.1:8080``">http://{fateboard-ip}:8080，一般就可以了，如果8080端口没有被别人占了的话。想要直接换端口应该可以在启动的时候往java那命令里加参数就可以。standalone的话一般是``127.0.0.1:8080``</a><br>不过搞笑的是访问后竟然还要登录……默认是账密是<code>admin</code>和<code>admin</code>。<br>接下来都是可视化操作了。<br><img src="https://img-blog.csdnimg.cn/3163acf1d2db45df872c8d1c21e7b63f.png" alt="在这里插入图片描述"></p><h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>Fateboard是重要的FATE框架任务看板，即便是开发debug的时候也会常用到这一看版。</p><p>party id should be positive integer<br>‘NoneType’ object has no attribute ‘index’</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>FATE数据上传、读取、训练、保存</title>
      <link href="/2023/02/28/FATE%E6%95%B0%E6%8D%AE%E4%B8%8A%E4%BC%A0%E8%AE%AD%E7%BB%83/"/>
      <url>/2023/02/28/FATE%E6%95%B0%E6%8D%AE%E4%B8%8A%E4%BC%A0%E8%AE%AD%E7%BB%83/</url>
      
        <content type="html"><![CDATA[<p>fate如何安装？本文续<a href="https://yonggie.blog.csdn.net/article/details/129240605">这篇文章</a>。</p><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>fate是一个服务，还原联邦学习，所以分client和host两种身份，一般来说用户都是client，用户想要上传自己的数据，合并他人数据最终获得一个更好的模型，所以要“上传”数据。</p><p>在 FATE 框架中，横向联邦的场景被称为 homo，纵向的被称为 hetero，比如 纵向安全提升树模型就叫做 hetero secure boost。</p><h1 id="上传"><a href="#上传" class="headerlink" title="上传"></a>上传</h1><p>官方文档：<a href="https://fate.readthedocs.io/en/latest/tutorial/pipeline">https://fate.readthedocs.io/en/latest/tutorial/pipeline</a><br><strong>强烈建议对着官方文档看我这个！</strong></p><h2 id="工具"><a href="#工具" class="headerlink" title="工具"></a>工具</h2><p>FATE框架可以使用pipeline工具进行上传。</p><p>先下载fate_client，因为Pipeline是fate_client里的一个工具。<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install fate_client</span><br></pre></td></tr></table></figure><br>根据文档，想要使用pipeline，需要命令行配合使用<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pipeline init --ip=xxx --port=xxx</span><br></pre></td></tr></table></figure><br>先terminal里面对pipeline初始化才能使用pipeline，ip和port要跟FATE启动时的ip和port要对应，如果是standalone，那么ip是127.0.0.1，port一般是9380。</p><p>如果记不清fate的配置了，使用（暂时还没找到，等着补上<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">flow </span><br></pre></td></tr></table></figure><br>如果记不清pipeleine的配置了，使用<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pipeline config show</span><br></pre></td></tr></table></figure><br>查看</p><h2 id="Python开发"><a href="#Python开发" class="headerlink" title="Python开发"></a>Python开发</h2><p>python文件如下代码即可上传csv文件。<br>每一个上传的数据都会有自己的table_name和namespace，fate用这两个字段来命名区分每一个上传的数据。<br>pipeline的initiator绑定此pipeline是谁的，set roles标明此任务是由哪些人们一起做。<br>下面的例子意思是“此pipeline属于guest，他的id号是9999，此任务由id是9999的guest和id是10000的host共同完成”。guest和host参数除了可以是一个数字，也可以是一个list，比如<code>guest=[1,2,3,4]</code>。<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pipeline.backend.pipeline <span class="keyword">import</span> PipeLine</span><br><span class="line"></span><br><span class="line">pipeline = PipeLine() \</span><br><span class="line">        .set_initiator(role=<span class="string">&#x27;guest&#x27;</span>, party_id=<span class="number">9999</span>) \</span><br><span class="line">        .set_roles(guest=<span class="number">9999</span>, host=<span class="number">10000</span>) </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">data_path=<span class="string">&#x27;/root/Downloads/dummy.csv&#x27;</span></span><br><span class="line">table_name=<span class="string">&#x27;dummy&#x27;</span></span><br><span class="line">namespace=<span class="string">&#x27;dummy&#x27;</span></span><br><span class="line">pipeline.add_upload_data(file=data_path,table_name=table_name,namespace=namespace)</span><br><span class="line">pipeline.upload(drop=<span class="number">1</span>) <span class="comment"># drop表示是否覆盖已经上传的table</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><br>成功运行后，terminal会出现类似字样。<img src="https://img-blog.csdnimg.cn/28a3be499b404b18917b31fc7664e3e2.png" alt="在这里插入图片描述"></p><h1 id="从FATE服务中获得数据"><a href="#从FATE服务中获得数据" class="headerlink" title="从FATE服务中获得数据"></a>从FATE服务中获得数据</h1><p>官方文档：<a href="https://fate.readthedocs.io/en/latest/tutorial/pipeline/pipeline_tutorial_hetero_sbt/#install**强烈建议对着官方文档看我这个！**">https://fate.readthedocs.io/en/latest/tutorial/pipeline/pipeline_tutorial_hetero_sbt/#install**强烈建议对着官方文档看我这个！**</a></p><p>文档中的sbt，其实就是Secure Boost Tree，一个决策树模型，因为使用了FATE，所以叫Secure。</p><h2 id="工具-1"><a href="#工具-1" class="headerlink" title="工具"></a>工具</h2><p>FATE中使用<code>Reader</code>类，从FATE框架中获得数据。</p><p>文档中说“load data”，我一开始以为load data是从本地load，汗！文档最好改成load data from FATE service……</p><p>使用<code>Reader</code>类获得数据后，可以使用<code>DataTransform</code>类进行变换。文档和代码有提，可以参考文档。使用<code>Intersection</code>可以获得两份数据的PSI值，根据<a href="https://fate.readthedocs.io/en/latest/zh/federatedml_component/#_2">Component文档</a>，PSI是两份数据中交集程度的指标，FATE当然还提供了更多的函数，文档的代码只是举了一个PSI的例子。</p><h2 id="Python"><a href="#Python" class="headerlink" title="Python"></a>Python</h2><p><code>Reader</code>同样也需要绑定party，但是是要绑定<strong>数据提供方</strong>的身份和id。比如有一份数据A是guest id10提供的，在定义Reader的时候要绑定guest id10才能成功读取。</p><p>在下方的例子中，由于我上面已经用guest 9999上传过一份数据了，所以下面的pipeline我还是用guest 9999下载获得这份数据，没有其他方，所以我的参数不需要加入其他的guest或者host。</p><p>注意：如果一方party在上传数据的时候没有提前和另一方party通知（也就是上传的pipeline时没有约定谁能够使用我的数据），那么即便是有一方得知了此份数据是谁上传的，在reader真正读取的时候会出现错误。<br>这符合联邦学习的“初心”，各方相互不信任，但是有FATE做第三方做担保，没有人的数据会被泄露。<a href="">没有看懂？这篇博客我详细讲了这一点。</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pipeline.component <span class="keyword">import</span> Reader, DataTransform, HeteroSecureBoost, Evaluation</span><br><span class="line"><span class="keyword">from</span> pipeline.interface <span class="keyword">import</span> Data</span><br><span class="line"><span class="comment"># set pipeline operation party ids.</span></span><br><span class="line">pipeline = PipeLine() \</span><br><span class="line">        .set_initiator(role=<span class="string">&#x27;guest&#x27;</span>, party_id=<span class="number">9999</span>) \</span><br><span class="line">        .set_roles(guest=<span class="number">9999</span>)<span class="comment">#, host=10000) 不需要加入其他host</span></span><br><span class="line"></span><br><span class="line">reader_0 = Reader(name=<span class="string">&quot;reader_0&quot;</span>)</span><br><span class="line"><span class="comment"># bind reader operation tables</span></span><br><span class="line">reader_0.get_party_instance(role=<span class="string">&#x27;guest&#x27;</span>, party_id=<span class="number">9999</span>).component_param(</span><br><span class="line">    table=&#123;<span class="string">&quot;name&quot;</span>: <span class="string">&quot;dummy&quot;</span>, <span class="string">&quot;namespace&quot;</span>: <span class="string">&quot;dummy&quot;</span>&#125;)</span><br><span class="line"></span><br><span class="line">data_transform_0 = DataTransform(name=<span class="string">&quot;data_transform_0&quot;</span>)</span><br><span class="line"><span class="comment"># bind transformation operation party</span></span><br><span class="line">data_transform_0.get_party_instance(role=<span class="string">&#x27;guest&#x27;</span>, party_id=<span class="number">9999</span>).component_param(</span><br><span class="line">    with_label=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># state a boost tree and evaluation</span></span><br><span class="line">hetero_secureboost_0 = HeteroSecureBoost(name=<span class="string">&quot;hetero_secureboost_0&quot;</span>,</span><br><span class="line">                                         num_trees=<span class="number">5</span>,</span><br><span class="line">                                         bin_num=<span class="number">16</span>,</span><br><span class="line">                                         task_type=<span class="string">&quot;classification&quot;</span>,</span><br><span class="line">                                         objective_param=&#123;<span class="string">&quot;objective&quot;</span>: <span class="string">&quot;cross_entropy&quot;</span>&#125;,</span><br><span class="line">                                         encrypt_param=&#123;<span class="string">&quot;method&quot;</span>: <span class="string">&quot;paillier&quot;</span>&#125;,</span><br><span class="line">                                         tree_param=&#123;<span class="string">&quot;max_depth&quot;</span>: <span class="number">3</span>&#125;)</span><br><span class="line">evaluation_0 = Evaluation(name=<span class="string">&quot;evaluation_0&quot;</span>, eval_type=<span class="string">&quot;binary&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># add everyone into pipeline and ready for training</span></span><br><span class="line">pipeline.add_component(reader_0)</span><br><span class="line">pipeline.add_component(data_transform_0,data=Data(train_data=reader_0.output.data))</span><br><span class="line">pipeline.add_component(hetero_secureboost_0, data=Data(train_data=data_transform_0.output.data))</span><br><span class="line">pipeline.add_component(evaluation_0, data=Data(data=hetero_secureboost_0.output.data))</span><br><span class="line">pipeline.<span class="built_in">compile</span>()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># training</span></span><br><span class="line">pipeline.fit()</span><br><span class="line"></span><br><span class="line"><span class="comment"># load another dataset via predict_pipeline</span></span><br><span class="line"><span class="comment"># predict_pipeline.predict()</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># save results</span></span><br><span class="line">pipeline.dump(<span class="string">&quot;pipeline_saved.pkl&quot;</span>)</span><br></pre></td></tr></table></figure><ul><li><p>如何查看取出的数据具体是什么？在fate board里面能够看到。<a href="https://yonggie.blog.csdn.net/article/details/129282301">怎么使用fate board？</a>。</p></li><li><p>如果训练失败了，怎么处理？python会提示，可以用fate board看日志。<a href="https://yonggie.blog.csdn.net/article/details/129282301">怎么使用fate board？</a>。</p></li></ul><p>对于一个pipeline可以通过dump把所有信息保存到pkl中。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>FATE联邦学习centos成功部署步骤</title>
      <link href="/2023/02/27/FATE%E5%AE%89%E8%A3%85/"/>
      <url>/2023/02/27/FATE%E5%AE%89%E8%A3%85/</url>
      
        <content type="html"><![CDATA[<p>官方文档：<a href="https://fate.readthedocs.io/en/latest/deploy/standalone-deploy/#1-description。">https://fate.readthedocs.io/en/latest/deploy/standalone-deploy/#1-description。</a></p><p>我用的文档中的Standalone的第二种安装方式，没用docker。</p><h1 id="安装过程"><a href="#安装过程" class="headerlink" title="安装过程"></a>安装过程</h1><p>文档上写着确定版本<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export version=1.7.0</span><br></pre></td></tr></table></figure><br><strong>但是你别真的用1.7.0啊！</strong> ，1.7.0已经是很老的版本了……<br>不然巨坑（我已经亲身经历过了，悲）。<br>首先要查一查现在比较新的版本是什么，目前2023年2月我查到的比较新的是1.10.0。<br>所以我<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export version=1.10.0</span><br></pre></td></tr></table></figure><br>获得安装包，解压<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">wget https://webank-ai-1251170195.cos.ap-guangzhou.myqcloud.com/fate/$&#123;version&#125;/release/standalone_fate_install_$&#123;version&#125;_release.tar.gz;</span><br><span class="line">tar -xzvf standalone_fate_install_$&#123;version&#125;_release.tar.gz</span><br><span class="line"></span><br></pre></td></tr></table></figure><br>然后init一下，安装。<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd standalone_fate_install_$&#123;version&#125;_release;</span><br><span class="line">bash bin/init.sh init</span><br></pre></td></tr></table></figure><br>安装后出现<br><img src="https://img-blog.csdnimg.cn/d60235f9b31c4005b427bc2de59c38d0.png" alt="在这里插入图片描述"></p><p>但是我这里除了这个，还有一些fail的任务，暂时不管他。</p><p>然后检查下<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bash bin/init.sh status</span><br></pre></td></tr></table></figure><br>输出一些config和运行状态，看到确实没有启动。</p><p>然后启动<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bash bin/init.sh start</span><br></pre></td></tr></table></figure><br>会经过许多许多的<code>check process by http port and grpt port</code><br>最后输出的<code>service start successfully</code>。<br><strong>但是他可能在前面先输出failed，后面还会输出success……</strong><br>检查一下吧，我是没有出现fail</p><p>然后执行官方文档的testing<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">flow test toy -gid 10000 -hid 10000</span><br></pre></td></tr></table></figure><br>如果不成功，会返回<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;retcode&quot;: 100,</span><br><span class="line">    &quot;retmsg&quot;: &quot;Connection refused, Please check if the fate flow service is started&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>或者torch出现错误或者其他python包或者库出现错误。<br>我自己是出现了<code>module ‘lib‘ has no attribute ‘OpenSSL_add_all_algorithms‘</code>，是由于cryptography包太新了，降一下级，我参考了<a href="https://blog.csdn.net/m0_67425175/article/details/129124597#:~:text=module%20%E2%80%98lib%E2%80%99%20has%20no%20attribute,%27OpenSSL_add_all_algorithms%E2%80%99%E5%87%BA%E7%8E%B0%E8%BF%99%E4%B8%AA%E9%97%AE%E9%A2%98%E6%98%AF%E5%9B%A0%E4%B8%BA%E4%BD%A0%E8%AF%B4%E5%AE%89%E8%A3%85%E7%9A%84%20cryptography%E5%BA%93%E4%B8%8E%E4%BD%A0%E7%8E%B0%E5%9C%A8%E7%9A%84%E4%BD%BF%E7%94%A8%E7%9A%84%E7%8E%AF%E5%A2%83%E4%B8%8D%E5%85%BC%E5%AE%B9%E5%AF%BC%E8%87%B4%E7%9A%84%EF%BC%8C%E5%8F%AF%E8%83%BD%E6%98%AF%E5%9B%A0%E4%B8%BAcryptography%E7%9A%84%E7%89%88%E6%9C%AC%E5%A4%AA%E9%AB%98%EF%BC%8C%E9%9C%80%E8%A6%81%E8%BF%9B%E8%A1%8C%E9%99%8D%E7%BA%A7%20pip%20install%20cryptography%3D%3D38.0.4">这个</a>，成功运行了<code>toy test</code><br>成功后会返回这样<br><img src="https://img-blog.csdnimg.cn/349d5d871d584305a08c20cf3f257ca1.png" alt="在这里插入图片描述"></p><p>这样FATE框架就启动起来了。</p><p>下一篇再教一下使用Python进行框架的开发。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>windows右键添加“使用vscode打开”</title>
      <link href="/2023/02/22/win%E5%8F%B3%E9%94%AE%E6%B7%BB%E5%8A%A0vscode%E6%89%93%E5%BC%80/"/>
      <url>/2023/02/22/win%E5%8F%B3%E9%94%AE%E6%B7%BB%E5%8A%A0vscode%E6%89%93%E5%BC%80/</url>
      
        <content type="html"><![CDATA[<ol><li>新建xx.reg文件并用文本编辑器打开复制下方文本 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">Windows Registry Editor Version 5.00</span><br><span class="line"></span><br><span class="line">[HKEY_CLASSES_ROOT\*\shell\VSCode]</span><br><span class="line">@=&quot;Open with Code&quot;</span><br><span class="line">&quot;Icon&quot;=&quot;E:\\Microsoft VS Code\\Code.exe&quot;</span><br><span class="line"></span><br><span class="line">[HKEY_CLASSES_ROOT\*\shell\VSCode\command]</span><br><span class="line">@=&quot;\&quot;E:\\Microsoft VS Code\\Code.exe\&quot; \&quot;%1\&quot;&quot;</span><br><span class="line"></span><br><span class="line">Windows Registry Editor Version 5.00</span><br><span class="line"></span><br><span class="line">[HKEY_CLASSES_ROOT\Directory\shell\VSCode]</span><br><span class="line">@=&quot;Open with Code&quot;</span><br><span class="line">&quot;Icon&quot;=&quot;E:\\Microsoft VS Code\\Code.exe&quot;</span><br><span class="line"></span><br><span class="line">[HKEY_CLASSES_ROOT\Directory\shell\VSCode\command]</span><br><span class="line">@=&quot;\&quot;E:\\Microsoft VS Code\\Code.exe\&quot; \&quot;%V\&quot;&quot;</span><br><span class="line"></span><br><span class="line">Windows Registry Editor Version 5.00</span><br><span class="line"></span><br><span class="line">[HKEY_CLASSES_ROOT\Directory\Background\shell\VSCode]</span><br><span class="line">@=&quot;Open with Code&quot;</span><br><span class="line">&quot;Icon&quot;=&quot;E:\\Microsoft VS Code\\Code.exe&quot;</span><br><span class="line"></span><br><span class="line">[HKEY_CLASSES_ROOT\Directory\Background\shell\VSCode\command]</span><br><span class="line">@=&quot;\&quot;E:\\Microsoft VS Code\\Code.exe\&quot; \&quot;%V\&quot;&quot;</span><br><span class="line"></span><br></pre></td></tr></table></figure></li><li>把所有路径替换成你的路径</li><li>保存后双击运行，一路确定即可完成。</li></ol>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>T-SNE PCA UMAP的降维可视化比较</title>
      <link href="/2022/11/03/tsne/"/>
      <url>/2022/11/03/tsne/</url>
      
        <content type="html"><![CDATA[<h1 id="T-SNE"><a href="#T-SNE" class="headerlink" title="T-SNE"></a>T-SNE</h1><p><a href="https://github.com/CannyLab/tsne-cuda">2017年 tsne cuda</a><br><a href="https://gitee.com/chixiangbo/tsne-cuda">gitee tsne cuda</a><br><a href="https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html">sklearn api</a></p><p>根据以上的已经集成好的api，有以下示例：<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.manifold <span class="keyword">import</span> TSNE</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># Random state.</span></span><br><span class="line">RS = <span class="number">20150101</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"> </span><br><span class="line">X = np.random.rand(<span class="number">100</span>,<span class="number">20</span>)</span><br><span class="line">y = np.random.randint(<span class="number">0</span>,<span class="number">10</span>,<span class="number">100</span>)</span><br><span class="line">reduced_x = TSNE(random_state=RS).fit_transform(X)</span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">8</span>, <span class="number">8</span>))</span><br><span class="line"><span class="comment"># ax = plt.subplot(aspect=&#x27;equal&#x27;)</span></span><br><span class="line">sc = plt.scatter(reduced_x[:,<span class="number">0</span>], reduced_x[:,<span class="number">1</span>],c=y)<span class="comment">#,cmap=&#x27;Spectral&#x27;)#, lw=0, s=40)</span></span><br><span class="line"><span class="comment"># plt.xlim(-25, 25)</span></span><br><span class="line"><span class="comment"># plt.ylim(-25, 25)</span></span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line"><span class="comment"># ax.axis(&#x27;tight&#x27;)</span></span><br><span class="line">plt.savefig(<span class="string">&#x27;tsne-generated.png&#x27;</span>, dpi=<span class="number">120</span>)</span><br><span class="line"><span class="comment"># plt.show()</span></span><br></pre></td></tr></table></figure><br>可以得到<br><img src="https://img-blog.csdnimg.cn/7de8eb69467648659e9173f68fcd80e7.png" alt="在这里插入图片描述"></p><h1 id="PCA降维"><a href="#PCA降维" class="headerlink" title="PCA降维"></a>PCA降维</h1><h1 id="UMAP降维"><a href="#UMAP降维" class="headerlink" title="UMAP降维"></a>UMAP降维</h1>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Differences between Knowledge Graph and Graph Neural Network</title>
      <link href="/2022/10/18/difference_KG_GNN/"/>
      <url>/2022/10/18/difference_KG_GNN/</url>
      
        <content type="html"><![CDATA[<p>参考：<a href="https://www.bilibili.com/video/BV16u411z7ss/">https://www.bilibili.com/video/BV16u411z7ss/</a></p><p><img src="https://img-blog.csdnimg.cn/f50527c575e8424eba4273034e99d7eb.png" alt="在这里插入图片描述"></p><h1 id="区别"><a href="#区别" class="headerlink" title="区别"></a>区别</h1><p>对于GNN：</p><ul><li><strong>目的</strong>是representation learning表示学习，目的是对图中每个节点进行向量表示；</li><li><strong>应用场景</strong>是极度稀疏、残缺、规模庞大的图结构数据</li><li><strong>解决方式</strong>是通过更好的表示学习后，进行节点向量的距离度量。</li></ul><p>对于知识图谱：</p><ul><li><strong>目的</strong>是为了<strong>知识推理</strong>，对知识进行建模，而非实体，形成能够迁移的知识表示体系</li><li><strong>场景</strong>是具有可解释性的知识<strong>推理</strong>，多目标优化求解</li><li><strong>解决方式</strong>是取样path或者子图优化。</li></ul><h1 id="联系"><a href="#联系" class="headerlink" title="联系"></a>联系</h1><p>都是图形数据结构，都需要吸取边信息进行推断/预测。</p>]]></content>
      
      
      
        <tags>
            
            <tag> knowledge graph, graph neural network </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Graph learning 数据集</title>
      <link href="/2022/10/18/graph_dataset/"/>
      <url>/2022/10/18/graph_dataset/</url>
      
        <content type="html"><![CDATA[<ul><li><p><a href="https://blog.csdn.net/weixin_39373480/article/details/88742200?spm=1001.2101.3001.6650.1&amp;utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1-88742200-blog-93374216.pc_relevant_3mothn_strategy_recovery&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1-88742200-blog-93374216.pc_relevant_3mothn_strategy_recovery&amp;utm_relevant_index=2#3__58">cora</a>，文献数据集，共2708个节点，每个节点是文献。5429条边</p></li><li><p>(citeseer)[<a href="https://linqs-data.soe.ucsc.edu/public/lbc/citeseer.tgz]，3312个节点，4732条边，可用于分类">https://linqs-data.soe.ucsc.edu/public/lbc/citeseer.tgz]，3312个节点，4732条边，可用于分类</a></p></li><li><p><a href="http://snap.stanford.edu/graphsage/ppi.zip">PPI</a>，蛋白与蛋白数据集，PPI数据集共24张图，每张图对应不同的人体组织，平均每张图有2371个节点，共56944个节点818716条边，每个节点特征长度为50，其中包含位置基因集，基序集和免疫学特征。基因本体基作为label(总共121个)，label不是one-hot编码。</p></li></ul><h1 id="“大”数据集"><a href="#“大”数据集" class="headerlink" title="“大”数据集"></a>“大”数据集</h1><ul><li><a href="https://paperswithcode.com/dataset/reddit">Reddit</a> In total this dataset contains 232,965 posts with an average degree of 492.</li></ul><p>更多可参考 <a href="https://blog.csdn.net/w55100/article/details/115911550">https://blog.csdn.net/w55100/article/details/115911550</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> graph learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>中文近义短语合并实验</title>
      <link href="/2022/10/11/chinese_sentence_sim/"/>
      <url>/2022/10/11/chinese_sentence_sim/</url>
      
        <content type="html"><![CDATA[<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>最近要做一个文本到graph的数据集，里面有不少不同字但同义的小文本段，想简单用文本相似度的方式把他们归到一类里面。</p><h1 id="方式"><a href="#方式" class="headerlink" title="方式"></a>方式</h1><ol><li>直接调用hanlp的sentence sim，帮忙解决</li><li>用中文transformer做sentence embedding，后用距离函数设定阈值解决。</li><li>直接用hugging face的transformer的高级api，也是直接端到端帮忙解决。</li></ol><h1 id="Hanlp"><a href="#Hanlp" class="headerlink" title="Hanlp"></a>Hanlp</h1><p>根据<a href="https://github.com/hankcs/HanLP/blob/doc-zh/plugins/hanlp_demo/hanlp_demo/zh/sts_stl.ipynb">这里</a>，<code>pip install hanlp</code>后，直接<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> hanlp</span><br><span class="line">sts = hanlp.load(hanlp.pretrained.sts.STS_ELECTRA_BASE_ZH)</span><br><span class="line"></span><br><span class="line">sentence_list=make_sentence_list()</span><br><span class="line"><span class="comment"># sentence_list=[</span></span><br><span class="line"><span class="comment">#     (&#x27;看图猜一电影名&#x27;, &#x27;看图猜电影&#x27;),</span></span><br><span class="line"><span class="comment">#     (&#x27;无线路由器怎么无线上网&#x27;, &#x27;无线上网卡和无线路由器怎么用&#x27;),</span></span><br><span class="line"><span class="comment">#     (&#x27;北京到上海的动车票&#x27;, &#x27;上海到北京的动车票&#x27;),</span></span><br><span class="line"><span class="comment"># ]</span></span><br><span class="line">res=sts(sentence_list)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(res)</span><br></pre></td></tr></table></figure></p><p>该说不说，我一共才1k左右个小句子，共$C_{1900}^2$个，inference竟然用时58.48093847433726分钟，太慢了！！</p><h1 id="transformer-end2end"><a href="#transformer-end2end" class="headerlink" title="transformer end2end"></a>transformer end2end</h1><p><code>pip install transformer</code>后，<br>本来想偷懒直接用pipeline的，<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModelForTokenClassification,AutoTokenizer,pipeline</span><br><span class="line">model_id=<span class="string">&#x27;uer/sbert-base-chinese-nli&#x27;</span></span><br><span class="line">scorer=pipeline(<span class="string">&quot;sentence-similarity&quot;</span>,model=model_id)</span><br></pre></td></tr></table></figure><br>但是报错，嘻嘻：<br><code>&quot;Unknown task sentence-similarity, available tasks are [&#39;audio-classification&#39;, &#39;automatic-speech-recognition&#39;, &#39;conversational&#39;, &#39;document-question-answering&#39;, &#39;feature-extraction&#39;, &#39;fill-mask&#39;, &#39;image-classification&#39;, &#39;image-segmentation&#39;, &#39;image-to-text&#39;, &#39;ner&#39;, &#39;object-detection&#39;, &#39;question-answering&#39;, &#39;sentiment-analysis&#39;, &#39;summarization&#39;, &#39;table-question-answering&#39;, &#39;text-classification&#39;, &#39;text-generation&#39;, &#39;text2text-generation&#39;, &#39;token-classification&#39;, &#39;translation&#39;, &#39;visual-question-answering&#39;, &#39;vqa&#39;, &#39;zero-shot-classification&#39;, &#39;zero-shot-image-classification&#39;, &#39;translation_XX_to_YY&#39;]&quot;</code><br>行吧，再偷懒下，看看能不能autotokenizer和automodel解决。</p><p>根据我的<a href="https://yonggie.github.io/2022/10/11/huggingface_transformer_real_quickstart/">这篇教程</a>，找到对应任务后选择model id。<br>找到后，只有两个模型……好家伙，够少的。怎么连个example也没有……<br><img src="https://img-blog.csdnimg.cn/fe47ba1ff779430d98d1f07316698603.png" alt="在这里插入图片描述"><br>随便选择一个，然后看下其他语言的sentence similarity的example：<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> scipy.spatial.distance <span class="keyword">import</span> cosine</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModel, AutoTokenizer</span><br><span class="line"></span><br><span class="line"><span class="comment"># Load the model</span></span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(<span class="string">&quot;johngiorgi/declutr-small&quot;</span>)</span><br><span class="line">model = AutoModel.from_pretrained(<span class="string">&quot;johngiorgi/declutr-small&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Prepare some text to embed</span></span><br><span class="line">text = [</span><br><span class="line">    <span class="string">&quot;A smiling costumed woman is holding an umbrella.&quot;</span>,</span><br><span class="line">    <span class="string">&quot;A happy woman in a fairy costume holds an umbrella.&quot;</span>,</span><br><span class="line">]</span><br><span class="line">inputs = tokenizer(text, padding=<span class="literal">True</span>, truncation=<span class="literal">True</span>, return_tensors=<span class="string">&quot;pt&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Embed the text</span></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    sequence_output = model(**inputs)[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Mean pool the token-level embeddings to get sentence-level embeddings</span></span><br><span class="line">embeddings = torch.<span class="built_in">sum</span>(</span><br><span class="line">    sequence_output * inputs[<span class="string">&quot;attention_mask&quot;</span>].unsqueeze(-<span class="number">1</span>), dim=<span class="number">1</span></span><br><span class="line">) / torch.clamp(torch.<span class="built_in">sum</span>(inputs[<span class="string">&quot;attention_mask&quot;</span>], dim=<span class="number">1</span>, keepdims=<span class="literal">True</span>), <span class="built_in">min</span>=<span class="number">1e-9</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Compute a semantic similarity via the cosine distance</span></span><br><span class="line">semantic_sim = <span class="number">1</span> - cosine(embeddings[<span class="number">0</span>], embeddings[<span class="number">1</span>])</span><br><span class="line"></span><br></pre></td></tr></table></figure></p><p>woc，明面上写的是end2end，结果还是只返回sentence embedding……<br><strong>根本是假的端到端……</strong></p><h1 id="transformer-sentence-embedding"><a href="#transformer-sentence-embedding" class="headerlink" title="transformer sentence embedding"></a>transformer sentence embedding</h1><p>既然是假的端到端，那没必要选择特定task的model了。<br>例子上一部分已经给出来了，很棒！换个model id就行了，看看？<br><img src="https://img-blog.csdnimg.cn/2944ceb230cf4fc6add2c5af96e9d1a2.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/24e6fd72e857482180b8b01da8140d11.png" alt="在这里插入图片描述"><br>有那么点意思哈，把阈值放低些可以看看。<br>到此，处理部分就结束了。<br>接下来就是人工设置阈值，合并了。</p><h1 id="最后附处理的代码"><a href="#最后附处理的代码" class="headerlink" title="最后附处理的代码"></a>最后附处理的代码</h1><h2 id="hanlp"><a href="#hanlp" class="headerlink" title="hanlp"></a>hanlp</h2><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> hanlp</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> itertools <span class="keyword">import</span> combinations</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">make_sentence_list</span>():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;making sentence pair, waiting...&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">    node_storage=pickle.load(<span class="built_in">open</span>(<span class="string">&#x27;path.pkl&#x27;</span>,<span class="string">&#x27;rb&#x27;</span>))</span><br><span class="line">    syndromes=node_storage[<span class="string">&#x27;syndrome&#x27;</span>]</span><br><span class="line">    sentence_list=[]</span><br><span class="line">    <span class="keyword">for</span> sentence_pair <span class="keyword">in</span> combinations(syndromes,<span class="number">2</span>):</span><br><span class="line">        sentence_list.append(sentence_pair)</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;pairs prepared&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> sentence_list</span><br><span class="line"></span><br><span class="line">scorer = hanlp.load(hanlp.pretrained.sts.STS_ELECTRA_BASE_ZH)</span><br><span class="line"></span><br><span class="line">sentence_list=make_sentence_list()</span><br><span class="line"><span class="comment"># sentence_list=[</span></span><br><span class="line"><span class="comment">#     (&#x27;看图猜一电影名&#x27;, &#x27;看图猜电影&#x27;),</span></span><br><span class="line"><span class="comment">#     (&#x27;无线路由器怎么无线上网&#x27;, &#x27;无线上网卡和无线路由器怎么用&#x27;),</span></span><br><span class="line"><span class="comment">#     (&#x27;北京到上海的动车票&#x27;, &#x27;上海到北京的动车票&#x27;),</span></span><br><span class="line"><span class="comment"># ]</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;inferencing...&#x27;</span>)</span><br><span class="line">T1 = time.time()</span><br><span class="line">res=scorer(sentence_list)</span><br><span class="line">T2=time.time()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;inference done, time:<span class="subst">&#123;(T2-T1)/<span class="number">60</span>&#125;</span>min&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(res)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="transformer-sentence-embedding-1"><a href="#transformer-sentence-embedding-1" class="headerlink" title="transformer sentence embedding"></a>transformer sentence embedding</h2><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> itertools <span class="keyword">import</span> combinations</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModel, AutoTokenizer</span><br><span class="line"></span><br><span class="line"><span class="comment"># Load the model</span></span><br><span class="line">model_id=<span class="string">&#x27;bert-base-chinese&#x27;</span></span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(model_id)</span><br><span class="line"></span><br><span class="line">model = AutoModel.from_pretrained(model_id)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Prepare some text to embed</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">make_sentence_list</span>():</span><br><span class="line">    </span><br><span class="line">    node_storage=pickle.load(<span class="built_in">open</span>(<span class="string">&#x27;path.pkl&#x27;</span>,<span class="string">&#x27;rb&#x27;</span>))</span><br><span class="line">    syndromes=<span class="built_in">sorted</span>(<span class="built_in">list</span>(node_storage[<span class="string">&#x27;syndrome&#x27;</span>]))</span><br><span class="line">    <span class="comment"># sentence_list=[]</span></span><br><span class="line">    <span class="comment"># for sentence_pair in combinations(syndromes,2):</span></span><br><span class="line">    <span class="comment">#     sentence_list.append(sentence_pair)</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> syndromes</span><br><span class="line"></span><br><span class="line">text = make_sentence_list()</span><br><span class="line">input_data = tokenizer(text, padding=<span class="literal">True</span>, truncation=<span class="literal">True</span>, return_tensors=<span class="string">&quot;pt&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Embed the text</span></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    sequence_output = model(**input_data)[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Mean pool the token-level embeddings to get sentence-level embeddings</span></span><br><span class="line">embeddings = torch.<span class="built_in">sum</span>(</span><br><span class="line">    sequence_output * input_data[<span class="string">&quot;attention_mask&quot;</span>].unsqueeze(-<span class="number">1</span>), dim=<span class="number">1</span></span><br><span class="line">) / torch.clamp(torch.<span class="built_in">sum</span>(input_data[<span class="string">&quot;attention_mask&quot;</span>], dim=<span class="number">1</span>, keepdims=<span class="literal">True</span>), <span class="built_in">min</span>=<span class="number">1e-9</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Compute a semantic similarity via the cosine distance</span></span><br><span class="line"><span class="comment"># coss = torch.cosine_similarity(embeddings.unsqueeze(1),embeddings.unsqueeze(0),dim=-1)</span></span><br><span class="line">idxs=<span class="built_in">list</span>(<span class="built_in">range</span>(<span class="built_in">len</span>(embeddings)))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;calculating cosine similarity...&#x27;</span>)</span><br><span class="line">T1 = time.time()</span><br><span class="line">sentence_pair2cos=&#123;&#125;</span><br><span class="line"><span class="keyword">for</span> idx1,idx2 <span class="keyword">in</span> combinations(idxs,<span class="number">2</span>):</span><br><span class="line">    cos=torch.cosine_similarity(embeddings[idx1].unsqueeze(<span class="number">0</span>),embeddings[idx2].unsqueeze(<span class="number">0</span>)).item()</span><br><span class="line">    sentence_pair2cos[(text[idx1],text[idx2])]=cos</span><br><span class="line">T2=time.time()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;time:<span class="subst">&#123;T2-T1&#125;</span>sec\n\nSaving similarity as dict&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 太多、太慢。</span></span><br><span class="line"><span class="comment"># with open(&#x27;sentence_sim.dict&#x27;,&#x27;w&#x27;) as f:</span></span><br><span class="line"><span class="comment">#     f.write(&#x27;&#123;\n&#x27;)</span></span><br><span class="line"><span class="comment">#     for k,v in sentence_pair2cos.items():</span></span><br><span class="line"><span class="comment">#         f.write(f&quot;&#123;k&#125;:&#123;v&#125;,\n&quot;)</span></span><br><span class="line"><span class="comment">#     f.write(&#x27;&#125;\n&#x27;)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;sentence_sim_dict.pkl&#x27;</span>,<span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    pickle.dump(sentence_pair2cos,f)</span><br><span class="line"><span class="comment"># print(coss.shape)</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>huggingface real quickstart</title>
      <link href="/2022/10/10/huggingface_transformer_real_quickstart/"/>
      <url>/2022/10/10/huggingface_transformer_real_quickstart/</url>
      
        <content type="html"><![CDATA[<h1 id="tokenizer"><a href="#tokenizer" class="headerlink" title="tokenizer"></a>tokenizer</h1><p>对于sentence要先分词，对每个词做一个word embedding，这个过程叫tokenize，所以用tokenizer这个类。</p><p>那对于中文来说，选用什么tokenizer好？<br>可以见<a href="https://github.com/lonePatient/awesome-pretrained-chinese-nlp-models">https://github.com/lonePatient/awesome-pretrained-chinese-nlp-models</a></p><p>假定我要用<code>nlptown/bert-base-multilingual-uncased-sentiment</code>这个模型，则<code>from_pretrain</code>是很重要的方法，你需要传入一个mode id来确定tokenizer的适配的模型。<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer</span><br><span class="line"></span><br><span class="line">model_name = <span class="string">&quot;nlptown/bert-base-multilingual-uncased-sentiment&quot;</span></span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(model_name)</span><br><span class="line">encoding = tokenizer(<span class="string">&quot;We are very happy to show you the 🤗 Transformers library.&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(encoding)</span><br></pre></td></tr></table></figure></p><p>那如何确定选用的model是否在huggingface的transformer库里面？<a href="https://huggingface.co/docs/transformers/v4.22.2/en/model_doc/auto#transformers.AutoTokenizer.from_pretrained.pretrained_model_name_or_path">可详见这里</a><br><img src="https://img-blog.csdnimg.cn/5e90887ff51a4beabca663284031a105.png" alt="在这里插入图片描述">对于<code>model id</code>，去huggingface documentation，界面中<br><img src="https://img-blog.csdnimg.cn/2ff024ae7128472097b46fcaabaa55a4.png" alt="在这里插入图片描述">就可以找得到<code>model id</code>了，点开后左侧有各种选项，太全了，他真的，我哭死……<br><img src="https://img-blog.csdnimg.cn/d2087de320d645a999c0608353c3470a.png" alt="在这里插入图片描述"></p><h1 id="中文tokenizer"><a href="#中文tokenizer" class="headerlink" title="中文tokenizer"></a>中文tokenizer</h1><p>以<code>ckiplab/albert-base-chinese-ner</code>为例</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AlbertTokenizer,AlbertModel,AutoTokenizer</span><br><span class="line"></span><br><span class="line">tokenizer=AutoTokenizer.from_pretrained(<span class="string">&#x27;ckiplab/albert-base-chinese-ner&#x27;</span>)</span><br><span class="line">encoding=tokenizer.encode(<span class="string">&#x27;我草你是真的牛逼&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(encoding)</span><br><span class="line"><span class="built_in">print</span>(tokenizer.decode(encoding))</span><br></pre></td></tr></table></figure><p>输出<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[101, 2769, 5770, 872, 3221, 4696, 4638, 4281, 6873, 102]</span><br><span class="line">[CLS] 我 草 你 是 真 的 牛 逼 [SEP]</span><br></pre></td></tr></table></figure><br>可以看到每个词对应了vocab里面的一个id，整个句子已经被tokenize了。（中文里不一定一个id都只对应一个字哦，也可能一个id对应2个字。）</p><h1 id="model"><a href="#model" class="headerlink" title="model"></a>model</h1><p>选定任务（从左侧的tag里面）后，类似的，model里面也有<code>AutoModel+任务名称</code>类，也是调用from_pretrain，model id写一样的就可以了。<br>以NER任务为例，左边tag的名字叫TokenClassification，导入<code>AutoModelForTokenClassification</code>，然后<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">sentence=<span class="string">&#x27;舌质淡红，苔薄白，右侧瘀斑较淡。&#x27;</span></span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModelForTokenClassification,AutoTokenizer</span><br><span class="line"></span><br><span class="line">tokenizer=AutoTokenizer.from_pretrained(<span class="string">&#x27;ckiplab/albert-base-chinese-ner&#x27;</span>)</span><br><span class="line">encoding=tokenizer(<span class="string">&#x27;舌质淡红，苔薄白，右侧瘀斑较淡。&#x27;</span>,return_tensors=<span class="string">&#x27;pt&#x27;</span>)</span><br><span class="line"></span><br><span class="line">model = AutoModelForTokenClassification.from_pretrained(<span class="string">&quot;ckiplab/albert-base-chinese-ner&quot;</span>)</span><br><span class="line">results=model(**encoding)</span><br><span class="line"><span class="built_in">print</span>(results)</span><br></pre></td></tr></table></figure></p><p>注意tokenizer和model的<code>from_pretrain</code>的<code>model id</code>参数要对应一致。</p><p>from_pretrained下载的东西在哪里？<br>linux上，在<code>/home/yourname/.cache/torch/transformers</code>，所以如果网络不好，可以手动下载后放入那里。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Chinese Segment Tools in 2022(2022年的中文分词工具)</title>
      <link href="/2022/09/18/chinese_seg/"/>
      <url>/2022/09/18/chinese_seg/</url>
      
        <content type="html"><![CDATA[<h1 id="Hanlp"><a href="#Hanlp" class="headerlink" title="Hanlp"></a><a href="https://github.com/hankcs/HanLP/tree/doc-zh">Hanlp</a></h1><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install hanlp</span><br></pre></td></tr></table></figure><p>后<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> hanlp</span><br><span class="line">hanlp.pretrained.tok.ALL </span><br><span class="line">tok = hanlp.load(hanlp.pretrained.tok.COARSE_ELECTRA_SMALL_ZH)</span><br><span class="line">res=tok(sentence)</span><br><span class="line"><span class="built_in">print</span>(res)</span><br></pre></td></tr></table></figure><br>其实更多文档在(这个链接)[<a href="https://github.com/hankcs/HanLP/tree/doc-zh]里有，这是十分强大的工具，并且已经商业化。">https://github.com/hankcs/HanLP/tree/doc-zh]里有，这是十分强大的工具，并且已经商业化。</a></p><p>python3.8以下使用<a href="https://pypi.org/project/pyhanlp/">这个</a><br>根据官方文档下载，<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">conda install -c conda-forge openjdk python=3.8 jpype1=0.7.0 -y</span><br><span class="line">pip install pyhanlp</span><br></pre></td></tr></table></figure><br>后可以使用<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyhanlp <span class="keyword">import</span> *</span><br><span class="line">sentence=<span class="string">&#x27;我草你是真的牛批&#x27;</span></span><br><span class="line">res=HanLP.segment(sentence)</span><br><span class="line"><span class="built_in">print</span>(res)</span><br></pre></td></tr></table></figure></p><h1 id="paddlepaddle"><a href="#paddlepaddle" class="headerlink" title="paddlepaddle"></a>paddlepaddle</h1><p>paddlepaddle的hub里面有很多中文分词模型，见<a href="https://blog.csdn.net/qq_42067550/article/details/106026629">这里</a></p><p>其实这样看torch社区和tensorflow社区也有很多hub的模型可以使用。</p><h1 id="stanza"><a href="#stanza" class="headerlink" title="stanza"></a>stanza</h1><p>是斯坦福CoreNLP的继承，安装和使用相对麻烦，见<a href="https://blog.csdn.net/shenliang1985/article/details/103509258">这里</a></p><h1 id="fenci"><a href="#fenci" class="headerlink" title="fenci"></a><a href="https://github.com/a358003542/fenci">fenci</a></h1><p>git clone下就可以使用，十分轻量级，是jieba的升级版和继承项目。<br><a href="https://github.com/fxsjy/jieba/issues/957">jieba项目“已死”</a><br>但是fenci只能分词，没有词性标注等功能。</p><h1 id="pkuseg"><a href="#pkuseg" class="headerlink" title="pkuseg"></a><a href="https://github.com/lancopku/pkuseg-python#%E5%90%84%E7%B1%BB%E5%88%86%E8%AF%8D%E5%B7%A5%E5%85%B7%E5%8C%85%E7%9A%84%E6%80%A7%E8%83%BD%E5%AF%B9%E6%AF%94">pkuseg</a></h1><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip3 install pkuseg</span><br></pre></td></tr></table></figure><p>后，出现如下错误（简略）<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">Building wheels for collected packages: pkuseg</span><br><span class="line">  Building wheel for pkuseg (setup.py) ... error</span><br><span class="line">  error: subprocess-exited-with-error</span><br><span class="line">  </span><br><span class="line">  × python setup.py bdist_wheel did not run successfully.</span><br><span class="line">  │ exit code: 1</span><br><span class="line">  ╰─&gt; [208 lines of output]</span><br><span class="line">      /usr/share/anaconda3/envs/yzc_trans/lib/python3.9/site-packages/setuptools/installer.py:27: SetuptoolsDeprecationWarning: setuptools.installer is deprecated. Requirements should be satisfied by a PEP 517 installer.</span><br><span class="line">        warnings.warn(</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  </span><br><span class="line">  note: This error originates from a subprocess, and is likely not a problem with pip.</span><br><span class="line">error: legacy-install-failure</span><br><span class="line"></span><br><span class="line">× Encountered error while trying to install package.</span><br><span class="line">╰─&gt; pkuseg</span><br><span class="line"></span><br><span class="line">note: This is an issue with the package mentioned above, not pip.</span><br><span class="line">hint: See above for output from the failure.</span><br></pre></td></tr></table></figure><br>应该是老了，pip还说这是package自己的问题，不是pip的问题。那应该是是太老了。</p><h1 id="jieba"><a href="#jieba" class="headerlink" title="jieba"></a>jieba</h1><p>不赘述，太多博客了。</p><h1 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h1><p>可从(这里)[<a href="https://github.com/ysc/cws_evaluation]看到另外的分词器">https://github.com/ysc/cws_evaluation]看到另外的分词器</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Cox PH模型</title>
      <link href="/2022/09/18/cox%20PH/"/>
      <url>/2022/09/18/cox%20PH/</url>
      
        <content type="html"><![CDATA[<p>Cox PH model, 全称 proportional hazard regression model.</p><h1 id="模型假设前提"><a href="#模型假设前提" class="headerlink" title="模型假设前提"></a>模型假设前提</h1><p>PH，比例风险变量对生存率的影响不随时间的改变而改变。<br>举个例子，若以$h$预测生存概率，则$h<em>{t_i}(x)$与$h</em>{t_0}(x)$是定值。</p><h1 id="是什么"><a href="#是什么" class="headerlink" title="是什么"></a>是什么</h1><p>假设$h$是生存预测模型函数（输出t时刻生存风险），则</p><script type="math/tex; mode=display">h(t,X)=h_0(t) * exp(\sum w_ix_i)</script><p>表示特征是$X$的人在t时刻的风险。但是$h_0$是不需要求的，$h_0$除过去两边取对数</p><script type="math/tex; mode=display">ln\frac{h(t,X)}{h_0(t)}=\sum w_ix_i</script><p>其实算是一个线性回归。</p><h1 id="求解参数"><a href="#求解参数" class="headerlink" title="求解参数"></a>求解参数</h1><p>极大似然估计<br>参考：<a href="https://zhuanlan.zhihu.com/p/538476448">https://zhuanlan.zhihu.com/p/538476448</a> </p><h1 id="Metrics"><a href="#Metrics" class="headerlink" title="Metrics"></a>Metrics</h1><h2 id="CI"><a href="#CI" class="headerlink" title="CI"></a><a href="https://www.semanticscholar.org/paper/Multivariable-prognostic-models%3A-issues-in-models%2C-Harrell-Lee/a6d33daa0e093a50b1b58e3aa34191c4b5acda92">CI</a></h2><p>C-index有多种，只介绍链接那种。</p><p>concordence index $\in [0.5,1]$, 在非删失的数据中，两两组pair，#表示pair的个数。<script type="math/tex">CI=\frac{\# expectated\ pair}{\# all\ pair}</script>.</p><p>结合删失标志位$\delta$的话，<br>Given observed survival times ti, predicted risk scores ηi, and<br>censoring indicators δi, the concordance index is defined as<br>可以表示为</p><script type="math/tex; mode=display">CI=\frac{\sum_j\sum_i 1_{t_j<t_i}1_{\eta_j>\eta_i}\delta}{\sum_j\sum_i 1_{t_j<t_i}\delta}</script><p>δi is the censoring indicator: δi = 0 if the survival time of the i-th patient was censored, and δi = 1 otherwise. 0 unuseful 1 useful.</p><p>所以可见，其没有使用删失数据。<br>举个例子suppose：<br>| survival time      | predict rish | censored|CI|<br>| —————- | —————- |—————- | —————- |<br>| 4      | 0.9       |0<br>| 5   | 0.8        |1<br>| 6   | 0.7        |0</p><p>则<script type="math/tex">CI=</script></p><h2 id="REA"><a href="#REA" class="headerlink" title="REA"></a><a href="https://dl.acm.org/doi/10.5555/2986459.2986665">REA</a></h2><p>Relative absolute error,</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Dynamic Planning Series</title>
      <link href="/2022/09/02/dp/"/>
      <url>/2022/09/02/dp/</url>
      
        <content type="html"><![CDATA[<h1 id="上台阶-入门"><a href="#上台阶-入门" class="headerlink" title="上台阶(入门)"></a>上台阶(入门)</h1><h1 id="矩阵路径相关"><a href="#矩阵路径相关" class="headerlink" title="矩阵路径相关"></a>矩阵路径相关</h1><h2 id="desc"><a href="#desc" class="headerlink" title="desc"></a>desc</h2><p><a href="https://leetcode.cn/problems/unique-paths/">不同路径</a><br><a href="https://leetcode.cn/problems/unique-paths-ii/">不同路径2</a><br><a href="https://leetcode.cn/problems/minimum-path-sum/">最小路径</a><br><a href="https://leetcode.cn/problems/dungeon-game/">地下城</a></p><h2 id="idea"><a href="#idea" class="headerlink" title="idea"></a>idea</h2><p>题目以矩阵的形式给出来.<br>定义$dp[i][j]$是到达i j的最优解，那么$dp[i][j]$往往只能来自$dp[i-1][j]$和$dp[i][j-1]$，可以根据要求写出状态转移方程。<br><strong>并不都是所有矩阵形式都是这种动态规划。</strong></p><h1 id="序列相关"><a href="#序列相关" class="headerlink" title="序列相关"></a>序列相关</h1><p>提示：并不是所有字符串问题都是用dp求解，能暴力的可以先暴力一下看看。</p><h2 id="最长连续递增序列"><a href="#最长连续递增序列" class="headerlink" title="最长连续递增序列"></a><a href="https://leetcode.cn/problems/longest-continuous-increasing-subsequence/">最长连续递增序列</a></h2><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">findLengthOfLCIS</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="comment"># dp[i]是以nums[i]为最后一个元素的最长长度</span></span><br><span class="line">        dp=[<span class="number">0</span> <span class="keyword">for</span> n <span class="keyword">in</span> nums]</span><br><span class="line">        dp[<span class="number">0</span>]=<span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,<span class="built_in">len</span>(nums)):</span><br><span class="line">            <span class="keyword">if</span> nums[i]&gt;nums[i-<span class="number">1</span>]:</span><br><span class="line">                dp[i]=dp[i-<span class="number">1</span>]+<span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                dp[i]=<span class="number">1</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">max</span>(dp)</span><br></pre></td></tr></table></figure><h2 id="最长递增子序列"><a href="#最长递增子序列" class="headerlink" title="最长递增子序列"></a><a href="https://leetcode.cn/problems/longest-increasing-subsequence/">最长递增子序列</a></h2><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">lengthOfLIS</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        length=<span class="built_in">len</span>(nums)</span><br><span class="line">        dp=[<span class="number">1</span> <span class="keyword">for</span> n <span class="keyword">in</span> <span class="built_in">range</span>(length)]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(length):</span><br><span class="line">            <span class="comment"># 从前面i个里面找比nums[i]大的</span></span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i):</span><br><span class="line">                </span><br><span class="line">                <span class="keyword">if</span> nums[i]&gt;nums[j]:</span><br><span class="line">                    <span class="comment"># 可以接的很多，我要找一个最大的接进去</span></span><br><span class="line">                    dp[i]=<span class="built_in">max</span>(dp[i],dp[j]+<span class="number">1</span>)</span><br><span class="line">                </span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">max</span>(dp)</span><br></pre></td></tr></table></figure><p><a href="https://leetcode.cn/problems/increasing-triplet-subsequence/">检查游戏1</a><br><a href="https://leetcode.cn/problems/number-of-longest-increasing-subsequence/">检查游戏2</a></p><h2 id="最大子序列和"><a href="#最大子序列和" class="headerlink" title="最大子序列和"></a><a href="https://leetcode.cn/problems/lian-xu-zi-shu-zu-de-zui-da-he-lcof/">最大子序列和</a></h2><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">maxSubArray</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="comment"># dp[i]以nums[i]为结尾的最大连续和</span></span><br><span class="line">        length=<span class="built_in">len</span>(nums)</span><br><span class="line">        dp=[n <span class="keyword">for</span> n <span class="keyword">in</span> nums]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,length):    </span><br><span class="line">            <span class="comment"># 是自己独立，还是并入前面？</span></span><br><span class="line">            dp[i]=<span class="built_in">max</span>(dp[i-<span class="number">1</span>]+nums[i],dp[i])</span><br><span class="line">        <span class="comment"># 可以不需要dp数组直接用res。但是看起来方便还是保留</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">max</span>(dp)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="最长公共子序列-Longest-Common-Sub-string-LCS"><a href="#最长公共子序列-Longest-Common-Sub-string-LCS" class="headerlink" title="最长公共子序列 Longest Common Sub-string(LCS)"></a><a href="https://leetcode.cn/problems/qJnOS7/">最长公共子序列 Longest Common Sub-string(LCS)</a></h2><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">longestCommonSubsequence</span>(<span class="params">self, text1: <span class="built_in">str</span>, text2: <span class="built_in">str</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        len1=<span class="built_in">len</span>(text1)</span><br><span class="line">        len2=<span class="built_in">len</span>(text2)</span><br><span class="line">        <span class="comment"># dp[i][j]表示A串到i且B串到j时候，最长公共子序列。多出来0 0，方便初始化</span></span><br><span class="line"></span><br><span class="line">        dp=[[<span class="number">0</span> <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(len2+<span class="number">1</span>)] <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(len1+<span class="number">1</span>)]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,len1+<span class="number">1</span>):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,len2+<span class="number">1</span>):</span><br><span class="line">                <span class="comment"># 当前的ij与原字符串的i j有偏移。</span></span><br><span class="line">                <span class="keyword">if</span> text1[i-<span class="number">1</span>]==text2[j-<span class="number">1</span>]:</span><br><span class="line">                    <span class="comment"># 若相同</span></span><br><span class="line">                    dp[i][j]=dp[i-<span class="number">1</span>][j-<span class="number">1</span>]+<span class="number">1</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="comment"># 若不相同，</span></span><br><span class="line">                    dp[i][j]=<span class="built_in">max</span>(dp[i-<span class="number">1</span>][j],dp[i][j-<span class="number">1</span>])</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> dp[-<span class="number">1</span>][-<span class="number">1</span>]</span><br></pre></td></tr></table></figure><h2 id="打家劫舍（树形dp）"><a href="#打家劫舍（树形dp）" class="headerlink" title="打家劫舍（树形dp）"></a><a href="https://leetcode.cn/problems/house-robber/">打家劫舍（树形dp）</a></h2><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">rob</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(nums)==<span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> nums[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(nums)==<span class="number">2</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">max</span>(nums[<span class="number">0</span>],nums[<span class="number">1</span>])</span><br><span class="line">        <span class="comment"># dp表示此位置的最大值</span></span><br><span class="line">        dp=[<span class="number">0</span> <span class="keyword">for</span> n <span class="keyword">in</span> nums]</span><br><span class="line">        dp[<span class="number">0</span>]=nums[<span class="number">0</span>]</span><br><span class="line">        dp[<span class="number">1</span>]=<span class="built_in">max</span>(nums[<span class="number">0</span>],nums[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">        length=<span class="built_in">len</span>(nums)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>,length):</span><br><span class="line">            dp[i]=<span class="built_in">max</span>(dp[i-<span class="number">1</span>],dp[i-<span class="number">2</span>]+nums[i])</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> dp[-<span class="number">1</span>]</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><a href="https://leetcode.cn/problems/house-robber-ii/">打家劫舍2</a>:下标范围dp，后比较即可<br><a href="https://leetcode.cn/problems/house-robber-iii/">打家劫舍3</a></p><h1 id="背包"><a href="#背包" class="headerlink" title="背包"></a>背包</h1><p><a href="https://www.bilibili.com/video/BV1X741127ZM">闫氏dp分析法教程</a></p><h2 id="01背包"><a href="#01背包" class="headerlink" title="01背包"></a>01背包</h2><p>其中cap = capacity，表示背包容量，n表示物品个数。<br>定义dp数组是背包容量为W，且迭代到第i个物品时能拿到的最大价值数。</p><p>由于需要先初始化dp[0][j]和dp[i][0]，则dp数组需要多出一行一列，注意weights和values数据会下标偏移。<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">n,cap=[<span class="built_in">int</span>(n) <span class="keyword">for</span> n <span class="keyword">in</span> <span class="built_in">input</span>().strip().split()] </span><br><span class="line"><span class="comment"># cap = capacity</span></span><br><span class="line">dp=[[<span class="number">0</span> <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(cap+<span class="number">1</span>)] <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n+<span class="number">1</span>)]</span><br><span class="line"></span><br><span class="line">values,weights=[],[]</span><br><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">    w,v=[<span class="built_in">int</span>(n) <span class="keyword">for</span> n <span class="keyword">in</span> <span class="built_in">input</span>().strip().split()]</span><br><span class="line">    values.append(v)</span><br><span class="line">    weights.append(w)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,n+<span class="number">1</span>):</span><br><span class="line">    <span class="keyword">for</span> cap_now <span class="keyword">in</span> <span class="built_in">range</span>(cap+<span class="number">1</span>):</span><br><span class="line">        <span class="keyword">if</span> cap_now&gt;=weights[i-<span class="number">1</span>]:</span><br><span class="line">            <span class="comment"># 如果能拿，但是我可以选择不拿</span></span><br><span class="line">            dp[i][cap_now]=<span class="built_in">max</span>(dp[i-<span class="number">1</span>][cap_now],dp[i-<span class="number">1</span>][cap_now-weights[i-<span class="number">1</span>]]+values[i-<span class="number">1</span>])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 此时肯定拿不了</span></span><br><span class="line">            dp[i][cap_now]=dp[i-<span class="number">1</span>][cap_now]</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(dp[-<span class="number">1</span>][-<span class="number">1</span>])</span><br></pre></td></tr></table></figure><br>由于可以优化下空间和写法，所以可以：<br>注意倒序的weights和下标开始点<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cap = capacity</span></span><br><span class="line">dp=[<span class="number">0</span> <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(cap+<span class="number">1</span>)] </span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,n+<span class="number">1</span>):</span><br><span class="line">    <span class="keyword">for</span> cap_now <span class="keyword">in</span> <span class="built_in">range</span>(cap+<span class="number">1</span>)[::-<span class="number">1</span>]:</span><br><span class="line">        <span class="keyword">if</span> cap_now&gt;=weights[i-<span class="number">1</span>]:</span><br><span class="line">            <span class="comment"># 如果能拿，但是我可以选择不拿</span></span><br><span class="line">            dp[cap_now]=<span class="built_in">max</span>(dp[cap_now],dp[cap_now-weights[i-<span class="number">1</span>]]+values[i-<span class="number">1</span>])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            dp[cap_now]=dp[cap_now]</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(dp[-<span class="number">1</span>])</span><br></pre></td></tr></table></figure><br>为什么不改掉<code>if else</code>语句？因为方便记忆。</p><h2 id="完全背包"><a href="#完全背包" class="headerlink" title="完全背包"></a>完全背包</h2><p>tbd</p>]]></content>
      
      
      
        <tags>
            
            <tag> classic algorithm, data structure </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Learning Backward Compatible Embeddings</title>
      <link href="/2022/09/02/kdd2022%20%20Compatible%20Embeddings/"/>
      <url>/2022/09/02/kdd2022%20%20Compatible%20Embeddings/</url>
      
        <content type="html"><![CDATA[<h1 id="文章链接"><a href="#文章链接" class="headerlink" title="文章链接"></a>文章链接</h1><p>KDD2022： <a href="https://cs.stanford.edu/people/jure/pubs/bcemb-kdd22.pdf">https://cs.stanford.edu/people/jure/pubs/bcemb-kdd22.pdf</a></p><h1 id="文章主要内容"><a href="#文章主要内容" class="headerlink" title="文章主要内容"></a>文章主要内容</h1><p>文章本身说的情景并不适合。<br>个人认为此方法适合的场景是：如何在低储存量的前提下交付多个下游用户。而不是文章说的在同一个模型不断迭代的情景下保持对某个用户的稳定节点表示。</p><h1 id="文章主要新意"><a href="#文章主要新意" class="headerlink" title="文章主要新意"></a>文章主要新意</h1><p>把原先只在face recognition的方法迁移到图表示上来。另外还做了些工程上的尝试。</p><h1 id="文章脉络"><a href="#文章脉络" class="headerlink" title="文章脉络"></a>文章脉络</h1><h2 id="3种应对场景的方法"><a href="#3种应对场景的方法" class="headerlink" title="3种应对场景的方法"></a>3种应对场景的方法</h2><ul><li>keep all，把所有使用到的embedding都存储</li><li>keep latest，只存储最后一版emebdding，剩下的用B来转换到对应版本，文章在这一方法下做了6种不同的实验。</li><li>keep original， 只储存第一版embedding，但是文章除了用fine tune，并没有给出更多实验。<h2 id="3种实验setting："><a href="#3种实验setting：" class="headerlink" title="3种实验setting："></a>3种实验setting：</h2>为了学到一个B矩阵，用来还原上一版，</li><li>Representation transformation：对上一步的embedding是否做linear变换，做linear的文章叫<code>Lin</code>，不做的叫<code>Notrans</code></li><li>Single/Multiple version of Regularizer：只对上一步的embedding做拉近还是对前多步的embedding做拉近。上一步的文章叫<code>Single step</code>，上多步的叫<code>Multi step</code></li><li>Training: 先train再regularize，还是training与regularization一起。先train再regularize叫<code>Posthoc</code>，一起的叫<code>Joint</code>。</li></ul><p>原本应该有2<em>2</em>2 共8种实验，但是文章只给出了6种。</p><h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><p>模型使用Pinsage，也就是graph sage。</p><h1 id="其他：-情景理由"><a href="#其他：-情景理由" class="headerlink" title="其他： 情景理由"></a>其他： 情景理由</h1><p>为了“稳定节点表示”而去倒推回原先的一套表示？那我新训练出来的新的embedding有什么用？</p>]]></content>
      
      
      
        <tags>
            
            <tag> paper reading, analysis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>metric-learning</title>
      <link href="/2022/09/01/metric_learning/"/>
      <url>/2022/09/01/metric_learning/</url>
      
        <content type="html"><![CDATA[<h1 id="Euclidean-distance-L2-norm"><a href="#Euclidean-distance-L2-norm" class="headerlink" title="Euclidean distance (L2 norm)"></a>Euclidean distance (L2 norm)</h1><p>No explanation, too simple.</p><p>eg: 2-demensional data</p><script type="math/tex; mode=display">A=(a_1,a_2)\ B=(b_1,b_2)</script><script type="math/tex; mode=display">D(A,B)=\sqrt{(a_1−b_1)^2+(a_2−b_2)^2}</script><h1 id="Mahalanobis-distance"><a href="#Mahalanobis-distance" class="headerlink" title="Mahalanobis distance"></a>Mahalanobis distance</h1><p>A distance with consideration on data distribution, more specifically on covarience and demention(量纲). Euclidean is Mahalanobis distance if you perform PCA and normalization on data. In other word, Euclidean distance is a special case of Mahalanobis distance.</p><script type="math/tex; mode=display">D(x,y)=\sqrt{(x−y)^TΣ^{−1}(x−y)}</script><p>where Σ is the covariance metrix of the two data.</p><h1 id="contrastive-loss-对比损失"><a href="#contrastive-loss-对比损失" class="headerlink" title="contrastive loss(对比损失)"></a>contrastive loss(对比损失)</h1><p>It’s created with the idea that we should pull as far as possible away for any data that do not belong to the same class and pull as close as possible for ones that belong to the same class.</p><script type="math/tex; mode=display">D(X_i,X_j)=y_{i,j}d^2_{i,j}+(1−y_{i,j})[α−d^2_{i,j}]</script><p>where $y<em>{i,j}$ is 1 if $X_i$ and $X_j$ is of same class, and 0 otherwise, $d</em>{i,j}$ is euclidean distance, and $α$ controls how aggressive you want different classes to be.</p><p>It can measure data that has never shown before, which cannot be done by classic methods.</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Black List</title>
      <link href="/2022/09/01/black_list/"/>
      <url>/2022/09/01/black_list/</url>
      
        <content type="html"><![CDATA[<p>排名不分先后。</p><h2 id="抄袭"><a href="#抄袭" class="headerlink" title="抄袭"></a>抄袭</h2><h3 id="李铎"><a href="#李铎" class="headerlink" title="李铎"></a>李铎</h3><p>据个人主页，他是清华自动化专业2019届毕业生，还是ICCV、 CVPR、 ICML、NeurIPS、ICLR、AAAI审稿人，现在是香港科技大学二年级硕士生。</p><p>抄袭论文m-RevNet: Deep Reversible Neural Networks with Momentum</p><p><img src="../../img/liduo.png" alt=""></p><p>参考:</p><ul><li><a href="https://cloud.tencent.com/developer/article/2237523">https://cloud.tencent.com/developer/article/2237523</a></li><li><a href="https://www.zhihu.com/question/480075870">https://www.zhihu.com/question/480075870</a></li></ul><h3 id="高明豪，张海伦"><a href="#高明豪，张海伦" class="headerlink" title="高明豪，张海伦"></a>高明豪，张海伦</h3><p>一作 山东科技大学计算机科学与工程学院网络工程专业2017级本科生高明豪，现已毕业。<br>二作 北京理工大学自动化学院智能信息处理与控制方向2020级硕士生 张海伦<br>三作 河海大学常州校区物联网院计算机科学与技术专业 2017 级本科生晏艺格，现已毕业</p><p>抄袭文章Label Assignment Distillation for Object Detection</p><p>参考：</p><ul><li><a href="https://mp.weixin.qq.com/s/FScA4YQ4GWLBThqDU7BpAg">https://mp.weixin.qq.com/s/FScA4YQ4GWLBThqDU7BpAg</a></li><li><a href="https://www.zhihu.com/question/487690998/answer/2128202695">https://www.zhihu.com/question/487690998/answer/2128202695</a></li><li><a href="https://mp.weixin.qq.com/s/lRCF7bpAf2NvGZ6E1774LA">https://mp.weixin.qq.com/s/lRCF7bpAf2NvGZ6E1774LA</a></li></ul><h3 id="伊浩天"><a href="#伊浩天" class="headerlink" title="伊浩天"></a>伊浩天</h3><p>南开大学物理学院应用物理专业本科生</p><p>参考：</p><ul><li><a href="https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&amp;mid=2652245617&amp;idx=1&amp;sn=4148db9881f98163ab47d2ca89023c32&amp;chksm=f1257a80c652f3960b47c5670310a702201bd00acdd12b316d5661eb13f2baa14c5692cfb4c2&amp;scene=21#wechat_redirect">https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&amp;mid=2652245617&amp;idx=1&amp;sn=4148db9881f98163ab47d2ca89023c32&amp;chksm=f1257a80c652f3960b47c5670310a702201bd00acdd12b316d5661eb13f2baa14c5692cfb4c2&amp;scene=21#wechat_redirect</a></li><li><a href="https://www.zhihu.com/question/565565085">https://www.zhihu.com/question/565565085</a></li></ul><h3 id="谢红"><a href="#谢红" class="headerlink" title="谢红"></a>谢红</h3><p>谢红（河北师范大学硕士研究生导师）于2003年全文抄袭已故钢琴教育家陈比纲（享受国务院特殊津贴专家，中央音乐学院钢琴系教授）科研成果两篇。现在抄袭者谢红已经是河北师范大学音乐学院钢琴系主任、学院学术委员会委员、教学委员会委员，而陈比纲教授已于2018年9月2日溘然长逝，无从知晓谢红主任此等行径了。</p><p>参考：</p><ul><li><a href="https://www.zhihu.com/question/311935889/answer/2440880925">https://www.zhihu.com/question/311935889/answer/2440880925</a></li></ul><h3 id="Jongwan-Kim-DongJin-Lee-Byunggook-Na-Seongsik-Park-Jeonghee-Jo-Sungroh-Yoon"><a href="#Jongwan-Kim-DongJin-Lee-Byunggook-Na-Seongsik-Park-Jeonghee-Jo-Sungroh-Yoon" class="headerlink" title="Jongwan Kim,DongJin Lee,Byunggook Na,Seongsik Park,Jeonghee Jo,Sungroh Yoon"></a>Jongwan Kim,DongJin Lee,Byunggook Na,Seongsik Park,Jeonghee Jo,Sungroh Yoon</h3><p>Seol University</p><p>E2V-SDE: From Asynchronous Events to Fast and Continuous Video Reconstruction via Neural Stochastic Differential Equations</p><ul><li><a href="https://www.zhihu.com/question/539378810">https://www.zhihu.com/question/539378810</a></li></ul><h2 id="涉嫌抄袭"><a href="#涉嫌抄袭" class="headerlink" title="涉嫌抄袭"></a>涉嫌抄袭</h2><h3 id="Ahmed-Nassar-Nikolaos-Livathinos-Maksym-Lysak-Peter-Staar"><a href="#Ahmed-Nassar-Nikolaos-Livathinos-Maksym-Lysak-Peter-Staar" class="headerlink" title="Ahmed Nassar, Nikolaos Livathinos, Maksym Lysak Peter Staar"></a>Ahmed Nassar, Nikolaos Livathinos, Maksym Lysak Peter Staar</h3><p>IBM Zurich Research</p><p>TableFormer: Table Structure Understanding with Transformers<br>原文 PINGAN-VCGROUP’S SOLUTION FOR ICDAR 2021 COMPETITION ON SCIENTIFIC LITERATURE PARSING TASK B: TABLE RECOGNITION TO HTML</p><ul><li><a href="https://github.com/JiaquanYe/TableMASTER-mmocr/blob/master/Reply2IBMZurich.pdf">https://github.com/JiaquanYe/TableMASTER-mmocr/blob/master/Reply2IBMZurich.pdf</a></li><li><a href="https://www.zhihu.com/question/539137931/answer/2541401041">https://www.zhihu.com/question/539137931/answer/2541401041</a></li></ul><h3 id="杨志新-Prof-Yang-Zhixin"><a href="#杨志新-Prof-Yang-Zhixin" class="headerlink" title="杨志新 Prof. Yang Zhixin"></a>杨志新 Prof. Yang Zhixin</h3><p>作者Luqing Luo1, Lulu Tang1∗, Wanyi Zhou2, Shizheng Wang3, Zhi-Xin Yang1†</p><p>1 State Key Laboratory of Internet of Things for Smart City, University of Macau<br>2 South China University of Technology<br>3 Institute of Microelectronics Chinese Academy of Sciences</p><p>主单位澳门大学智慧城市物联网国家重点实验室</p><p>涉嫌文章PU-EVA: An Edge-Vector based Approximation Solution for Flexible-scale Point Cloud Upsampling</p><p>原文：Deep Magnification-Flexible Upsampling over 3D Point Clouds</p><ul><li><a href="https://www.zhihu.com/question/540700307/answer/2551525417">https://www.zhihu.com/question/540700307/answer/2551525417</a><h3 id="Junjie-Huang1∗-Duyu-Tang4-Wanjun-Zhong2-Shuai-Lu3-Linjun-Shou5-Ming-Gong5-Daxin-Jiang5-Nan-Duan4"><a href="#Junjie-Huang1∗-Duyu-Tang4-Wanjun-Zhong2-Shuai-Lu3-Linjun-Shou5-Ming-Gong5-Daxin-Jiang5-Nan-Duan4" class="headerlink" title="Junjie Huang1∗, Duyu Tang4, Wanjun Zhong2, Shuai Lu3,Linjun Shou5, Ming Gong5, Daxin Jiang5, Nan Duan4"></a>Junjie Huang1∗, Duyu Tang4, Wanjun Zhong2, Shuai Lu3,Linjun Shou5, Ming Gong5, Daxin Jiang5, Nan Duan4</h3></li></ul><p>单位1Beihang University 2Sun Yat-sen University 3Peking University<br>4Microsoft Research Asia 5Microsoft STC Asia</p><p>涉嫌抄袭论文：<a href="https://arxiv.org/abs/2104.01767">https://arxiv.org/abs/2104.01767</a></p><p>参考：</p><ul><li><a href="https://spaces.ac.cn/archives/8715">https://spaces.ac.cn/archives/8715</a></li></ul><h3 id="Dong-Zhang，魏素忠，-Shoushan-Li，Hanqian-Wu，Qiaoming-Zhu，Guodong-Zhou"><a href="#Dong-Zhang，魏素忠，-Shoushan-Li，Hanqian-Wu，Qiaoming-Zhu，Guodong-Zhou" class="headerlink" title="Dong Zhang，魏素忠， Shoushan Li，Hanqian Wu，Qiaoming Zhu，Guodong Zhou"></a>Dong Zhang，魏素忠， Shoushan Li，Hanqian Wu，Qiaoming Zhu，Guodong Zhou</h3><p>其中Hanqian Wu 东南大学，其他苏州大学</p><p>涉嫌抄袭论文：Multi-modal Graph Fusion for Named Entity Recognition with Targeted Visual Guidance</p><ul><li><a href="https://www.zhihu.com/question/505808044/answer/2269414820">https://www.zhihu.com/question/505808044/answer/2269414820</a></li><li><a href="https://www.zhihu.com/question/506018160">https://www.zhihu.com/question/506018160</a></li></ul><h2 id="毕业论文抄袭"><a href="#毕业论文抄袭" class="headerlink" title="毕业论文抄袭"></a>毕业论文抄袭</h2><h3 id="湖南大学"><a href="#湖南大学" class="headerlink" title="湖南大学"></a>湖南大学</h3><p>湖南大学信息科学与工程学院软件工程专业2018届毕业生侯伟的硕士学位论文《企业协同办公系统的设计与实现》涉嫌抄袭电子科技大学光电科学与工程学院硕士毕业生杨姝妍的学位论文《基于J2EE的企业协同办公系统的设计与实现》，两篇论文的重复率接近100%。</p><p>湖南大学信息科学与工程学院软件工程专业2018届毕业生侯伟<br>的硕士学位论文《企业协同办公系统的设计与实现》<br>涉嫌抄袭电子科技大学光电科学与工程学院硕士毕业生杨姝妍的学位论文《基于J2EE的企业协同办公系统的设计与实现》，两篇论文的重复率接近100%。</p><p>继湖南大学软件工程专业2016届硕士毕业生曹律、陈杰因论文抄袭华东师范大学2013届硕士毕业生武秀萍的硕士学位论文。比对后发现，这两篇论文不仅题目一字不差，全文雷同。<br>被撤销硕士学位之后，该专业再次被爆出的第三篇涉嫌抄袭的硕士学位论文。   </p><ul><li><a href="https://www.thepaper.cn/newsDetail_forward_15242975">https://www.thepaper.cn/newsDetail_forward_15242975</a></li><li><a href="https://www.zhihu.com/question/496065823/answer/2202004186">https://www.zhihu.com/question/496065823/answer/2202004186</a></li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>YOLOv5 结果解析</title>
      <link href="/2020/09/16/yolov5_res/"/>
      <url>/2020/09/16/yolov5_res/</url>
      
        <content type="html"><![CDATA[<h1 id="Confusion-matrix"><a href="#Confusion-matrix" class="headerlink" title="Confusion matrix"></a>Confusion matrix</h1><p>以这种形式给出矩阵的值</p><div class="table-container"><table><thead><tr><th></th><th>$gt_{class1}$</th><th>$gt_{class2}$</th><th>$gt_{class3}$</th><th>background FP</th></tr></thead><tbody><tr><td>$pred_{class1}$</td></tr><tr><td>$pred_{class2}$     </td></tr><tr><td>$pred_{class3}$</td></tr><tr><td>background FN</td></tr></tbody></table></div><p><img src="https://img-blog.csdnimg.cn/36f1d7598d4141c3a6c9c0eed111df08.png" alt="在这里插入图片描述">若是分类的完美，则应当只有对角线是高峰，其余都是0（除了最后一行和最后一列）.<br>根据GitHub上的讨论，background也被列成单独一类，所以也有他的TP、FP、TN、FN等。</p><p><strong>最后一列和最后一行都是以background的类别pos的prediction的FN和FP</strong>。所以最右下角是没有意义的，没有值。</p><ul><li>由于最后一列是background的FP，本来不是背景的，被pred分成了背景，<strong>漏检了非背景物体</strong></li><li>由于最后一行是background的FN，本来是背景的，被pred分成了不是背景，<strong>虚检了本来没有的物体</strong>。</li></ul><blockquote><p>混淆矩阵最后一行和一列是背景类。上面我们知道列是模型预测的结果，行是标签的真实结果。而FP则是表示真实为假预测为真，FN表示真实为真预测为假。可以看到最后一行即backgroundFN出现数值，表示出现了漏检；最后一列即background FP出现数值，则表示出现了虚检<br>来自 <a href="https://blog.csdn.net/m0_66447617/article/details/124180032">https://blog.csdn.net/m0_66447617/article/details/124180032</a>, </p><p>另外可参考github上的讨论，background也被单独划分成了一个类别。<br>    <a href="https://github.com/kaanakan/object_detection_confusion_matrix/issues/12">https://github.com/kaanakan/object_detection_confusion_matrix/issues/12</a></p></blockquote><p>以上面的图为例子的话，可以看到background FN各类都比较高，虚检了很多物体；background FP- hat的相对较高，漏检了很多head类别的物体。而在非背景的类别中，可以看到对角线的值相对大，可见模型能够很好的分清楚这三类谁是谁。</p><h1 id="F1-curve"><a href="#F1-curve" class="headerlink" title="F1 curve"></a>F1 curve</h1><p><img src="https://img-blog.csdnimg.cn/48fdfad93ac2402599e7f189fd090c85.png" alt="在这里插入图片描述">横坐标是置信阈值。</p><script type="math/tex; mode=display">F1=2*\frac1{\frac1{precision}+\frac1{recall}}</script><p>此图能够看到什么阈值下什么类别能够达到最好的F1 score，比如绿线在0.27左右，海蓝色在0.8左右。</p><h1 id="labels"><a href="#labels" class="headerlink" title="labels"></a>labels</h1><p><img src="https://img-blog.csdnimg.cn/c36f8eac520d47978e91ed1374c06841.png" alt="在这里插入图片描述"><br>给所提供的label数据进行统计，是4个图，左上是各个物体的数量直方图，右上是中心对齐后各个物体的bounding box，左下角是中心点统计，右下角是方框长、宽统计</p><h1 id="results"><a href="#results" class="headerlink" title="results"></a>results</h1><p><img src="https://img-blog.csdnimg.cn/788a6a6fc6d947adbbf72974414ee040.png" alt="在这里插入图片描述">横坐标是epoch，标题比较直观的说了每个图的意思</p><h1 id="剩下一些不需要解释的图"><a href="#剩下一些不需要解释的图" class="headerlink" title="剩下一些不需要解释的图"></a>剩下一些不需要解释的图</h1><h2 id="常规曲线"><a href="#常规曲线" class="headerlink" title="常规曲线"></a>常规曲线</h2><p>P-R curve<br>P curve<br>R curve</p><h2 id="batch抽取的case-study"><a href="#batch抽取的case-study" class="headerlink" title="batch抽取的case study"></a>batch抽取的case study</h2><p><img src="https://img-blog.csdnimg.cn/985feb0454444956801d04e8798c5dd8.png" alt="在这里插入图片描述"><br>这些就是抽取个例查看。</p>]]></content>
      
      
      
        <tags>
            
            <tag> cv, object detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Xgboost LightGBM Demo</title>
      <link href="/2020/09/06/xgboost/"/>
      <url>/2020/09/06/xgboost/</url>
      
        <content type="html"><![CDATA[<h1 id="Xgboost"><a href="#Xgboost" class="headerlink" title="Xgboost"></a>Xgboost</h1><h2 id="Binary-Classification"><a href="#Binary-Classification" class="headerlink" title="Binary Classification"></a>Binary Classification</h2><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> StratifiedKFold</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_auc_score,precision_score</span><br><span class="line"><span class="keyword">import</span> xgboost <span class="keyword">as</span> xgb</span><br><span class="line"><span class="keyword">import</span> lightgbm <span class="keyword">as</span> lgb</span><br><span class="line"></span><br><span class="line">skfold=StratifiedKFold(n_splits=<span class="number">3</span>,random_state=<span class="number">2022</span>,shuffle=<span class="literal">True</span>)</span><br><span class="line"><span class="keyword">for</span> train_idx,val_idx <span class="keyword">in</span> skfold.split(all_data,labels):</span><br><span class="line">    <span class="comment"># xgboost划分数据集 训练</span></span><br><span class="line">    train_d=xgb.DMatrix(all_data[train_idx],labels[train_idx])</span><br><span class="line">    test_d=xgb.DMatrix(all_data[val_idx])</span><br><span class="line">    </span><br><span class="line">    params = &#123;</span><br><span class="line">        <span class="string">&#x27;booster&#x27;</span>:<span class="string">&#x27;gblinear&#x27;</span>, <span class="comment"># gbtree gblinear dart</span></span><br><span class="line">        <span class="string">&#x27;eta&#x27;</span>: <span class="number">0.1</span>,</span><br><span class="line">        <span class="comment"># &#x27;colsample_bytree&#x27;: 0.7,</span></span><br><span class="line">        <span class="comment"># &#x27;subsample&#x27;: 0.7,</span></span><br><span class="line">        <span class="comment"># &#x27;alpha&#x27;: 0.01, #L1 norm</span></span><br><span class="line">        <span class="comment"># &#x27;gamma&#x27;: 1,</span></span><br><span class="line">        <span class="string">&#x27;objective&#x27;</span>: <span class="string">&#x27;binary:logistic&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;seed&#x27;</span>: <span class="number">2022</span></span><br><span class="line">    &#125;</span><br><span class="line">    clf=xgb.train(params=params,evals=[(train_d,<span class="string">&#x27;Train&#x27;</span>)],dtrain=train_d,num_boost_round=<span class="number">10</span>) <span class="comment"># 0.65625</span></span><br><span class="line">    preds=clf.predict(test_d)</span><br><span class="line">    preds[preds &gt; <span class="number">0.5</span>] = <span class="number">0</span></span><br><span class="line">    preds[preds &lt;= <span class="number">0.5</span>] = <span class="number">1</span></span><br><span class="line">    <span class="built_in">print</span>(preds)</span><br><span class="line">    <span class="comment"># precision 85 auc 60</span></span><br><span class="line"></span><br><span class="line">    test_y=labels[val_idx]</span><br><span class="line">    score=precision_score(test_y,preds)</span><br><span class="line">    <span class="built_in">print</span>(score)</span><br><span class="line">    score = roc_auc_score(test_y, preds)</span><br><span class="line">    <span class="built_in">print</span>(score, end=<span class="string">&#x27;\n\n&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    </span><br></pre></td></tr></table></figure><h2 id="Regression"><a href="#Regression" class="headerlink" title="Regression"></a>Regression</h2><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> KFold</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_auc_score,mean_squared_error</span><br><span class="line"><span class="keyword">import</span> xgboost <span class="keyword">as</span> xgb</span><br><span class="line"><span class="keyword">import</span> lightgbm <span class="keyword">as</span> lgb</span><br><span class="line"></span><br><span class="line">skfold=KFold(n_splits=<span class="number">3</span>,random_state=<span class="number">2022</span>,shuffle=<span class="literal">True</span>)</span><br><span class="line"><span class="keyword">for</span> train_idx,val_idx <span class="keyword">in</span> skfold.split(all_data, labels):</span><br><span class="line">    <span class="comment"># xgboost划分数据集 训练</span></span><br><span class="line">    train_d=xgb.DMatrix(all_data[train_idx],labels[train_idx])</span><br><span class="line">    test_d=xgb.DMatrix(all_data[val_idx])</span><br><span class="line">    </span><br><span class="line">    params = &#123;</span><br><span class="line">        <span class="string">&#x27;booster&#x27;</span>:<span class="string">&#x27;gblinear&#x27;</span>, <span class="comment"># gbtree gblinear dart</span></span><br><span class="line">        <span class="string">&#x27;eta&#x27;</span>: <span class="number">1</span>,</span><br><span class="line">        <span class="comment"># &#x27;colsample_bytree&#x27;: 0.7,</span></span><br><span class="line">        <span class="comment"># &#x27;subsample&#x27;: 0.7,</span></span><br><span class="line">        <span class="string">&#x27;alpha&#x27;</span>: <span class="number">0.01</span>, <span class="comment">#L1 norm</span></span><br><span class="line">        <span class="comment"># &#x27;gamma&#x27;: 1,</span></span><br><span class="line">        <span class="string">&#x27;objective&#x27;</span>: <span class="string">&#x27;reg:squarederror&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;seed&#x27;</span>: <span class="number">2022</span></span><br><span class="line">    &#125;</span><br><span class="line">    clf=xgb.train(params=params,evals=[(train_d,<span class="string">&#x27;Train&#x27;</span>)],dtrain=train_d,num_boost_round=<span class="number">30</span>) <span class="comment"># 0.65625</span></span><br><span class="line">    preds=clf.predict(test_d)</span><br><span class="line"></span><br><span class="line">    test_y=labels[val_idx]</span><br><span class="line">    <span class="built_in">print</span>(preds)</span><br><span class="line">    <span class="built_in">print</span>(test_y)</span><br><span class="line">    <span class="comment"># test_y=test_y*labels.std(0)+labels.mean(0)</span></span><br><span class="line">    <span class="comment"># preds=preds*labels.std(0)+labels.mean(0)</span></span><br><span class="line">    score=mean_squared_error(test_y,preds)</span><br><span class="line">    <span class="built_in">print</span>(score, end=<span class="string">&#x27;\n\n&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id="Lightgbm"><a href="#Lightgbm" class="headerlink" title="Lightgbm"></a>Lightgbm</h1><h2 id="Binary-Classification-1"><a href="#Binary-Classification-1" class="headerlink" title="Binary Classification"></a>Binary Classification</h2><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> StratifiedKFold</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_auc_score,precision_score</span><br><span class="line"><span class="keyword">import</span> xgboost <span class="keyword">as</span> xgb</span><br><span class="line"><span class="keyword">import</span> lightgbm <span class="keyword">as</span> lgb</span><br><span class="line"></span><br><span class="line">skfold=StratifiedKFold(n_splits=<span class="number">3</span>,random_state=<span class="number">2022</span>,shuffle=<span class="literal">True</span>)</span><br><span class="line"><span class="keyword">for</span> train_idx,val_idx <span class="keyword">in</span> skfold.split(all_data,labels):</span><br><span class="line">    params=&#123;</span><br><span class="line">        <span class="string">&#x27;objective&#x27;</span> : <span class="string">&#x27;binary&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;learning_rate&#x27;</span>: <span class="number">1</span>,</span><br><span class="line">        <span class="string">&#x27;n_estimators&#x27;</span> : <span class="number">10</span>,</span><br><span class="line">    &#125;</span><br><span class="line">    gbm = lgb.LGBMClassifier(**params)</span><br><span class="line">    gbm.fit(all_data[train_idx], labels[train_idx], eval_set=[(all_data[train_idx], labels[train_idx])], eval_metric=<span class="string">&#x27;cross_entropy&#x27;</span>)</span><br><span class="line">    preds = gbm.predict(all_data[val_idx], num_iteration=gbm.best_iteration_)</span><br><span class="line">    <span class="comment"># precision 84 auc 59</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    test_y=labels[val_idx]</span><br><span class="line">    score=precision_score(test_y,preds)</span><br><span class="line">    <span class="built_in">print</span>(score)</span><br><span class="line">    score = roc_auc_score(test_y, preds)</span><br><span class="line">    <span class="built_in">print</span>(score, end=<span class="string">&#x27;\n\n&#x27;</span>)</span><br></pre></td></tr></table></figure><h2 id="Regression-1"><a href="#Regression-1" class="headerlink" title="Regression"></a>Regression</h2><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> StratifiedKFold</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_auc_score,precision_score</span><br><span class="line"><span class="keyword">import</span> xgboost <span class="keyword">as</span> xgb</span><br><span class="line"><span class="keyword">import</span> lightgbm <span class="keyword">as</span> lgb</span><br><span class="line"></span><br><span class="line">skfold=StratifiedKFold(n_splits=<span class="number">3</span>,random_state=<span class="number">2022</span>,shuffle=<span class="literal">True</span>)</span><br><span class="line"><span class="keyword">for</span> train_idx,val_idx <span class="keyword">in</span> skfold.split(all_data,labels):</span><br><span class="line">    params=&#123;</span><br><span class="line">        <span class="string">&#x27;objective&#x27;</span> : <span class="string">&#x27;regression&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;learning_rate&#x27;</span>: <span class="number">1</span>,</span><br><span class="line">        <span class="string">&#x27;n_estimators&#x27;</span> : <span class="number">40</span>,</span><br><span class="line">    &#125;</span><br><span class="line">    gbm = lgb.LGBMRegressor(**params)</span><br><span class="line">    gbm.fit(all_data[train_idx], labels_norm[train_idx], eval_set=[(all_data[train_idx], labels_norm[train_idx])])</span><br><span class="line">    preds = gbm.predict(all_data[val_idx], num_iteration=gbm.best_iteration_)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    test_y=labels[val_idx]</span><br><span class="line">    <span class="built_in">print</span>(preds)</span><br><span class="line">    <span class="built_in">print</span>(test_y)</span><br><span class="line">    test_y=test_y*labels.std(<span class="number">0</span>)+labels.mean(<span class="number">0</span>)</span><br><span class="line">    preds=preds*labels.std(<span class="number">0</span>)+labels.mean(<span class="number">0</span>)</span><br><span class="line">    score=mean_squared_error(test_y,preds)</span><br><span class="line">    <span class="built_in">print</span>(score, end=<span class="string">&#x27;\n\n&#x27;</span>)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>YOLOv5 quick start</title>
      <link href="/2020/09/04/yolov5_takeaway/"/>
      <url>/2020/09/04/yolov5_takeaway/</url>
      
        <content type="html"><![CDATA[<h1 id="Takeaways"><a href="#Takeaways" class="headerlink" title="Takeaways"></a>Takeaways</h1><p>需要规整两个文件<code>xx/images/</code>和<code>xx/labels</code>，其中里面堆放可以堆放指向文件的txt，分别都是<code>train.txt</code>和<code>val.txt</code>。</p><p>训练使用yolo项目中<code>train.py</code>，其命令中data选项需要yaml，进行数据集的指向和说明。一定要保证yaml的路径与我们处理的数据集的路径相同。</p><p>所有运行后的结果，都会在项目的runs文件夹中。</p><h1 id="快速上手-https-docs-ultralytics-com-quick-start"><a href="#快速上手-https-docs-ultralytics-com-quick-start" class="headerlink" title="快速上手^[https://docs.ultralytics.com/quick-start/]"></a>快速上手^[<a href="https://docs.ultralytics.com/quick-start/">https://docs.ultralytics.com/quick-start/</a>]</h1><p>总参考：<a href="https://docs.ultralytics.com/tutorials/training-tips-best-results/">https://docs.ultralytics.com/tutorials/training-tips-best-results/</a> </p><h1 id="Inference"><a href="#Inference" class="headerlink" title="Inference"></a>Inference</h1><ul><li>两种方法，一个是自行下载model源码，使用detect.py.  <figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python .\detect.py --weights <span class="string">&quot;weights/yolov5s.pt&quot;</span> --source <span class="string">&quot;data/images/bus.jpg&quot;</span></span><br></pre></td></tr></table></figure></li><li>另一个是通过<code>torch.hub</code>  <figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">    <span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="comment"># Model</span></span><br><span class="line">model = torch.hub.load(<span class="string">&#x27;ultralytics/yolov5&#x27;</span>, <span class="string">&#x27;yolov5s&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Images</span></span><br><span class="line"><span class="built_in">dir</span> = <span class="string">&#x27;https://github.com/ultralytics/yolov5/raw/master/data/images/&#x27;</span></span><br><span class="line">imgs = [<span class="built_in">dir</span> + f <span class="keyword">for</span> f <span class="keyword">in</span> (<span class="string">&#x27;zidane.jpg&#x27;</span>, <span class="string">&#x27;bus.jpg&#x27;</span>)]  <span class="comment"># batch of images</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Inference</span></span><br><span class="line">results = model(imgs)</span><br><span class="line">results.<span class="built_in">print</span>()  <span class="comment"># or .show(), .save()</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h1></li></ul><h2 id="编写yaml文件"><a href="#编写yaml文件" class="headerlink" title="编写yaml文件"></a>编写yaml文件</h2><p>首先需要一个yaml文件，放在<code>data</code>文件夹下，示例如下：<br>第一行其实是存放路径名的文件，文件的每一行可以有三种形式，注释已经给出。</p><ul><li>一种是直接把目录给出，目录里面放有图片+标签</li><li>一种是以txt形式给出，txt里面有图片/label的路径</li><li>一种是多种路径同时给出<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># train and val data as 1) directory: path/images/, 2) file: path/images.txt, or 3) list: [path1/images/, path2/images/]</span></span><br><span class="line"><span class="attr">train:</span> <span class="string">../coco128/images/train2017/</span></span><br><span class="line"><span class="attr">val:</span> <span class="string">../coco128/images/train2017/</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># number of classes</span></span><br><span class="line"><span class="attr">nc:</span> <span class="number">80</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># class names</span></span><br><span class="line"><span class="attr">names:</span> [<span class="string">&#x27;person&#x27;</span>, <span class="string">&#x27;bicycle&#x27;</span>, <span class="string">&#x27;car&#x27;</span>, <span class="string">&#x27;motorcycle&#x27;</span>, <span class="string">&#x27;airplane&#x27;</span>, <span class="string">&#x27;bus&#x27;</span>, <span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;truck&#x27;</span>, <span class="string">&#x27;boat&#x27;</span>, <span class="string">&#x27;traffic light&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;fire hydrant&#x27;</span>, <span class="string">&#x27;stop sign&#x27;</span>, <span class="string">&#x27;parking meter&#x27;</span>, <span class="string">&#x27;bench&#x27;</span>, <span class="string">&#x27;bird&#x27;</span>, <span class="string">&#x27;cat&#x27;</span>, <span class="string">&#x27;dog&#x27;</span>, <span class="string">&#x27;horse&#x27;</span>, <span class="string">&#x27;sheep&#x27;</span>, <span class="string">&#x27;cow&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;elephant&#x27;</span>, <span class="string">&#x27;bear&#x27;</span>, <span class="string">&#x27;zebra&#x27;</span>, <span class="string">&#x27;giraffe&#x27;</span>, <span class="string">&#x27;backpack&#x27;</span>, <span class="string">&#x27;umbrella&#x27;</span>, <span class="string">&#x27;handbag&#x27;</span>, <span class="string">&#x27;tie&#x27;</span>, <span class="string">&#x27;suitcase&#x27;</span>, <span class="string">&#x27;frisbee&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;skis&#x27;</span>, <span class="string">&#x27;snowboard&#x27;</span>, <span class="string">&#x27;sports ball&#x27;</span>, <span class="string">&#x27;kite&#x27;</span>, <span class="string">&#x27;baseball bat&#x27;</span>, <span class="string">&#x27;baseball glove&#x27;</span>, <span class="string">&#x27;skateboard&#x27;</span>, <span class="string">&#x27;surfboard&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;tennis racket&#x27;</span>, <span class="string">&#x27;bottle&#x27;</span>, <span class="string">&#x27;wine glass&#x27;</span>, <span class="string">&#x27;cup&#x27;</span>, <span class="string">&#x27;fork&#x27;</span>, <span class="string">&#x27;knife&#x27;</span>, <span class="string">&#x27;spoon&#x27;</span>, <span class="string">&#x27;bowl&#x27;</span>, <span class="string">&#x27;banana&#x27;</span>, <span class="string">&#x27;apple&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;sandwich&#x27;</span>, <span class="string">&#x27;orange&#x27;</span>, <span class="string">&#x27;broccoli&#x27;</span>, <span class="string">&#x27;carrot&#x27;</span>, <span class="string">&#x27;hot dog&#x27;</span>, <span class="string">&#x27;pizza&#x27;</span>, <span class="string">&#x27;donut&#x27;</span>, <span class="string">&#x27;cake&#x27;</span>, <span class="string">&#x27;chair&#x27;</span>, <span class="string">&#x27;couch&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;potted plant&#x27;</span>, <span class="string">&#x27;bed&#x27;</span>, <span class="string">&#x27;dining table&#x27;</span>, <span class="string">&#x27;toilet&#x27;</span>, <span class="string">&#x27;tv&#x27;</span>, <span class="string">&#x27;laptop&#x27;</span>, <span class="string">&#x27;mouse&#x27;</span>, <span class="string">&#x27;remote&#x27;</span>, <span class="string">&#x27;keyboard&#x27;</span>, </span><br><span class="line">        <span class="string">&#x27;cell phone&#x27;</span>, <span class="string">&#x27;microwave&#x27;</span>, <span class="string">&#x27;oven&#x27;</span>, <span class="string">&#x27;toaster&#x27;</span>, <span class="string">&#x27;sink&#x27;</span>, <span class="string">&#x27;refrigerator&#x27;</span>, <span class="string">&#x27;book&#x27;</span>, <span class="string">&#x27;clock&#x27;</span>, <span class="string">&#x27;vase&#x27;</span>, <span class="string">&#x27;scissors&#x27;</span>, </span><br><span class="line">        <span class="string">&#x27;teddy bear&#x27;</span>, <span class="string">&#x27;hair drier&#x27;</span>, <span class="string">&#x27;toothbrush&#x27;</span>]</span><br><span class="line"></span><br></pre></td></tr></table></figure></li></ul><h2 id="获得标签"><a href="#获得标签" class="headerlink" title="获得标签"></a>获得标签</h2><p>可以使用CVAT、 makesense.ai、 Labelbox、Labelimg等等工具打标。</p><h2 id="转化label格式（如果需要）"><a href="#转化label格式（如果需要）" class="headerlink" title="转化label格式（如果需要）"></a>转化label格式（如果需要）</h2><p>label格式一般有两种，一个是xml，一个是txt。<br>txt格式是：每一行都是一个object，以<code>class x_center y_center width height</code>表示，yolo系列使用的是txt格式。<br>xml格式实例：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">&lt;?xml version=&quot;1.0&quot; ?&gt;&lt;annotation&gt;</span><br><span class="line">  &lt;filename&gt;helmet_10827.jpg&lt;/filename&gt;</span><br><span class="line">  &lt;size&gt;</span><br><span class="line">    &lt;width&gt;1920&lt;/width&gt;</span><br><span class="line">    &lt;height&gt;1080&lt;/height&gt;</span><br><span class="line">    &lt;depth&gt;3&lt;/depth&gt;</span><br><span class="line">  &lt;/size&gt;</span><br><span class="line">  &lt;object&gt;</span><br><span class="line">    &lt;name&gt;hat&lt;/name&gt;</span><br><span class="line">    &lt;bndbox&gt;</span><br><span class="line">      &lt;xmin&gt;1227&lt;/xmin&gt;</span><br><span class="line">      &lt;ymin&gt;385&lt;/ymin&gt;</span><br><span class="line">      &lt;xmax&gt;1288&lt;/xmax&gt;</span><br><span class="line">      &lt;ymax&gt;446&lt;/ymax&gt;</span><br><span class="line">    &lt;/bndbox&gt;</span><br><span class="line">  &lt;/object&gt;</span><br><span class="line">  &lt;object&gt;</span><br><span class="line">    &lt;name&gt;person&lt;/name&gt;</span><br><span class="line">    &lt;bndbox&gt;</span><br><span class="line">      &lt;xmin&gt;1161&lt;/xmin&gt;</span><br><span class="line">      &lt;ymin&gt;377&lt;/ymin&gt;</span><br><span class="line">      &lt;xmax&gt;1324&lt;/xmax&gt;</span><br><span class="line">      &lt;ymax&gt;604&lt;/ymax&gt;</span><br><span class="line">    &lt;/bndbox&gt;</span><br><span class="line">  &lt;/object&gt;</span><br><span class="line">&lt;/annotation&gt;</span><br></pre></td></tr></table></figure></p><p>xml转txt可以用以下<strong>示例</strong>代码^[<a href="https://docs.cvmart.net/#/best_practice_for_newbie?id=jump1]转化：">https://docs.cvmart.net/#/best_practice_for_newbie?id=jump1]转化：</a><br>xml转txt<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> xml.etree.ElementTree <span class="keyword">as</span> ET</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> os <span class="keyword">import</span> listdir, getcwd</span><br><span class="line"><span class="keyword">from</span> os.path <span class="keyword">import</span> join</span><br><span class="line"></span><br><span class="line">sets=[<span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;val&#x27;</span>, <span class="string">&#x27;test&#x27;</span>]</span><br><span class="line">classes = [<span class="string">&#x27;person&#x27;</span>, <span class="string">&#x27;hat&#x27;</span>,<span class="string">&#x27;head&#x27;</span>]</span><br><span class="line"></span><br><span class="line">abs_path = os.getcwd()</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">convert</span>(<span class="params">size, box</span>):</span><br><span class="line">    dw = <span class="number">1.</span>/(size[<span class="number">0</span>])</span><br><span class="line">    dh = <span class="number">1.</span>/(size[<span class="number">1</span>])</span><br><span class="line">    x = (box[<span class="number">0</span>] + box[<span class="number">1</span>])/<span class="number">2.0</span> - <span class="number">1</span></span><br><span class="line">    y = (box[<span class="number">2</span>] + box[<span class="number">3</span>])/<span class="number">2.0</span> - <span class="number">1</span></span><br><span class="line">    w = box[<span class="number">1</span>] - box[<span class="number">0</span>]</span><br><span class="line">    h = box[<span class="number">3</span>] - box[<span class="number">2</span>]</span><br><span class="line">    x = x*dw</span><br><span class="line">    w = w*dw</span><br><span class="line">    y = y*dh</span><br><span class="line">    h = h*dh</span><br><span class="line">    <span class="keyword">return</span> (x,y,w,h)</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">convert_annotation</span>(<span class="params">image_id</span>):</span><br><span class="line">    in_file = <span class="built_in">open</span>(<span class="string">&#x27;/project/train/src_repo/dataset/Annotations/%s.xml&#x27;</span>%( image_id))</span><br><span class="line">    out_file = <span class="built_in">open</span>(<span class="string">&#x27;/project/train/src_repo/dataset/labels/%s.txt&#x27;</span>%(image_id), <span class="string">&#x27;w&#x27;</span>)</span><br><span class="line">    tree=ET.parse(in_file)</span><br><span class="line">    root = tree.getroot()</span><br><span class="line">    size = root.find(<span class="string">&#x27;size&#x27;</span>)</span><br><span class="line">    w = <span class="built_in">int</span>(size.find(<span class="string">&#x27;width&#x27;</span>).text)</span><br><span class="line">    h = <span class="built_in">int</span>(size.find(<span class="string">&#x27;height&#x27;</span>).text)</span><br><span class="line">    <span class="keyword">for</span> obj <span class="keyword">in</span> root.<span class="built_in">iter</span>(<span class="string">&#x27;object&#x27;</span>):</span><br><span class="line">        <span class="comment">#difficult = obj.find(&#x27;difficult&#x27;).text</span></span><br><span class="line">        cls = obj.find(<span class="string">&#x27;name&#x27;</span>).text</span><br><span class="line">        <span class="keyword">if</span> cls <span class="keyword">not</span> <span class="keyword">in</span> classes :</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        cls_id = classes.index(cls)</span><br><span class="line">        xmlbox = obj.find(<span class="string">&#x27;bndbox&#x27;</span>)</span><br><span class="line">        b = (<span class="built_in">float</span>(xmlbox.find(<span class="string">&#x27;xmin&#x27;</span>).text), <span class="built_in">float</span>(xmlbox.find(<span class="string">&#x27;xmax&#x27;</span>).text), <span class="built_in">float</span>(xmlbox.find(<span class="string">&#x27;ymin&#x27;</span>).text), <span class="built_in">float</span>(xmlbox.find(<span class="string">&#x27;ymax&#x27;</span>).text))</span><br><span class="line">        bb = convert((w,h), b)</span><br><span class="line">        out_file.write(<span class="built_in">str</span>(cls_id) + <span class="string">&quot; &quot;</span> + <span class="string">&quot; &quot;</span>.join([<span class="built_in">str</span>(a) <span class="keyword">for</span> a <span class="keyword">in</span> bb]) + <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> image_set <span class="keyword">in</span> sets:</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="string">&#x27;/project/train/src_repo/dataset/labels/&#x27;</span>):</span><br><span class="line">        os.makedirs(<span class="string">&#x27;/project/train/src_repo/dataset/labels/&#x27;</span>)</span><br><span class="line">    image_ids = <span class="built_in">open</span>(<span class="string">&#x27;/project/train/src_repo/dataset/ImageSets/Main/%s.txt&#x27;</span>%(image_set)).read().strip().split()</span><br><span class="line">    list_file = <span class="built_in">open</span>(<span class="string">&#x27;/project/train/src_repo/dataset/%s.txt&#x27;</span>%(image_set), <span class="string">&#x27;w&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> image_id <span class="keyword">in</span> image_ids:</span><br><span class="line">        list_file.write(<span class="string">&#x27;/project/train/src_repo/dataset/images/%s.jpg\n&#x27;</span>%(image_id))</span><br><span class="line">        convert_annotation(image_id)</span><br><span class="line">    list_file.close()</span><br></pre></td></tr></table></figure></p><h2 id="整理目录"><a href="#整理目录" class="headerlink" title="整理目录"></a>整理目录</h2><p>目录结构应该成这个样子：<br><img src="https://user-images.githubusercontent.com/26833433112467887-e18a0980-8d67-11eb-93af-6505620ff8aa.png" alt="这是图片"></p><p>dataset单独一个目录，目录下有images和labels两个目录，每个目录下有train和valid。</p><h2 id="Training-1"><a href="#Training-1" class="headerlink" title="Training"></a>Training</h2><p>在下载的源码里，有<code>train.py</code>。<br>只需按照示例：<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Train YOLOv5s on COCO128 for 5 epochs</span></span><br><span class="line">$ python train.py --img <span class="number">640</span> --batch <span class="number">16</span> --epochs <span class="number">5</span> --data coco128.yaml --weights yolov5s.pt</span><br></pre></td></tr></table></figure><br>训练结果会保存在项目的<code>runs/train/</code>。</p><h2 id="查看训练、可视化"><a href="#查看训练、可视化" class="headerlink" title="查看训练、可视化"></a>查看训练、可视化</h2><p>可以用wandb和tensorboard，教程推荐使用wandb。</p><h3 id="wandb"><a href="#wandb" class="headerlink" title="wandb"></a>wandb</h3><p>可以用wandb，<code>pip install wandb</code>，在训练过程中就可以在 <a href="https://wandb.ai">https://wandb.ai</a> 中看到结果。<br>使用这个工具，log会被默认的放在<code>runs/train</code>。</p><h3 id="tensorboard"><a href="#tensorboard" class="headerlink" title="tensorboard"></a>tensorboard</h3><p>这个需要自行修改代码，在合适的位置加入tb，记录数据。</p><h1 id="更高训练结果tips"><a href="#更高训练结果tips" class="headerlink" title="更高训练结果tips"></a>更高训练结果tips</h1><h2 id="数据集改进点"><a href="#数据集改进点" class="headerlink" title="数据集改进点"></a>数据集改进点</h2><ul><li>关于每类的图片：每一类最好是≥1.5k的图片。</li><li>每类物体最好是≥10k. 并且物体要具有代表性。真实场景下，推荐使用不同时间段、不同季节、不同角度、不同光照、不同天气、不同采集源的同一物体，做为训练数据。</li><li>Label consistency. All instances of all classes in all images must be labelled. Partial labelling will not work.</li><li>Label accuracy. Labels must closely enclose each object. No space should exist between an object and it’s bounding box. No objects should be missing a label.</li><li>Background images. Background images are images with no objects that are added to a dataset to reduce False Positives (FP). We recommend about 0-10% background images to help reduce FPs (COCO has 1000 background images for reference, 1% of the total).</li></ul><h2 id="模型选择"><a href="#模型选择" class="headerlink" title="模型选择"></a>模型选择</h2><p>yolo提供了多种不同大小的模型，大模型往往能更好的结果。<br><img src="https://user-images.githubusercontent.com/26833433/103595982-ab986000-4eb1-11eb-8c57-4726261b0a88.png" alt=""></p><ul><li>pretrain往往在中小型数据集上。  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">python train.py --data custom.yaml --weights yolov5s.pt</span><br><span class="line">                                         yolov5m.pt</span><br><span class="line">                                         yolov5l.pt</span><br><span class="line">                                         yolov5x.pt</span><br><span class="line">                                         custom_pretrained.pt</span><br><span class="line"></span><br></pre></td></tr></table></figure></li><li>train from scratch往往在大数据集上。  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">python train.py --data custom.yaml --weights &#x27;&#x27; --cfg yolov5s.yaml</span><br><span class="line">                                                  yolov5m.yaml</span><br><span class="line">                                                  yolov5l.yaml</span><br><span class="line">                                                  yolov5x.yaml</span><br><span class="line"></span><br></pre></td></tr></table></figure></li></ul><h2 id="训练参数"><a href="#训练参数" class="headerlink" title="训练参数"></a>训练参数</h2><p>Training Settings</p><p>Before modifying anything, first train with default settings to establish a performance baseline. A full list of train.py settings can be found in the train.py argparser.</p><ul><li><strong>Epochs</strong>. Start with 300 epochs. If this overfits early then you can reduce epochs. If overfitting does not occur after 300 epochs, train longer, i.e. 600, 1200 etc epochs.</li><li><strong>Image size</strong>. COCO trains at native resolution of <code>--img 640</code>, though due to the high amount of small objects in the dataset it can benefit from training at higher resolutions such as <code>--img 1280</code>. If there are many <strong>small objects</strong> then custom datasets will benefit from training at native or higher resolution. Best inference results are obtained at the same —img as the training was run at, i.e. if you train at <code>--img 1280</code> you should also test and detect at <code>--img 1280</code>.</li><li><strong>Batch size</strong>. Use the largest <code>--batch-size</code> that your hardware allows for. Small batch sizes produce poor batchnorm statistics and should be avoided.</li><li><strong>Hyperparameters</strong>. Default hyperparameters are in <a href="https://github.com/ultralytics/yolov5/blob/master/data/hyp.scratch.yaml">hyp.scratch.yaml</a>. We recommend you train with default hyperparameters first before thinking of modifying any. In general, <em>increasing augmentation hyperparameters will reduce and delay overfitting, allowing for longer trainings and higher final mAP</em>. Reduction in loss component gain hyperparameters like <code>hyp[&#39;obj&#39;]</code> will help reduce overfitting in those specific loss components. For an automated method of optimizing these hyperparameters, see our <a href="https://github.com/ultralytics/yolov5/issues/607">Hyperparameter Evolution Tutorial</a>.</li></ul><p>参考^[<a href="https://docs.ultralytics.com/tutorials/train-custom-datasets/">https://docs.ultralytics.com/tutorials/train-custom-datasets/</a>]</p>]]></content>
      
      
      
        <tags>
            
            <tag> cv, object detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>moving average</title>
      <link href="/2020/09/01/moving_average/"/>
      <url>/2020/09/01/moving_average/</url>
      
        <content type="html"><![CDATA[<h2 id="Exponentially-weighted-averages"><a href="#Exponentially-weighted-averages" class="headerlink" title="Exponentially weighted averages "></a>Exponentially weighted averages </h2><script type="math/tex; mode=display">Vt=βVt−1−(1−β)Vt</script><p>where β ranges from 0 to 1.<br>This equation enables you to make average of 11−β</p><p>days’ data, which will make the data plot much smoother.</p><p>example:<br><a href="https://www.bilibili.com/video/av49445369?p=60">https://www.bilibili.com/video/av49445369?p=60</a><br>result:<br>pic<br>where the red line is the smoother plot and the blue ones are the original data plot.</p><p><a href="https://zhuanlan.zhihu.com/p/29895933">https://zhuanlan.zhihu.com/p/29895933</a><br>So it’s just a weighted average, and it can perform smoothening.<br>Improvement–Bias correction</p><p>At early stage, if we use standard equation may get the purple line in the picture below, because it lack former data to be averaged.<br>pic<br>To eliminate this problem, perform the method in red rectangle on the picture in early stage.</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>measure the contribution:shaply value</title>
      <link href="/2020/09/01/shaply/"/>
      <url>/2020/09/01/shaply/</url>
      
        <content type="html"><![CDATA[<p>Measure Contribution of Participants in Federated Learning<br>2020-03-27</p><p><a href="https://arxiv.org/pdf/1909.08525v1.pdf">Paper link</a></p><h1 id="BASIC"><a href="#BASIC" class="headerlink" title="BASIC"></a>BASIC</h1><p>backgroud: federated learning<br>two measure methods exist, deletion <a href="https://www.ime.usp.br/~abe/lista/pdfWiH1zqnMHo.pdf">diagnostics</a> and <a href="https://arxiv.org/pdf/1703.04730.pdf">influence functions</a></p><h1 id="SHAPLEY-VALUE-amp-MARIGINAL-CONTRIBUTION"><a href="#SHAPLEY-VALUE-amp-MARIGINAL-CONTRIBUTION" class="headerlink" title="SHAPLEY VALUE &amp; MARIGINAL CONTRIBUTION"></a>SHAPLEY VALUE &amp; MARIGINAL CONTRIBUTION</h1><p>it’s used to split profit earned by all participants.</p><h2 id="Example"><a href="#Example" class="headerlink" title="Example:"></a>Example:</h2><p>We need to kill 500 monsters in total. A alone can kill 100; B alone can kill 125; C alone can kill 50. A and B together can kill 270; B and C together can kill 350; A and C together can kill 375; A and B and C together can kill 500 in total.<br>We denote what mentioned above as:<br>v(1)=100;</p><p>v(2)=125; v(3)=50;<br>v(1,2)=270; v(2,3)=350; v(1,3)=375;<br>v(1,2,3)=500;</p><p>Note that the task can only be accomplished by three people.<br>possible cases might be 6 in total:<br>A invites B to make a group S and then invites C.<br>A invites C to make a group S and then invites B.<br>etc etc.</p><h1 id="Marginal-Contribution"><a href="#Marginal-Contribution" class="headerlink" title="Marginal Contribution"></a>Marginal Contribution</h1><p>The marginal contribution splitted of this 6 cases should be calculated as this as shown in the table.<br>image<br>so the marginal contribution is formulated as: $δ_i(S)=v(S\cup i)−v(S)$<br>, where $δ$ denote the influence/contribution factor, $δ_i(S)$ denotes the ith participant’s contribution to group S.<br>From the discussion we can know that the order of the participants really matters in term of marginal contribution.</p><h1 id="Shapley-Value"><a href="#Shapley-Value" class="headerlink" title="Shapley Value"></a>Shapley Value</h1><p>shapley value takes high importance on marginal contribution(边际贡献 in chinese), which is formulated as</p><script type="math/tex; mode=display">Sh(S,i)=\frac{Σ_{r∈R}δ_i(r)}{|Ag|!}</script><p>where $|Ag|$ denotes the number of agants who participates; R denotes the set of all possible cases, r denotes one specific case that belong to whole set R;<br>According to the shapley value equation, we calculate agants’ value as followed:<br>1： 16(100+100+145+150+325+150)=9706<br>2： 16(170+125+125+125+125+300)=9706<br>3： 16(230+275+230+225+50+50)=10606</p><p>1 2 3 total is 500.<br>and then they can split the profit according to the shapley value.</p><h1 id="PAPER-METHOD"><a href="#PAPER-METHOD" class="headerlink" title="PAPER METHOD"></a>PAPER METHOD</h1><h2 id="Horizontal-Measurement"><a href="#Horizontal-Measurement" class="headerlink" title="Horizontal Measurement"></a>Horizontal Measurement</h2><p>Deletion diagnostics is intuitive. Retrain the model each time with an instance omitted from training dataset and measure how much the prediction of retrained model changes.</p><p>Suppose we omit the $i$th instance, or rather one piece of data, influence is formulated as:</p><script type="math/tex; mode=display">Influence(i)=\frac1nΣ^n_{j=i}|predj−pred−ij|</script><p>And any dataset had many instance, so the dataset influence can be discribed as:</p><script type="math/tex; mode=display">Influence(D)=Σ_{i∈D}Influence(D_i)</script><p>where $Di$ means the $i$th instance in dataset.</p><h2 id="Vertical-Measurement"><a href="#Vertical-Measurement" class="headerlink" title="Vertical Measurement"></a>Vertical Measurement</h2><p>coeffient<br>Questions tbd: what is situational importance?<br>It’s an ancient question coming up a long time ago, and there’re pretty many paper about this question. Most of them applied shapley value as measurement to get vertical FML contribution of each party.</p><p>We first take a easy example and then we generalize the situation.</p><h2 id="Individual-Feature-Shaley-Value"><a href="#Individual-Feature-Shaley-Value" class="headerlink" title="Individual Feature Shaley Value"></a>Individual Feature Shaley Value</h2><p>Note: we are now in INSTANCE level! We are talking about ONE SINGLE INSTANCE, one piece of data.<br>Consider an instance with total n features, what is the contribution of one specific feature value?<br>Suppose to calculate the contribution of the ith<br>feature, we go like this:</p><script type="math/tex; mode=display">ϕ_i(x)=Σ_{Q∈S∖i}\frac{|Q|!(|S|−|Q|−1)!}{|S|!}(Δ_{Q\cup i}−Δ_Q)</script><p>where S is the index set of all feature, Q is a index subset, |.| denotes the number of . .<br>By observation, we can see that right part of the equation is the influence difference between subset with ith and subset without ith</p><p>while the left part is just a coeffient to average the influence.</p><h2 id="Dataset-Feature-Shaley-Value"><a href="#Dataset-Feature-Shaley-Value" class="headerlink" title="Dataset Feature Shaley Value"></a>Dataset Feature Shaley Value</h2><p>We are coming into DATASET LEVEL.<br>Although the method mentioned above gives a strong sulotion to get contribution of individual feature, but with so many data in a dataset, computing has a exponential time complexity, making it infeasible to implement in practice.<br>An approximation with Monto-Carlo Sampling algorithm has been proposed in <a href="https://link.springer.com/article/10.1007/s10115-013-0679-x">this paper</a>:</p><script type="math/tex; mode=display">ϕ_i(x)=\frac1M\sum^M_{m=1}(f(x^m_{+i})−f(x^{m}_{−i}))</script><p>where $M$ is the iteration number, which is customized by user; $x^{m}<em>{−i}$ is subset with random feature replaced by randomly picked instance from dataset, and WITHOUT ith feature; $x^m</em>{+i}$ is everything the same as $x^{m}_{−i}$ but WITH ith feature.</p><p>To summarize, the sampling method helps simplify computing making it feasible to perform contribution algorithm in dataset level.</p><h2 id="Federated-Learning-Feature-Shaley-Value"><a href="#Federated-Learning-Feature-Shaley-Value" class="headerlink" title="Federated Learning Feature Shaley Value"></a>Federated Learning Feature Shaley Value</h2><p>This is the paper method proposed by the author.</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>yolo example</title>
      <link href="/2020/09/01/yolo/"/>
      <url>/2020/09/01/yolo/</url>
      
        <content type="html"><![CDATA[<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment">#cv2.rectangle 通过对角线来画矩形，左上到右下这个对角线。</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#load yolo</span></span><br><span class="line">base=<span class="string">r&quot;G:/Code/YOLO recognition/&quot;</span></span><br><span class="line">yolo_net = cv2.dnn.readNet(base + <span class="string">&quot;yolov3.weights&quot;</span>, base + <span class="string">&quot;yolov3.cfg&quot;</span>)</span><br><span class="line"><span class="comment">#load label</span></span><br><span class="line">classes=<span class="string">&#x27;whatever&#x27;</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(base+<span class="string">&quot;coco.names&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">     classes=[line.strip() <span class="keyword">for</span> line <span class="keyword">in</span> f]</span><br><span class="line"><span class="comment"># print(classes)</span></span><br><span class="line"></span><br><span class="line">layer_names = yolo_net.getLayerNames()</span><br><span class="line">output_layers = [layer_names[i[<span class="number">0</span>] - <span class="number">1</span>] <span class="keyword">for</span> i <span class="keyword">in</span> yolo_net.getUnconnectedOutLayers()]</span><br><span class="line">colors = np.random.uniform(<span class="number">0</span>, <span class="number">255</span>, size=(<span class="built_in">len</span>(classes), <span class="number">3</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#load image</span></span><br><span class="line">img=cv2.imread(base+<span class="string">&quot;2.jpg&quot;</span>)</span><br><span class="line"><span class="comment"># img=cv2.resize(img,None,fx=0.4,fy=0.4)</span></span><br><span class="line">img_height, img_width, channel=img.shape</span><br><span class="line">cv2.imshow(<span class="string">&quot;original&quot;</span>,img)</span><br><span class="line">blob=cv2.dnn.blobFromImage(img,<span class="number">0.00392</span>,(<span class="number">416</span>,<span class="number">416</span>),(<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>),<span class="literal">True</span>,crop=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># blob=blob.astype(np.uint8) this is for image show, if needed.</span></span><br><span class="line">yolo_net.setInput(blob)</span><br><span class="line">outs=yolo_net.forward(output_layers)</span><br><span class="line"><span class="comment">#except for confidence, what else does yolo output contain?</span></span><br><span class="line"><span class="comment">#for detection down below, detection[0] is centroid_x ratio, detection[1] is centroid_y ratio</span></span><br><span class="line"><span class="comment">#detection[2] is width ratio, detection[3] is height ratio.</span></span><br><span class="line"></span><br><span class="line">confidences=[]</span><br><span class="line">boxes=[]</span><br><span class="line">pred_indeces=[]</span><br><span class="line"><span class="comment">#show info on pic</span></span><br><span class="line"><span class="keyword">for</span> out <span class="keyword">in</span> outs:</span><br><span class="line">    <span class="keyword">for</span> detection <span class="keyword">in</span> out:</span><br><span class="line">        <span class="comment">#why after 5</span></span><br><span class="line">        scores=detection[<span class="number">5</span>:]</span><br><span class="line">        pred_index=np.argmax(scores)</span><br><span class="line">        confidence=scores[pred_index]</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> confidence &gt; <span class="number">0.5</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;there is one!&quot;</span>)</span><br><span class="line">            </span><br><span class="line">            center_x=<span class="built_in">int</span>(detection[<span class="number">0</span>] * img_width)</span><br><span class="line">            center_y=<span class="built_in">int</span>(detection[<span class="number">1</span>] * img_height)</span><br><span class="line">            rec_width= <span class="built_in">int</span>(detection[<span class="number">2</span>] * img_width)</span><br><span class="line">            rec_height= <span class="built_in">int</span>(detection[<span class="number">3</span>] * img_height)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># cv2.circle(img,(center_x,center_y),10,(0,0,255),2)</span></span><br><span class="line"></span><br><span class="line">            <span class="comment">#rectangle coordinates beginning at left top side.</span></span><br><span class="line">            left_top_x=<span class="built_in">int</span>(center_x - rec_width / <span class="number">2</span>)</span><br><span class="line">            left_top_y=<span class="built_in">int</span>(center_y - rec_height / <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">            boxes.append([left_top_x, left_top_y, rec_width, rec_height])</span><br><span class="line">            pred_indeces.append(pred_index)</span><br><span class="line">            confidences.append(<span class="built_in">float</span>(confidence))</span><br><span class="line">            <span class="comment"># cv2.rectangle(img,(x,y),(x+w,y+h),(0,0,255),2)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#NMSBoxes recieves only float type data, otherwise it returns nothing.</span></span><br><span class="line">indexes = cv2.dnn.NMSBoxes(boxes, confidences, <span class="number">0.5</span>, <span class="number">0.4</span>)</span><br><span class="line"></span><br><span class="line">font=cv2.FONT_HERSHEY_PLAIN</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(boxes)):</span><br><span class="line">    <span class="keyword">if</span> i <span class="keyword">in</span> indexes:</span><br><span class="line">        left_top_x, left_top_y, rec_width, rec_height=boxes[i]</span><br><span class="line">        label=classes[pred_indeces[i]]</span><br><span class="line">        color=colors[i]</span><br><span class="line">        cv2.rectangle(img, (left_top_x, left_top_y), (left_top_x + rec_width, left_top_y + rec_height), color, <span class="number">2</span>)</span><br><span class="line">        cv2.putText(img, label, (left_top_x, left_top_y + <span class="number">30</span>), font, <span class="number">1</span>, color, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">cv2.imshow(<span class="string">&quot;detection&quot;</span>,img)</span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br><span class="line">cv2.destroyAllWindows()</span><br><span class="line"></span><br><span class="line">exit()</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
