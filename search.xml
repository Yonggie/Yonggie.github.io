<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>fateboard的使用</title>
      <link href="/2023/03/01/fateboard%E4%BD%BF%E7%94%A8/"/>
      <url>/2023/03/01/fateboard%E4%BD%BF%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<p>fateboard文档 <a href="https://fate.fedai.org/fateboard/">https://fate.fedai.org/fateboard/</a><br>github Fateboard文档 <a href="https://github.com/FederatedAI/FATE-Board/blob/master/README-CN.md">https://github.com/FederatedAI/FATE-Board/blob/master/README-CN.md</a></p><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>Fateboard是FATE框架的任务看板。<br>在配置FATE时，Fateboard一般是被安装好了的，安装过程查看<a href="">这里</a><br>ATEBoard代码使用spring-boot框架并嵌入在tomcat容器中，默认的网络端口是8080，所以还要稍微懂点java。<br>我自己并没有深究springboot，按我的理解，</p><h1 id="启动fateboard服务"><a href="#启动fateboard服务" class="headerlink" title="启动fateboard服务"></a>启动fateboard服务</h1><p>因为我是standalone安装的FATE，已经直接安装好了，根据文档<a href="https://fate.fedai.org/fateboard/">https://fate.fedai.org/fateboard/</a><br>输入以下可启动Fateboard<br><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java -Dspring.config.location=FATE/fateboard/src/main/resources/application.properties -DFATE_DEPLOY_PREFIX=FATE/logs/ -Dssh_config_file=FATE/fateboard/src/main/resources/ -Xmx2048m -Xms2048m -XX:+PrintGCDetails -XX:+PrintGCDateStamps -Xloggc:gc.log -XX:+HeapDumpOnOutOfMemoryError -jar FATE/fateboard/target/fateboard-1.0.jar &gt;/dev/null 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure><br>一些参数解释<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">-Dspring.config.location path of application.properties of fateboard</span><br><span class="line">-Dssh_config_file path of directory which ssh.properties lies in</span><br><span class="line">-DFATE_DEPLOY_PREFIX path of logs directory which produced by fate_flow</span><br></pre></td></tr></table></figure><br>所以看上去挺长，其实就是输入了一些路径，有点长。<br>拆解一下就是用java启动了springboot的一个服务，<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java -A a -B b</span><br></pre></td></tr></table></figure><br>还有一些杂项，列在下面了，基本上是java的相关的一些参数（我不是很熟悉java，有错请评论指出</p><ul><li>-Xms2048m ：代表最小堆要2048MiB</li><li>-XX:+PrintGCDetails ：开启了jvm的Garage Collector的日志输出</li><li>-XX:+PrintGCDateStamps ：输出GC的时间戳（以日期的形式，如 2013-05-04T21:53:59.2）参考<a href="https://blog.csdn.net/yinni11/article/details/102591431">这个</a></li><li>-Xloggc:gc.log : 输出GC日志到文件</li><li>-XX:+HeapDumpOnOutOfMemoryError : 表示当JVM发生OOM时，自动生成DUMP文件。啥是DUMP文件？</li><li>-jar FATE/fateboard/target/fateboard-1.0.jar </li><li><blockquote><p>/dev/null 2&gt;&amp;1 &amp; ： 这些就是linux运维基本知识了，直接把输出的信息不要了，把stderr错误信息输出给到stdout来，参考<a href="https://blog.csdn.net/ggxiaobai/article/details/53507530">这个</a></p></blockquote></li></ul><p>停止服务<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ps -ef|grep java|grep fateboard-1.1.jar|grep -v grep|awk ‘&#123;print $2&#125;’</span><br><span class="line">kill -9 $&#123;pid&#125;</span><br></pre></td></tr></table></figure></p><h1 id="启动服务后，网页访问"><a href="#启动服务后，网页访问" class="headerlink" title="启动服务后，网页访问"></a>启动服务后，网页访问</h1><p><a href="http://{fateboard-ip}:8080，一般就可以了，如果8080端口没有被别人占了的话。想要直接换端口应该可以在启动的时候往java那命令里加参数就可以。standalone的话一般是``127.0.0.1:8080``">http://{fateboard-ip}:8080，一般就可以了，如果8080端口没有被别人占了的话。想要直接换端口应该可以在启动的时候往java那命令里加参数就可以。standalone的话一般是``127.0.0.1:8080``</a><br>不过搞笑的是访问后竟然还要登录……默认是账密是<code>admin</code>和<code>admin</code>。<br>接下来都是可视化操作了。<br><img src="https://img-blog.csdnimg.cn/3163acf1d2db45df872c8d1c21e7b63f.png" alt="在这里插入图片描述"></p><h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>Fateboard是重要的FATE框架任务看板，即便是开发debug的时候也会常用到这一看版。</p><p>party id should be positive integer<br>‘NoneType’ object has no attribute ‘index’</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>FATE数据上传、读取、训练、保存</title>
      <link href="/2023/02/28/FATE%E6%95%B0%E6%8D%AE%E4%B8%8A%E4%BC%A0%E8%AE%AD%E7%BB%83/"/>
      <url>/2023/02/28/FATE%E6%95%B0%E6%8D%AE%E4%B8%8A%E4%BC%A0%E8%AE%AD%E7%BB%83/</url>
      
        <content type="html"><![CDATA[<p>fate如何安装？本文续<a href="https://yonggie.blog.csdn.net/article/details/129240605">这篇文章</a>。</p><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>fate是一个服务，还原联邦学习，所以分client和host两种身份，一般来说用户都是client，用户想要上传自己的数据，合并他人数据最终获得一个更好的模型，所以要“上传”数据。</p><p>在 FATE 框架中，横向联邦的场景被称为 homo，纵向的被称为 hetero，比如 纵向安全提升树模型就叫做 hetero secure boost。</p><h1 id="上传"><a href="#上传" class="headerlink" title="上传"></a>上传</h1><p>官方文档：<a href="https://fate.readthedocs.io/en/latest/tutorial/pipeline">https://fate.readthedocs.io/en/latest/tutorial/pipeline</a><br><strong>强烈建议对着官方文档看我这个！</strong></p><h2 id="工具"><a href="#工具" class="headerlink" title="工具"></a>工具</h2><p>FATE框架可以使用pipeline工具进行上传。</p><p>先下载fate_client，因为Pipeline是fate_client里的一个工具。<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install fate_client</span><br></pre></td></tr></table></figure><br>根据文档，想要使用pipeline，需要命令行配合使用<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pipeline init --ip=xxx --port=xxx</span><br></pre></td></tr></table></figure><br>先terminal里面对pipeline初始化才能使用pipeline，ip和port要跟FATE启动时的ip和port要对应，如果是standalone，那么ip是127.0.0.1，port一般是9380。</p><p>如果记不清fate的配置了，使用（暂时还没找到，等着补上<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">flow </span><br></pre></td></tr></table></figure><br>如果记不清pipeleine的配置了，使用<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pipeline config show</span><br></pre></td></tr></table></figure><br>查看</p><h2 id="Python开发"><a href="#Python开发" class="headerlink" title="Python开发"></a>Python开发</h2><p>python文件如下代码即可上传csv文件。<br>每一个上传的数据都会有自己的table_name和namespace，fate用这两个字段来命名区分每一个上传的数据。<br>pipeline的initiator绑定此pipeline是谁的，set roles标明此任务是由哪些人们一起做。<br>下面的例子意思是“此pipeline属于guest，他的id号是9999，此任务由id是9999的guest和id是10000的host共同完成”。guest和host参数除了可以是一个数字，也可以是一个list，比如<code>guest=[1,2,3,4]</code>。<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pipeline.backend.pipeline <span class="keyword">import</span> PipeLine</span><br><span class="line"></span><br><span class="line">pipeline = PipeLine() \</span><br><span class="line">        .set_initiator(role=<span class="string">&#x27;guest&#x27;</span>, party_id=<span class="number">9999</span>) \</span><br><span class="line">        .set_roles(guest=<span class="number">9999</span>, host=<span class="number">10000</span>) </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">data_path=<span class="string">&#x27;/root/Downloads/dummy.csv&#x27;</span></span><br><span class="line">table_name=<span class="string">&#x27;dummy&#x27;</span></span><br><span class="line">namespace=<span class="string">&#x27;dummy&#x27;</span></span><br><span class="line">pipeline.add_upload_data(file=data_path,table_name=table_name,namespace=namespace)</span><br><span class="line">pipeline.upload(drop=<span class="number">1</span>) <span class="comment"># drop表示是否覆盖已经上传的table</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><br>成功运行后，terminal会出现类似字样。<img src="https://img-blog.csdnimg.cn/28a3be499b404b18917b31fc7664e3e2.png" alt="在这里插入图片描述"></p><h1 id="从FATE服务中获得数据"><a href="#从FATE服务中获得数据" class="headerlink" title="从FATE服务中获得数据"></a>从FATE服务中获得数据</h1><p>官方文档：<a href="https://fate.readthedocs.io/en/latest/tutorial/pipeline/pipeline_tutorial_hetero_sbt/#install**强烈建议对着官方文档看我这个！**">https://fate.readthedocs.io/en/latest/tutorial/pipeline/pipeline_tutorial_hetero_sbt/#install**强烈建议对着官方文档看我这个！**</a></p><p>文档中的sbt，其实就是Secure Boost Tree，一个决策树模型，因为使用了FATE，所以叫Secure。</p><h2 id="工具-1"><a href="#工具-1" class="headerlink" title="工具"></a>工具</h2><p>FATE中使用<code>Reader</code>类，从FATE框架中获得数据。</p><p>文档中说“load data”，我一开始以为load data是从本地load，汗！文档最好改成load data from FATE service……</p><p>使用<code>Reader</code>类获得数据后，可以使用<code>DataTransform</code>类进行变换。文档和代码有提，可以参考文档。使用<code>Intersection</code>可以获得两份数据的PSI值，根据<a href="https://fate.readthedocs.io/en/latest/zh/federatedml_component/#_2">Component文档</a>，PSI是两份数据中交集程度的指标，FATE当然还提供了更多的函数，文档的代码只是举了一个PSI的例子。</p><h2 id="Python"><a href="#Python" class="headerlink" title="Python"></a>Python</h2><p><code>Reader</code>同样也需要绑定party，但是是要绑定<strong>数据提供方</strong>的身份和id。比如有一份数据A是guest id10提供的，在定义Reader的时候要绑定guest id10才能成功读取。</p><p>在下方的例子中，由于我上面已经用guest 9999上传过一份数据了，所以下面的pipeline我还是用guest 9999下载获得这份数据，没有其他方，所以我的参数不需要加入其他的guest或者host。</p><p>注意：如果一方party在上传数据的时候没有提前和另一方party通知（也就是上传的pipeline时没有约定谁能够使用我的数据），那么即便是有一方得知了此份数据是谁上传的，在reader真正读取的时候会出现错误。<br>这符合联邦学习的“初心”，各方相互不信任，但是有FATE做第三方做担保，没有人的数据会被泄露。<a href="">没有看懂？这篇博客我详细讲了这一点。</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pipeline.component <span class="keyword">import</span> Reader, DataTransform, HeteroSecureBoost, Evaluation</span><br><span class="line"><span class="keyword">from</span> pipeline.interface <span class="keyword">import</span> Data</span><br><span class="line"><span class="comment"># set pipeline operation party ids.</span></span><br><span class="line">pipeline = PipeLine() \</span><br><span class="line">        .set_initiator(role=<span class="string">&#x27;guest&#x27;</span>, party_id=<span class="number">9999</span>) \</span><br><span class="line">        .set_roles(guest=<span class="number">9999</span>)<span class="comment">#, host=10000) 不需要加入其他host</span></span><br><span class="line"></span><br><span class="line">reader_0 = Reader(name=<span class="string">&quot;reader_0&quot;</span>)</span><br><span class="line"><span class="comment"># bind reader operation tables</span></span><br><span class="line">reader_0.get_party_instance(role=<span class="string">&#x27;guest&#x27;</span>, party_id=<span class="number">9999</span>).component_param(</span><br><span class="line">    table=&#123;<span class="string">&quot;name&quot;</span>: <span class="string">&quot;dummy&quot;</span>, <span class="string">&quot;namespace&quot;</span>: <span class="string">&quot;dummy&quot;</span>&#125;)</span><br><span class="line"></span><br><span class="line">data_transform_0 = DataTransform(name=<span class="string">&quot;data_transform_0&quot;</span>)</span><br><span class="line"><span class="comment"># bind transformation operation party</span></span><br><span class="line">data_transform_0.get_party_instance(role=<span class="string">&#x27;guest&#x27;</span>, party_id=<span class="number">9999</span>).component_param(</span><br><span class="line">    with_label=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># state a boost tree and evaluation</span></span><br><span class="line">hetero_secureboost_0 = HeteroSecureBoost(name=<span class="string">&quot;hetero_secureboost_0&quot;</span>,</span><br><span class="line">                                         num_trees=<span class="number">5</span>,</span><br><span class="line">                                         bin_num=<span class="number">16</span>,</span><br><span class="line">                                         task_type=<span class="string">&quot;classification&quot;</span>,</span><br><span class="line">                                         objective_param=&#123;<span class="string">&quot;objective&quot;</span>: <span class="string">&quot;cross_entropy&quot;</span>&#125;,</span><br><span class="line">                                         encrypt_param=&#123;<span class="string">&quot;method&quot;</span>: <span class="string">&quot;paillier&quot;</span>&#125;,</span><br><span class="line">                                         tree_param=&#123;<span class="string">&quot;max_depth&quot;</span>: <span class="number">3</span>&#125;)</span><br><span class="line">evaluation_0 = Evaluation(name=<span class="string">&quot;evaluation_0&quot;</span>, eval_type=<span class="string">&quot;binary&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># add everyone into pipeline and ready for training</span></span><br><span class="line">pipeline.add_component(reader_0)</span><br><span class="line">pipeline.add_component(data_transform_0,data=Data(train_data=reader_0.output.data))</span><br><span class="line">pipeline.add_component(hetero_secureboost_0, data=Data(train_data=data_transform_0.output.data))</span><br><span class="line">pipeline.add_component(evaluation_0, data=Data(data=hetero_secureboost_0.output.data))</span><br><span class="line">pipeline.<span class="built_in">compile</span>()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># training</span></span><br><span class="line">pipeline.fit()</span><br><span class="line"></span><br><span class="line"><span class="comment"># load another dataset via predict_pipeline</span></span><br><span class="line"><span class="comment"># predict_pipeline.predict()</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># save results</span></span><br><span class="line">pipeline.dump(<span class="string">&quot;pipeline_saved.pkl&quot;</span>)</span><br></pre></td></tr></table></figure><ul><li><p>如何查看取出的数据具体是什么？在fate board里面能够看到。<a href="https://yonggie.blog.csdn.net/article/details/129282301">怎么使用fate board？</a>。</p></li><li><p>如果训练失败了，怎么处理？python会提示，可以用fate board看日志。<a href="https://yonggie.blog.csdn.net/article/details/129282301">怎么使用fate board？</a>。</p></li></ul><p>对于一个pipeline可以通过dump把所有信息保存到pkl中。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>FATE联邦学习centos成功部署步骤</title>
      <link href="/2023/02/27/FATE%E5%AE%89%E8%A3%85/"/>
      <url>/2023/02/27/FATE%E5%AE%89%E8%A3%85/</url>
      
        <content type="html"><![CDATA[<p>官方文档：<a href="https://fate.readthedocs.io/en/latest/deploy/standalone-deploy/#1-description。">https://fate.readthedocs.io/en/latest/deploy/standalone-deploy/#1-description。</a></p><p>我用的文档中的Standalone的第二种安装方式，没用docker。</p><h1 id="安装过程"><a href="#安装过程" class="headerlink" title="安装过程"></a>安装过程</h1><p>文档上写着确定版本<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export version=1.7.0</span><br></pre></td></tr></table></figure><br><strong>但是你别真的用1.7.0啊！</strong> ，1.7.0已经是很老的版本了……<br>不然巨坑（我已经亲身经历过了，悲）。<br>首先要查一查现在比较新的版本是什么，目前2023年2月我查到的比较新的是1.10.0。<br>所以我<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export version=1.10.0</span><br></pre></td></tr></table></figure><br>获得安装包，解压<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">wget https://webank-ai-1251170195.cos.ap-guangzhou.myqcloud.com/fate/$&#123;version&#125;/release/standalone_fate_install_$&#123;version&#125;_release.tar.gz;</span><br><span class="line">tar -xzvf standalone_fate_install_$&#123;version&#125;_release.tar.gz</span><br><span class="line"></span><br></pre></td></tr></table></figure><br>然后init一下，安装。<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd standalone_fate_install_$&#123;version&#125;_release;</span><br><span class="line">bash bin/init.sh init</span><br></pre></td></tr></table></figure><br>安装后出现<br><img src="https://img-blog.csdnimg.cn/d60235f9b31c4005b427bc2de59c38d0.png" alt="在这里插入图片描述"></p><p>但是我这里除了这个，还有一些fail的任务，暂时不管他。</p><p>然后检查下<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bash bin/init.sh status</span><br></pre></td></tr></table></figure><br>输出一些config和运行状态，看到确实没有启动。</p><p>然后启动<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bash bin/init.sh start</span><br></pre></td></tr></table></figure><br>会经过许多许多的<code>check process by http port and grpt port</code><br>最后输出的<code>service start successfully</code>。<br><strong>但是他可能在前面先输出failed，后面还会输出success……</strong><br>检查一下吧，我是没有出现fail</p><p>然后执行官方文档的testing<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">flow test toy -gid 10000 -hid 10000</span><br></pre></td></tr></table></figure><br>如果不成功，会返回<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;retcode&quot;: 100,</span><br><span class="line">    &quot;retmsg&quot;: &quot;Connection refused, Please check if the fate flow service is started&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>或者torch出现错误或者其他python包或者库出现错误。<br>我自己是出现了<code>module ‘lib‘ has no attribute ‘OpenSSL_add_all_algorithms‘</code>，是由于cryptography包太新了，降一下级，我参考了<a href="https://blog.csdn.net/m0_67425175/article/details/129124597#:~:text=module%20%E2%80%98lib%E2%80%99%20has%20no%20attribute,%27OpenSSL_add_all_algorithms%E2%80%99%E5%87%BA%E7%8E%B0%E8%BF%99%E4%B8%AA%E9%97%AE%E9%A2%98%E6%98%AF%E5%9B%A0%E4%B8%BA%E4%BD%A0%E8%AF%B4%E5%AE%89%E8%A3%85%E7%9A%84%20cryptography%E5%BA%93%E4%B8%8E%E4%BD%A0%E7%8E%B0%E5%9C%A8%E7%9A%84%E4%BD%BF%E7%94%A8%E7%9A%84%E7%8E%AF%E5%A2%83%E4%B8%8D%E5%85%BC%E5%AE%B9%E5%AF%BC%E8%87%B4%E7%9A%84%EF%BC%8C%E5%8F%AF%E8%83%BD%E6%98%AF%E5%9B%A0%E4%B8%BAcryptography%E7%9A%84%E7%89%88%E6%9C%AC%E5%A4%AA%E9%AB%98%EF%BC%8C%E9%9C%80%E8%A6%81%E8%BF%9B%E8%A1%8C%E9%99%8D%E7%BA%A7%20pip%20install%20cryptography%3D%3D38.0.4">这个</a>，成功运行了<code>toy test</code><br>成功后会返回这样<br><img src="https://img-blog.csdnimg.cn/349d5d871d584305a08c20cf3f257ca1.png" alt="在这里插入图片描述"></p><p>这样FATE框架就启动起来了。</p><p>下一篇再教一下使用Python进行框架的开发。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>windows右键添加“使用vscode打开”</title>
      <link href="/2023/02/22/win%E5%8F%B3%E9%94%AE%E6%B7%BB%E5%8A%A0vscode%E6%89%93%E5%BC%80/"/>
      <url>/2023/02/22/win%E5%8F%B3%E9%94%AE%E6%B7%BB%E5%8A%A0vscode%E6%89%93%E5%BC%80/</url>
      
        <content type="html"><![CDATA[<ol><li>新建xx.reg文件并用文本编辑器打开复制下方文本 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">Windows Registry Editor Version 5.00</span><br><span class="line"></span><br><span class="line">[HKEY_CLASSES_ROOT\*\shell\VSCode]</span><br><span class="line">@=&quot;Open with Code&quot;</span><br><span class="line">&quot;Icon&quot;=&quot;E:\\Microsoft VS Code\\Code.exe&quot;</span><br><span class="line"></span><br><span class="line">[HKEY_CLASSES_ROOT\*\shell\VSCode\command]</span><br><span class="line">@=&quot;\&quot;E:\\Microsoft VS Code\\Code.exe\&quot; \&quot;%1\&quot;&quot;</span><br><span class="line"></span><br><span class="line">Windows Registry Editor Version 5.00</span><br><span class="line"></span><br><span class="line">[HKEY_CLASSES_ROOT\Directory\shell\VSCode]</span><br><span class="line">@=&quot;Open with Code&quot;</span><br><span class="line">&quot;Icon&quot;=&quot;E:\\Microsoft VS Code\\Code.exe&quot;</span><br><span class="line"></span><br><span class="line">[HKEY_CLASSES_ROOT\Directory\shell\VSCode\command]</span><br><span class="line">@=&quot;\&quot;E:\\Microsoft VS Code\\Code.exe\&quot; \&quot;%V\&quot;&quot;</span><br><span class="line"></span><br><span class="line">Windows Registry Editor Version 5.00</span><br><span class="line"></span><br><span class="line">[HKEY_CLASSES_ROOT\Directory\Background\shell\VSCode]</span><br><span class="line">@=&quot;Open with Code&quot;</span><br><span class="line">&quot;Icon&quot;=&quot;E:\\Microsoft VS Code\\Code.exe&quot;</span><br><span class="line"></span><br><span class="line">[HKEY_CLASSES_ROOT\Directory\Background\shell\VSCode\command]</span><br><span class="line">@=&quot;\&quot;E:\\Microsoft VS Code\\Code.exe\&quot; \&quot;%V\&quot;&quot;</span><br><span class="line"></span><br></pre></td></tr></table></figure></li><li>把所有路径替换成你的路径</li><li>保存后双击运行，一路确定即可完成。</li></ol>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>T-SNE PCA UMAP的降维可视化比较</title>
      <link href="/2022/11/03/tsne/"/>
      <url>/2022/11/03/tsne/</url>
      
        <content type="html"><![CDATA[<h1 id="T-SNE"><a href="#T-SNE" class="headerlink" title="T-SNE"></a>T-SNE</h1><p><a href="https://github.com/CannyLab/tsne-cuda">2017年 tsne cuda</a><br><a href="https://gitee.com/chixiangbo/tsne-cuda">gitee tsne cuda</a><br><a href="https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html">sklearn api</a></p><p>根据以上的已经集成好的api，有以下示例：<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.manifold <span class="keyword">import</span> TSNE</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># Random state.</span></span><br><span class="line">RS = <span class="number">20150101</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"> </span><br><span class="line">X = np.random.rand(<span class="number">100</span>,<span class="number">20</span>)</span><br><span class="line">y = np.random.randint(<span class="number">0</span>,<span class="number">10</span>,<span class="number">100</span>)</span><br><span class="line">reduced_x = TSNE(random_state=RS).fit_transform(X)</span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">8</span>, <span class="number">8</span>))</span><br><span class="line"><span class="comment"># ax = plt.subplot(aspect=&#x27;equal&#x27;)</span></span><br><span class="line">sc = plt.scatter(reduced_x[:,<span class="number">0</span>], reduced_x[:,<span class="number">1</span>],c=y)<span class="comment">#,cmap=&#x27;Spectral&#x27;)#, lw=0, s=40)</span></span><br><span class="line"><span class="comment"># plt.xlim(-25, 25)</span></span><br><span class="line"><span class="comment"># plt.ylim(-25, 25)</span></span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line"><span class="comment"># ax.axis(&#x27;tight&#x27;)</span></span><br><span class="line">plt.savefig(<span class="string">&#x27;tsne-generated.png&#x27;</span>, dpi=<span class="number">120</span>)</span><br><span class="line"><span class="comment"># plt.show()</span></span><br></pre></td></tr></table></figure><br>可以得到<br><img src="https://img-blog.csdnimg.cn/7de8eb69467648659e9173f68fcd80e7.png" alt="在这里插入图片描述"></p><h1 id="PCA降维"><a href="#PCA降维" class="headerlink" title="PCA降维"></a>PCA降维</h1><h1 id="UMAP降维"><a href="#UMAP降维" class="headerlink" title="UMAP降维"></a>UMAP降维</h1>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Differences between Knowledge Graph and Graph Neural Network</title>
      <link href="/2022/10/18/difference_KG_GNN/"/>
      <url>/2022/10/18/difference_KG_GNN/</url>
      
        <content type="html"><![CDATA[<p>参考：<a href="https://www.bilibili.com/video/BV16u411z7ss/">https://www.bilibili.com/video/BV16u411z7ss/</a></p><p><img src="https://img-blog.csdnimg.cn/f50527c575e8424eba4273034e99d7eb.png" alt="在这里插入图片描述"></p><h1 id="区别"><a href="#区别" class="headerlink" title="区别"></a>区别</h1><p>对于GNN：</p><ul><li><strong>目的</strong>是representation learning表示学习，目的是对图中每个节点进行向量表示；</li><li><strong>应用场景</strong>是极度稀疏、残缺、规模庞大的图结构数据</li><li><strong>解决方式</strong>是通过更好的表示学习后，进行节点向量的距离度量。</li></ul><p>对于知识图谱：</p><ul><li><strong>目的</strong>是为了<strong>知识推理</strong>，对知识进行建模，而非实体，形成能够迁移的知识表示体系</li><li><strong>场景</strong>是具有可解释性的知识<strong>推理</strong>，多目标优化求解</li><li><strong>解决方式</strong>是取样path或者子图优化。</li></ul><h1 id="联系"><a href="#联系" class="headerlink" title="联系"></a>联系</h1><p>都是图形数据结构，都需要吸取边信息进行推断/预测。</p>]]></content>
      
      
      
        <tags>
            
            <tag> knowledge graph, graph neural network </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Differences between Knowledge Graph and Graph Neural Network</title>
      <link href="/2022/10/18/graph_dataset/"/>
      <url>/2022/10/18/graph_dataset/</url>
      
        <content type="html"><![CDATA[<ul><li><p><a href="https://blog.csdn.net/weixin_39373480/article/details/88742200?spm=1001.2101.3001.6650.1&amp;utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1-88742200-blog-93374216.pc_relevant_3mothn_strategy_recovery&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1-88742200-blog-93374216.pc_relevant_3mothn_strategy_recovery&amp;utm_relevant_index=2#3__58">cora</a>，文献数据集，共2708个节点，每个节点是文献。5429条边</p></li><li><p>(citeseer)[<a href="https://linqs-data.soe.ucsc.edu/public/lbc/citeseer.tgz]，3312个节点，4732条边，可用于分类">https://linqs-data.soe.ucsc.edu/public/lbc/citeseer.tgz]，3312个节点，4732条边，可用于分类</a></p></li><li><p><a href="http://snap.stanford.edu/graphsage/ppi.zip">PPI</a>，蛋白与蛋白数据集，PPI数据集共24张图，每张图对应不同的人体组织，平均每张图有2371个节点，共56944个节点818716条边，每个节点特征长度为50，其中包含位置基因集，基序集和免疫学特征。基因本体基作为label(总共121个)，label不是one-hot编码。</p></li></ul><h1 id="“大”数据集"><a href="#“大”数据集" class="headerlink" title="“大”数据集"></a>“大”数据集</h1><ul><li><a href="https://paperswithcode.com/dataset/reddit">Reddit</a> In total this dataset contains 232,965 posts with an average degree of 492.</li></ul><p>更多可参考 <a href="https://blog.csdn.net/w55100/article/details/115911550">https://blog.csdn.net/w55100/article/details/115911550</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> graph learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>中文近义短语合并实验</title>
      <link href="/2022/10/11/chinese_sentence_sim/"/>
      <url>/2022/10/11/chinese_sentence_sim/</url>
      
        <content type="html"><![CDATA[<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>最近要做一个文本到graph的数据集，里面有不少不同字但同义的小文本段，想简单用文本相似度的方式把他们归到一类里面。</p><h1 id="方式"><a href="#方式" class="headerlink" title="方式"></a>方式</h1><ol><li>直接调用hanlp的sentence sim，帮忙解决</li><li>用中文transformer做sentence embedding，后用距离函数设定阈值解决。</li><li>直接用hugging face的transformer的高级api，也是直接端到端帮忙解决。</li></ol><h1 id="Hanlp"><a href="#Hanlp" class="headerlink" title="Hanlp"></a>Hanlp</h1><p>根据<a href="https://github.com/hankcs/HanLP/blob/doc-zh/plugins/hanlp_demo/hanlp_demo/zh/sts_stl.ipynb">这里</a>，<code>pip install hanlp</code>后，直接<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> hanlp</span><br><span class="line">sts = hanlp.load(hanlp.pretrained.sts.STS_ELECTRA_BASE_ZH)</span><br><span class="line"></span><br><span class="line">sentence_list=make_sentence_list()</span><br><span class="line"><span class="comment"># sentence_list=[</span></span><br><span class="line"><span class="comment">#     (&#x27;看图猜一电影名&#x27;, &#x27;看图猜电影&#x27;),</span></span><br><span class="line"><span class="comment">#     (&#x27;无线路由器怎么无线上网&#x27;, &#x27;无线上网卡和无线路由器怎么用&#x27;),</span></span><br><span class="line"><span class="comment">#     (&#x27;北京到上海的动车票&#x27;, &#x27;上海到北京的动车票&#x27;),</span></span><br><span class="line"><span class="comment"># ]</span></span><br><span class="line">res=sts(sentence_list)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(res)</span><br></pre></td></tr></table></figure></p><p>该说不说，我一共才1k左右个小句子，共$C_{1900}^2$个，inference竟然用时58.48093847433726分钟，太慢了！！</p><h1 id="transformer-end2end"><a href="#transformer-end2end" class="headerlink" title="transformer end2end"></a>transformer end2end</h1><p><code>pip install transformer</code>后，<br>本来想偷懒直接用pipeline的，<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModelForTokenClassification,AutoTokenizer,pipeline</span><br><span class="line">model_id=<span class="string">&#x27;uer/sbert-base-chinese-nli&#x27;</span></span><br><span class="line">scorer=pipeline(<span class="string">&quot;sentence-similarity&quot;</span>,model=model_id)</span><br></pre></td></tr></table></figure><br>但是报错，嘻嘻：<br><code>&quot;Unknown task sentence-similarity, available tasks are [&#39;audio-classification&#39;, &#39;automatic-speech-recognition&#39;, &#39;conversational&#39;, &#39;document-question-answering&#39;, &#39;feature-extraction&#39;, &#39;fill-mask&#39;, &#39;image-classification&#39;, &#39;image-segmentation&#39;, &#39;image-to-text&#39;, &#39;ner&#39;, &#39;object-detection&#39;, &#39;question-answering&#39;, &#39;sentiment-analysis&#39;, &#39;summarization&#39;, &#39;table-question-answering&#39;, &#39;text-classification&#39;, &#39;text-generation&#39;, &#39;text2text-generation&#39;, &#39;token-classification&#39;, &#39;translation&#39;, &#39;visual-question-answering&#39;, &#39;vqa&#39;, &#39;zero-shot-classification&#39;, &#39;zero-shot-image-classification&#39;, &#39;translation_XX_to_YY&#39;]&quot;</code><br>行吧，再偷懒下，看看能不能autotokenizer和automodel解决。</p><p>根据我的<a href="https://yonggie.github.io/2022/10/11/huggingface_transformer_real_quickstart/">这篇教程</a>，找到对应任务后选择model id。<br>找到后，只有两个模型……好家伙，够少的。怎么连个example也没有……<br><img src="https://img-blog.csdnimg.cn/fe47ba1ff779430d98d1f07316698603.png" alt="在这里插入图片描述"><br>随便选择一个，然后看下其他语言的sentence similarity的example：<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> scipy.spatial.distance <span class="keyword">import</span> cosine</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModel, AutoTokenizer</span><br><span class="line"></span><br><span class="line"><span class="comment"># Load the model</span></span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(<span class="string">&quot;johngiorgi/declutr-small&quot;</span>)</span><br><span class="line">model = AutoModel.from_pretrained(<span class="string">&quot;johngiorgi/declutr-small&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Prepare some text to embed</span></span><br><span class="line">text = [</span><br><span class="line">    <span class="string">&quot;A smiling costumed woman is holding an umbrella.&quot;</span>,</span><br><span class="line">    <span class="string">&quot;A happy woman in a fairy costume holds an umbrella.&quot;</span>,</span><br><span class="line">]</span><br><span class="line">inputs = tokenizer(text, padding=<span class="literal">True</span>, truncation=<span class="literal">True</span>, return_tensors=<span class="string">&quot;pt&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Embed the text</span></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    sequence_output = model(**inputs)[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Mean pool the token-level embeddings to get sentence-level embeddings</span></span><br><span class="line">embeddings = torch.<span class="built_in">sum</span>(</span><br><span class="line">    sequence_output * inputs[<span class="string">&quot;attention_mask&quot;</span>].unsqueeze(-<span class="number">1</span>), dim=<span class="number">1</span></span><br><span class="line">) / torch.clamp(torch.<span class="built_in">sum</span>(inputs[<span class="string">&quot;attention_mask&quot;</span>], dim=<span class="number">1</span>, keepdims=<span class="literal">True</span>), <span class="built_in">min</span>=<span class="number">1e-9</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Compute a semantic similarity via the cosine distance</span></span><br><span class="line">semantic_sim = <span class="number">1</span> - cosine(embeddings[<span class="number">0</span>], embeddings[<span class="number">1</span>])</span><br><span class="line"></span><br></pre></td></tr></table></figure></p><p>woc，明面上写的是end2end，结果还是只返回sentence embedding……<br><strong>根本是假的端到端……</strong></p><h1 id="transformer-sentence-embedding"><a href="#transformer-sentence-embedding" class="headerlink" title="transformer sentence embedding"></a>transformer sentence embedding</h1><p>既然是假的端到端，那没必要选择特定task的model了。<br>例子上一部分已经给出来了，很棒！换个model id就行了，看看？<br><img src="https://img-blog.csdnimg.cn/2944ceb230cf4fc6add2c5af96e9d1a2.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/24e6fd72e857482180b8b01da8140d11.png" alt="在这里插入图片描述"><br>有那么点意思哈，把阈值放低些可以看看。<br>到此，处理部分就结束了。<br>接下来就是人工设置阈值，合并了。</p><h1 id="最后附处理的代码"><a href="#最后附处理的代码" class="headerlink" title="最后附处理的代码"></a>最后附处理的代码</h1><h2 id="hanlp"><a href="#hanlp" class="headerlink" title="hanlp"></a>hanlp</h2><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> hanlp</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> itertools <span class="keyword">import</span> combinations</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">make_sentence_list</span>():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;making sentence pair, waiting...&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">    node_storage=pickle.load(<span class="built_in">open</span>(<span class="string">&#x27;path.pkl&#x27;</span>,<span class="string">&#x27;rb&#x27;</span>))</span><br><span class="line">    syndromes=node_storage[<span class="string">&#x27;syndrome&#x27;</span>]</span><br><span class="line">    sentence_list=[]</span><br><span class="line">    <span class="keyword">for</span> sentence_pair <span class="keyword">in</span> combinations(syndromes,<span class="number">2</span>):</span><br><span class="line">        sentence_list.append(sentence_pair)</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;pairs prepared&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> sentence_list</span><br><span class="line"></span><br><span class="line">scorer = hanlp.load(hanlp.pretrained.sts.STS_ELECTRA_BASE_ZH)</span><br><span class="line"></span><br><span class="line">sentence_list=make_sentence_list()</span><br><span class="line"><span class="comment"># sentence_list=[</span></span><br><span class="line"><span class="comment">#     (&#x27;看图猜一电影名&#x27;, &#x27;看图猜电影&#x27;),</span></span><br><span class="line"><span class="comment">#     (&#x27;无线路由器怎么无线上网&#x27;, &#x27;无线上网卡和无线路由器怎么用&#x27;),</span></span><br><span class="line"><span class="comment">#     (&#x27;北京到上海的动车票&#x27;, &#x27;上海到北京的动车票&#x27;),</span></span><br><span class="line"><span class="comment"># ]</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;inferencing...&#x27;</span>)</span><br><span class="line">T1 = time.time()</span><br><span class="line">res=scorer(sentence_list)</span><br><span class="line">T2=time.time()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;inference done, time:<span class="subst">&#123;(T2-T1)/<span class="number">60</span>&#125;</span>min&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(res)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="transformer-sentence-embedding-1"><a href="#transformer-sentence-embedding-1" class="headerlink" title="transformer sentence embedding"></a>transformer sentence embedding</h2><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> itertools <span class="keyword">import</span> combinations</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModel, AutoTokenizer</span><br><span class="line"></span><br><span class="line"><span class="comment"># Load the model</span></span><br><span class="line">model_id=<span class="string">&#x27;bert-base-chinese&#x27;</span></span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(model_id)</span><br><span class="line"></span><br><span class="line">model = AutoModel.from_pretrained(model_id)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Prepare some text to embed</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">make_sentence_list</span>():</span><br><span class="line">    </span><br><span class="line">    node_storage=pickle.load(<span class="built_in">open</span>(<span class="string">&#x27;path.pkl&#x27;</span>,<span class="string">&#x27;rb&#x27;</span>))</span><br><span class="line">    syndromes=<span class="built_in">sorted</span>(<span class="built_in">list</span>(node_storage[<span class="string">&#x27;syndrome&#x27;</span>]))</span><br><span class="line">    <span class="comment"># sentence_list=[]</span></span><br><span class="line">    <span class="comment"># for sentence_pair in combinations(syndromes,2):</span></span><br><span class="line">    <span class="comment">#     sentence_list.append(sentence_pair)</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> syndromes</span><br><span class="line"></span><br><span class="line">text = make_sentence_list()</span><br><span class="line">input_data = tokenizer(text, padding=<span class="literal">True</span>, truncation=<span class="literal">True</span>, return_tensors=<span class="string">&quot;pt&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Embed the text</span></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    sequence_output = model(**input_data)[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Mean pool the token-level embeddings to get sentence-level embeddings</span></span><br><span class="line">embeddings = torch.<span class="built_in">sum</span>(</span><br><span class="line">    sequence_output * input_data[<span class="string">&quot;attention_mask&quot;</span>].unsqueeze(-<span class="number">1</span>), dim=<span class="number">1</span></span><br><span class="line">) / torch.clamp(torch.<span class="built_in">sum</span>(input_data[<span class="string">&quot;attention_mask&quot;</span>], dim=<span class="number">1</span>, keepdims=<span class="literal">True</span>), <span class="built_in">min</span>=<span class="number">1e-9</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Compute a semantic similarity via the cosine distance</span></span><br><span class="line"><span class="comment"># coss = torch.cosine_similarity(embeddings.unsqueeze(1),embeddings.unsqueeze(0),dim=-1)</span></span><br><span class="line">idxs=<span class="built_in">list</span>(<span class="built_in">range</span>(<span class="built_in">len</span>(embeddings)))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;calculating cosine similarity...&#x27;</span>)</span><br><span class="line">T1 = time.time()</span><br><span class="line">sentence_pair2cos=&#123;&#125;</span><br><span class="line"><span class="keyword">for</span> idx1,idx2 <span class="keyword">in</span> combinations(idxs,<span class="number">2</span>):</span><br><span class="line">    cos=torch.cosine_similarity(embeddings[idx1].unsqueeze(<span class="number">0</span>),embeddings[idx2].unsqueeze(<span class="number">0</span>)).item()</span><br><span class="line">    sentence_pair2cos[(text[idx1],text[idx2])]=cos</span><br><span class="line">T2=time.time()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;time:<span class="subst">&#123;T2-T1&#125;</span>sec\n\nSaving similarity as dict&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 太多、太慢。</span></span><br><span class="line"><span class="comment"># with open(&#x27;sentence_sim.dict&#x27;,&#x27;w&#x27;) as f:</span></span><br><span class="line"><span class="comment">#     f.write(&#x27;&#123;\n&#x27;)</span></span><br><span class="line"><span class="comment">#     for k,v in sentence_pair2cos.items():</span></span><br><span class="line"><span class="comment">#         f.write(f&quot;&#123;k&#125;:&#123;v&#125;,\n&quot;)</span></span><br><span class="line"><span class="comment">#     f.write(&#x27;&#125;\n&#x27;)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;sentence_sim_dict.pkl&#x27;</span>,<span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    pickle.dump(sentence_pair2cos,f)</span><br><span class="line"><span class="comment"># print(coss.shape)</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>huggingface real quickstart</title>
      <link href="/2022/10/10/huggingface_transformer_real_quickstart/"/>
      <url>/2022/10/10/huggingface_transformer_real_quickstart/</url>
      
        <content type="html"><![CDATA[<h1 id="tokenizer"><a href="#tokenizer" class="headerlink" title="tokenizer"></a>tokenizer</h1><p>对于sentence要先分词，对每个词做一个word embedding，这个过程叫tokenize，所以用tokenizer这个类。</p><p>那对于中文来说，选用什么tokenizer好？<br>可以见<a href="https://github.com/lonePatient/awesome-pretrained-chinese-nlp-models">https://github.com/lonePatient/awesome-pretrained-chinese-nlp-models</a></p><p>假定我要用<code>nlptown/bert-base-multilingual-uncased-sentiment</code>这个模型，则<code>from_pretrain</code>是很重要的方法，你需要传入一个mode id来确定tokenizer的适配的模型。<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer</span><br><span class="line"></span><br><span class="line">model_name = <span class="string">&quot;nlptown/bert-base-multilingual-uncased-sentiment&quot;</span></span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(model_name)</span><br><span class="line">encoding = tokenizer(<span class="string">&quot;We are very happy to show you the 🤗 Transformers library.&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(encoding)</span><br></pre></td></tr></table></figure></p><p>那如何确定选用的model是否在huggingface的transformer库里面？<a href="https://huggingface.co/docs/transformers/v4.22.2/en/model_doc/auto#transformers.AutoTokenizer.from_pretrained.pretrained_model_name_or_path">可详见这里</a><br><img src="https://img-blog.csdnimg.cn/5e90887ff51a4beabca663284031a105.png" alt="在这里插入图片描述">对于<code>model id</code>，去huggingface documentation，界面中<br><img src="https://img-blog.csdnimg.cn/2ff024ae7128472097b46fcaabaa55a4.png" alt="在这里插入图片描述">就可以找得到<code>model id</code>了，点开后左侧有各种选项，太全了，他真的，我哭死……<br><img src="https://img-blog.csdnimg.cn/d2087de320d645a999c0608353c3470a.png" alt="在这里插入图片描述"></p><h1 id="中文tokenizer"><a href="#中文tokenizer" class="headerlink" title="中文tokenizer"></a>中文tokenizer</h1><p>以<code>ckiplab/albert-base-chinese-ner</code>为例</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AlbertTokenizer,AlbertModel,AutoTokenizer</span><br><span class="line"></span><br><span class="line">tokenizer=AutoTokenizer.from_pretrained(<span class="string">&#x27;ckiplab/albert-base-chinese-ner&#x27;</span>)</span><br><span class="line">encoding=tokenizer.encode(<span class="string">&#x27;我草你是真的牛逼&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(encoding)</span><br><span class="line"><span class="built_in">print</span>(tokenizer.decode(encoding))</span><br></pre></td></tr></table></figure><p>输出<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[101, 2769, 5770, 872, 3221, 4696, 4638, 4281, 6873, 102]</span><br><span class="line">[CLS] 我 草 你 是 真 的 牛 逼 [SEP]</span><br></pre></td></tr></table></figure><br>可以看到每个词对应了vocab里面的一个id，整个句子已经被tokenize了。（中文里不一定一个id都只对应一个字哦，也可能一个id对应2个字。）</p><h1 id="model"><a href="#model" class="headerlink" title="model"></a>model</h1><p>选定任务（从左侧的tag里面）后，类似的，model里面也有<code>AutoModel+任务名称</code>类，也是调用from_pretrain，model id写一样的就可以了。<br>以NER任务为例，左边tag的名字叫TokenClassification，导入<code>AutoModelForTokenClassification</code>，然后<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">sentence=<span class="string">&#x27;舌质淡红，苔薄白，右侧瘀斑较淡。&#x27;</span></span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModelForTokenClassification,AutoTokenizer</span><br><span class="line"></span><br><span class="line">tokenizer=AutoTokenizer.from_pretrained(<span class="string">&#x27;ckiplab/albert-base-chinese-ner&#x27;</span>)</span><br><span class="line">encoding=tokenizer(<span class="string">&#x27;舌质淡红，苔薄白，右侧瘀斑较淡。&#x27;</span>,return_tensors=<span class="string">&#x27;pt&#x27;</span>)</span><br><span class="line"></span><br><span class="line">model = AutoModelForTokenClassification.from_pretrained(<span class="string">&quot;ckiplab/albert-base-chinese-ner&quot;</span>)</span><br><span class="line">results=model(**encoding)</span><br><span class="line"><span class="built_in">print</span>(results)</span><br></pre></td></tr></table></figure></p><p>注意tokenizer和model的<code>from_pretrain</code>的<code>model id</code>参数要对应一致。</p><p>from_pretrained下载的东西在哪里？<br>linux上，在<code>/home/yourname/.cache/torch/transformers</code>，所以如果网络不好，可以手动下载后放入那里。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Chinese Segment Tools in 2022(2022年的中文分词工具)</title>
      <link href="/2022/09/18/chinese_seg/"/>
      <url>/2022/09/18/chinese_seg/</url>
      
        <content type="html"><![CDATA[<h1 id="Hanlp"><a href="#Hanlp" class="headerlink" title="Hanlp"></a><a href="https://github.com/hankcs/HanLP/tree/doc-zh">Hanlp</a></h1><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install hanlp</span><br></pre></td></tr></table></figure><p>后<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> hanlp</span><br><span class="line">hanlp.pretrained.tok.ALL </span><br><span class="line">tok = hanlp.load(hanlp.pretrained.tok.COARSE_ELECTRA_SMALL_ZH)</span><br><span class="line">res=tok(sentence)</span><br><span class="line"><span class="built_in">print</span>(res)</span><br></pre></td></tr></table></figure><br>其实更多文档在(这个链接)[<a href="https://github.com/hankcs/HanLP/tree/doc-zh]里有，这是十分强大的工具，并且已经商业化。">https://github.com/hankcs/HanLP/tree/doc-zh]里有，这是十分强大的工具，并且已经商业化。</a></p><p>python3.8以下使用<a href="https://pypi.org/project/pyhanlp/">这个</a><br>根据官方文档下载，<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">conda install -c conda-forge openjdk python=3.8 jpype1=0.7.0 -y</span><br><span class="line">pip install pyhanlp</span><br></pre></td></tr></table></figure><br>后可以使用<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyhanlp <span class="keyword">import</span> *</span><br><span class="line">sentence=<span class="string">&#x27;我草你是真的牛批&#x27;</span></span><br><span class="line">res=HanLP.segment(sentence)</span><br><span class="line"><span class="built_in">print</span>(res)</span><br></pre></td></tr></table></figure></p><h1 id="paddlepaddle"><a href="#paddlepaddle" class="headerlink" title="paddlepaddle"></a>paddlepaddle</h1><p>paddlepaddle的hub里面有很多中文分词模型，见<a href="https://blog.csdn.net/qq_42067550/article/details/106026629">这里</a></p><p>其实这样看torch社区和tensorflow社区也有很多hub的模型可以使用。</p><h1 id="stanza"><a href="#stanza" class="headerlink" title="stanza"></a>stanza</h1><p>是斯坦福CoreNLP的继承，安装和使用相对麻烦，见<a href="https://blog.csdn.net/shenliang1985/article/details/103509258">这里</a></p><h1 id="fenci"><a href="#fenci" class="headerlink" title="fenci"></a><a href="https://github.com/a358003542/fenci">fenci</a></h1><p>git clone下就可以使用，十分轻量级，是jieba的升级版和继承项目。<br><a href="https://github.com/fxsjy/jieba/issues/957">jieba项目“已死”</a><br>但是fenci只能分词，没有词性标注等功能。</p><h1 id="pkuseg"><a href="#pkuseg" class="headerlink" title="pkuseg"></a><a href="https://github.com/lancopku/pkuseg-python#%E5%90%84%E7%B1%BB%E5%88%86%E8%AF%8D%E5%B7%A5%E5%85%B7%E5%8C%85%E7%9A%84%E6%80%A7%E8%83%BD%E5%AF%B9%E6%AF%94">pkuseg</a></h1><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip3 install pkuseg</span><br></pre></td></tr></table></figure><p>后，出现如下错误（简略）<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">Building wheels for collected packages: pkuseg</span><br><span class="line">  Building wheel for pkuseg (setup.py) ... error</span><br><span class="line">  error: subprocess-exited-with-error</span><br><span class="line">  </span><br><span class="line">  × python setup.py bdist_wheel did not run successfully.</span><br><span class="line">  │ exit code: 1</span><br><span class="line">  ╰─&gt; [208 lines of output]</span><br><span class="line">      /usr/share/anaconda3/envs/yzc_trans/lib/python3.9/site-packages/setuptools/installer.py:27: SetuptoolsDeprecationWarning: setuptools.installer is deprecated. Requirements should be satisfied by a PEP 517 installer.</span><br><span class="line">        warnings.warn(</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  </span><br><span class="line">  note: This error originates from a subprocess, and is likely not a problem with pip.</span><br><span class="line">error: legacy-install-failure</span><br><span class="line"></span><br><span class="line">× Encountered error while trying to install package.</span><br><span class="line">╰─&gt; pkuseg</span><br><span class="line"></span><br><span class="line">note: This is an issue with the package mentioned above, not pip.</span><br><span class="line">hint: See above for output from the failure.</span><br></pre></td></tr></table></figure><br>应该是老了，pip还说这是package自己的问题，不是pip的问题。那应该是是太老了。</p><h1 id="jieba"><a href="#jieba" class="headerlink" title="jieba"></a>jieba</h1><p>不赘述，太多博客了。</p><h1 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h1><p>可从(这里)[<a href="https://github.com/ysc/cws_evaluation]看到另外的分词器">https://github.com/ysc/cws_evaluation]看到另外的分词器</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Cox PH模型</title>
      <link href="/2022/09/18/cox%20PH/"/>
      <url>/2022/09/18/cox%20PH/</url>
      
        <content type="html"><![CDATA[<p>Cox PH model, 全称 proportional hazard regression model.</p><h1 id="模型假设前提"><a href="#模型假设前提" class="headerlink" title="模型假设前提"></a>模型假设前提</h1><p>PH，比例风险变量对生存率的影响不随时间的改变而改变。<br>举个例子，若以$h$预测生存概率，则$h<em>{t_i}(x)$与$h</em>{t_0}(x)$是定值。</p><h1 id="是什么"><a href="#是什么" class="headerlink" title="是什么"></a>是什么</h1><p>假设$h$是生存预测模型函数（输出t时刻生存风险），则</p><script type="math/tex; mode=display">h(t,X)=h_0(t) * exp(\sum w_ix_i)</script><p>表示特征是$X$的人在t时刻的风险。但是$h_0$是不需要求的，$h_0$除过去两边取对数</p><script type="math/tex; mode=display">ln\frac{h(t,X)}{h_0(t)}=\sum w_ix_i</script><p>其实算是一个线性回归。</p><h1 id="求解参数"><a href="#求解参数" class="headerlink" title="求解参数"></a>求解参数</h1><p>极大似然估计<br>参考：<a href="https://zhuanlan.zhihu.com/p/538476448">https://zhuanlan.zhihu.com/p/538476448</a> </p><h1 id="Metrics"><a href="#Metrics" class="headerlink" title="Metrics"></a>Metrics</h1><h2 id="CI"><a href="#CI" class="headerlink" title="CI"></a><a href="https://www.semanticscholar.org/paper/Multivariable-prognostic-models%3A-issues-in-models%2C-Harrell-Lee/a6d33daa0e093a50b1b58e3aa34191c4b5acda92">CI</a></h2><p>C-index有多种，只介绍链接那种。</p><p>concordence index $\in [0.5,1]$, 在非删失的数据中，两两组pair，#表示pair的个数。<script type="math/tex">CI=\frac{\# expectated\ pair}{\# all\ pair}</script>.</p><p>结合删失标志位$\delta$的话，<br>Given observed survival times ti, predicted risk scores ηi, and<br>censoring indicators δi, the concordance index is defined as<br>可以表示为</p><script type="math/tex; mode=display">CI=\frac{\sum_j\sum_i 1_{t_j<t_i}1_{\eta_j>\eta_i}\delta}{\sum_j\sum_i 1_{t_j<t_i}\delta}</script><p>δi is the censoring indicator: δi = 0 if the survival time of the i-th patient was censored, and δi = 1 otherwise. 0 unuseful 1 useful.</p><p>所以可见，其没有使用删失数据。<br>举个例子suppose：<br>| survival time      | predict rish | censored|CI|<br>| —————- | —————- |—————- | —————- |<br>| 4      | 0.9       |0<br>| 5   | 0.8        |1<br>| 6   | 0.7        |0</p><p>则<script type="math/tex">CI=</script></p><h2 id="REA"><a href="#REA" class="headerlink" title="REA"></a><a href="https://dl.acm.org/doi/10.5555/2986459.2986665">REA</a></h2><p>Relative absolute error,</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Dynamic Planning Series</title>
      <link href="/2022/09/02/dp/"/>
      <url>/2022/09/02/dp/</url>
      
        <content type="html"><![CDATA[<h1 id="上台阶-入门"><a href="#上台阶-入门" class="headerlink" title="上台阶(入门)"></a>上台阶(入门)</h1><h1 id="矩阵路径相关"><a href="#矩阵路径相关" class="headerlink" title="矩阵路径相关"></a>矩阵路径相关</h1><h2 id="desc"><a href="#desc" class="headerlink" title="desc"></a>desc</h2><p><a href="https://leetcode.cn/problems/unique-paths/">不同路径</a><br><a href="https://leetcode.cn/problems/unique-paths-ii/">不同路径2</a><br><a href="https://leetcode.cn/problems/minimum-path-sum/">最小路径</a><br><a href="https://leetcode.cn/problems/dungeon-game/">地下城</a></p><h2 id="idea"><a href="#idea" class="headerlink" title="idea"></a>idea</h2><p>题目以矩阵的形式给出来.<br>定义$dp[i][j]$是到达i j的最优解，那么$dp[i][j]$往往只能来自$dp[i-1][j]$和$dp[i][j-1]$，可以根据要求写出状态转移方程。<br><strong>并不都是所有矩阵形式都是这种动态规划。</strong></p><h1 id="序列相关"><a href="#序列相关" class="headerlink" title="序列相关"></a>序列相关</h1><p>提示：并不是所有字符串问题都是用dp求解，能暴力的可以先暴力一下看看。</p><h2 id="最长连续递增序列"><a href="#最长连续递增序列" class="headerlink" title="最长连续递增序列"></a><a href="https://leetcode.cn/problems/longest-continuous-increasing-subsequence/">最长连续递增序列</a></h2><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">findLengthOfLCIS</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="comment"># dp[i]是以nums[i]为最后一个元素的最长长度</span></span><br><span class="line">        dp=[<span class="number">0</span> <span class="keyword">for</span> n <span class="keyword">in</span> nums]</span><br><span class="line">        dp[<span class="number">0</span>]=<span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,<span class="built_in">len</span>(nums)):</span><br><span class="line">            <span class="keyword">if</span> nums[i]&gt;nums[i-<span class="number">1</span>]:</span><br><span class="line">                dp[i]=dp[i-<span class="number">1</span>]+<span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                dp[i]=<span class="number">1</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">max</span>(dp)</span><br></pre></td></tr></table></figure><h2 id="最长递增子序列"><a href="#最长递增子序列" class="headerlink" title="最长递增子序列"></a><a href="https://leetcode.cn/problems/longest-increasing-subsequence/">最长递增子序列</a></h2><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">lengthOfLIS</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        length=<span class="built_in">len</span>(nums)</span><br><span class="line">        dp=[<span class="number">1</span> <span class="keyword">for</span> n <span class="keyword">in</span> <span class="built_in">range</span>(length)]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(length):</span><br><span class="line">            <span class="comment"># 从前面i个里面找比nums[i]大的</span></span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i):</span><br><span class="line">                </span><br><span class="line">                <span class="keyword">if</span> nums[i]&gt;nums[j]:</span><br><span class="line">                    <span class="comment"># 可以接的很多，我要找一个最大的接进去</span></span><br><span class="line">                    dp[i]=<span class="built_in">max</span>(dp[i],dp[j]+<span class="number">1</span>)</span><br><span class="line">                </span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">max</span>(dp)</span><br></pre></td></tr></table></figure><p><a href="https://leetcode.cn/problems/increasing-triplet-subsequence/">检查游戏1</a><br><a href="https://leetcode.cn/problems/number-of-longest-increasing-subsequence/">检查游戏2</a></p><h2 id="最大子序列和"><a href="#最大子序列和" class="headerlink" title="最大子序列和"></a><a href="https://leetcode.cn/problems/lian-xu-zi-shu-zu-de-zui-da-he-lcof/">最大子序列和</a></h2><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">maxSubArray</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="comment"># dp[i]以nums[i]为结尾的最大连续和</span></span><br><span class="line">        length=<span class="built_in">len</span>(nums)</span><br><span class="line">        dp=[n <span class="keyword">for</span> n <span class="keyword">in</span> nums]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,length):    </span><br><span class="line">            <span class="comment"># 是自己独立，还是并入前面？</span></span><br><span class="line">            dp[i]=<span class="built_in">max</span>(dp[i-<span class="number">1</span>]+nums[i],dp[i])</span><br><span class="line">        <span class="comment"># 可以不需要dp数组直接用res。但是看起来方便还是保留</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">max</span>(dp)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="最长公共子序列-Longest-Common-Sub-string-LCS"><a href="#最长公共子序列-Longest-Common-Sub-string-LCS" class="headerlink" title="最长公共子序列 Longest Common Sub-string(LCS)"></a><a href="https://leetcode.cn/problems/qJnOS7/">最长公共子序列 Longest Common Sub-string(LCS)</a></h2><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">longestCommonSubsequence</span>(<span class="params">self, text1: <span class="built_in">str</span>, text2: <span class="built_in">str</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        len1=<span class="built_in">len</span>(text1)</span><br><span class="line">        len2=<span class="built_in">len</span>(text2)</span><br><span class="line">        <span class="comment"># dp[i][j]表示A串到i且B串到j时候，最长公共子序列。多出来0 0，方便初始化</span></span><br><span class="line"></span><br><span class="line">        dp=[[<span class="number">0</span> <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(len2+<span class="number">1</span>)] <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(len1+<span class="number">1</span>)]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,len1+<span class="number">1</span>):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,len2+<span class="number">1</span>):</span><br><span class="line">                <span class="comment"># 当前的ij与原字符串的i j有偏移。</span></span><br><span class="line">                <span class="keyword">if</span> text1[i-<span class="number">1</span>]==text2[j-<span class="number">1</span>]:</span><br><span class="line">                    <span class="comment"># 若相同</span></span><br><span class="line">                    dp[i][j]=dp[i-<span class="number">1</span>][j-<span class="number">1</span>]+<span class="number">1</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="comment"># 若不相同，</span></span><br><span class="line">                    dp[i][j]=<span class="built_in">max</span>(dp[i-<span class="number">1</span>][j],dp[i][j-<span class="number">1</span>])</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> dp[-<span class="number">1</span>][-<span class="number">1</span>]</span><br></pre></td></tr></table></figure><h2 id="打家劫舍（树形dp）"><a href="#打家劫舍（树形dp）" class="headerlink" title="打家劫舍（树形dp）"></a><a href="https://leetcode.cn/problems/house-robber/">打家劫舍（树形dp）</a></h2><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">rob</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(nums)==<span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> nums[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(nums)==<span class="number">2</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">max</span>(nums[<span class="number">0</span>],nums[<span class="number">1</span>])</span><br><span class="line">        <span class="comment"># dp表示此位置的最大值</span></span><br><span class="line">        dp=[<span class="number">0</span> <span class="keyword">for</span> n <span class="keyword">in</span> nums]</span><br><span class="line">        dp[<span class="number">0</span>]=nums[<span class="number">0</span>]</span><br><span class="line">        dp[<span class="number">1</span>]=<span class="built_in">max</span>(nums[<span class="number">0</span>],nums[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">        length=<span class="built_in">len</span>(nums)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>,length):</span><br><span class="line">            dp[i]=<span class="built_in">max</span>(dp[i-<span class="number">1</span>],dp[i-<span class="number">2</span>]+nums[i])</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> dp[-<span class="number">1</span>]</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><a href="https://leetcode.cn/problems/house-robber-ii/">打家劫舍2</a>:下标范围dp，后比较即可<br><a href="https://leetcode.cn/problems/house-robber-iii/">打家劫舍3</a></p><h1 id="背包"><a href="#背包" class="headerlink" title="背包"></a>背包</h1><p><a href="https://www.bilibili.com/video/BV1X741127ZM">闫氏dp分析法教程</a></p><h2 id="01背包"><a href="#01背包" class="headerlink" title="01背包"></a>01背包</h2><p>其中cap = capacity，表示背包容量，n表示物品个数。<br>定义dp数组是背包容量为W，且迭代到第i个物品时能拿到的最大价值数。</p><p>由于需要先初始化dp[0][j]和dp[i][0]，则dp数组需要多出一行一列，注意weights和values数据会下标偏移。<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">n,cap=[<span class="built_in">int</span>(n) <span class="keyword">for</span> n <span class="keyword">in</span> <span class="built_in">input</span>().strip().split()] </span><br><span class="line"><span class="comment"># cap = capacity</span></span><br><span class="line">dp=[[<span class="number">0</span> <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(cap+<span class="number">1</span>)] <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n+<span class="number">1</span>)]</span><br><span class="line"></span><br><span class="line">values,weights=[],[]</span><br><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">    w,v=[<span class="built_in">int</span>(n) <span class="keyword">for</span> n <span class="keyword">in</span> <span class="built_in">input</span>().strip().split()]</span><br><span class="line">    values.append(v)</span><br><span class="line">    weights.append(w)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,n+<span class="number">1</span>):</span><br><span class="line">    <span class="keyword">for</span> cap_now <span class="keyword">in</span> <span class="built_in">range</span>(cap+<span class="number">1</span>):</span><br><span class="line">        <span class="keyword">if</span> cap_now&gt;=weights[i-<span class="number">1</span>]:</span><br><span class="line">            <span class="comment"># 如果能拿，但是我可以选择不拿</span></span><br><span class="line">            dp[i][cap_now]=<span class="built_in">max</span>(dp[i-<span class="number">1</span>][cap_now],dp[i-<span class="number">1</span>][cap_now-weights[i-<span class="number">1</span>]]+values[i-<span class="number">1</span>])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 此时肯定拿不了</span></span><br><span class="line">            dp[i][cap_now]=dp[i-<span class="number">1</span>][cap_now]</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(dp[-<span class="number">1</span>][-<span class="number">1</span>])</span><br></pre></td></tr></table></figure><br>由于可以优化下空间和写法，所以可以：<br>注意倒序的weights和下标开始点<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cap = capacity</span></span><br><span class="line">dp=[<span class="number">0</span> <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(cap+<span class="number">1</span>)] </span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,n+<span class="number">1</span>):</span><br><span class="line">    <span class="keyword">for</span> cap_now <span class="keyword">in</span> <span class="built_in">range</span>(cap+<span class="number">1</span>)[::-<span class="number">1</span>]:</span><br><span class="line">        <span class="keyword">if</span> cap_now&gt;=weights[i-<span class="number">1</span>]:</span><br><span class="line">            <span class="comment"># 如果能拿，但是我可以选择不拿</span></span><br><span class="line">            dp[cap_now]=<span class="built_in">max</span>(dp[cap_now],dp[cap_now-weights[i-<span class="number">1</span>]]+values[i-<span class="number">1</span>])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            dp[cap_now]=dp[cap_now]</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(dp[-<span class="number">1</span>])</span><br></pre></td></tr></table></figure><br>为什么不改掉<code>if else</code>语句？因为方便记忆。</p><h2 id="完全背包"><a href="#完全背包" class="headerlink" title="完全背包"></a>完全背包</h2><p>tbd</p>]]></content>
      
      
      
        <tags>
            
            <tag> classic algorithm, data structure </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Learning Backward Compatible Embeddings</title>
      <link href="/2022/09/02/kdd2022%20%20Compatible%20Embeddings/"/>
      <url>/2022/09/02/kdd2022%20%20Compatible%20Embeddings/</url>
      
        <content type="html"><![CDATA[<h1 id="文章链接"><a href="#文章链接" class="headerlink" title="文章链接"></a>文章链接</h1><p>KDD2022： <a href="https://cs.stanford.edu/people/jure/pubs/bcemb-kdd22.pdf">https://cs.stanford.edu/people/jure/pubs/bcemb-kdd22.pdf</a></p><h1 id="文章主要内容"><a href="#文章主要内容" class="headerlink" title="文章主要内容"></a>文章主要内容</h1><p>文章本身说的情景并不适合。<br>个人认为此方法适合的场景是：如何在低储存量的前提下交付多个下游用户。而不是文章说的在同一个模型不断迭代的情景下保持对某个用户的稳定节点表示。</p><h1 id="文章主要新意"><a href="#文章主要新意" class="headerlink" title="文章主要新意"></a>文章主要新意</h1><p>把原先只在face recognition的方法迁移到图表示上来。另外还做了些工程上的尝试。</p><h1 id="文章脉络"><a href="#文章脉络" class="headerlink" title="文章脉络"></a>文章脉络</h1><h2 id="3种应对场景的方法"><a href="#3种应对场景的方法" class="headerlink" title="3种应对场景的方法"></a>3种应对场景的方法</h2><ul><li>keep all，把所有使用到的embedding都存储</li><li>keep latest，只存储最后一版emebdding，剩下的用B来转换到对应版本，文章在这一方法下做了6种不同的实验。</li><li>keep original， 只储存第一版embedding，但是文章除了用fine tune，并没有给出更多实验。<h2 id="3种实验setting："><a href="#3种实验setting：" class="headerlink" title="3种实验setting："></a>3种实验setting：</h2>为了学到一个B矩阵，用来还原上一版，</li><li>Representation transformation：对上一步的embedding是否做linear变换，做linear的文章叫<code>Lin</code>，不做的叫<code>Notrans</code></li><li>Single/Multiple version of Regularizer：只对上一步的embedding做拉近还是对前多步的embedding做拉近。上一步的文章叫<code>Single step</code>，上多步的叫<code>Multi step</code></li><li>Training: 先train再regularize，还是training与regularization一起。先train再regularize叫<code>Posthoc</code>，一起的叫<code>Joint</code>。</li></ul><p>原本应该有2<em>2</em>2 共8种实验，但是文章只给出了6种。</p><h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><p>模型使用Pinsage，也就是graph sage。</p><h1 id="其他：-情景理由"><a href="#其他：-情景理由" class="headerlink" title="其他： 情景理由"></a>其他： 情景理由</h1><p>为了“稳定节点表示”而去倒推回原先的一套表示？那我新训练出来的新的embedding有什么用？</p>]]></content>
      
      
      
        <tags>
            
            <tag> paper reading, analysis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>metric-learning</title>
      <link href="/2022/09/01/metric_learning/"/>
      <url>/2022/09/01/metric_learning/</url>
      
        <content type="html"><![CDATA[<h1 id="Euclidean-distance-L2-norm"><a href="#Euclidean-distance-L2-norm" class="headerlink" title="Euclidean distance (L2 norm)"></a>Euclidean distance (L2 norm)</h1><p>No explanation, too simple.</p><p>eg: 2-demensional data</p><script type="math/tex; mode=display">A=(a_1,a_2)\ B=(b_1,b_2)</script><script type="math/tex; mode=display">D(A,B)=\sqrt{(a_1−b_1)^2+(a_2−b_2)^2}</script><h1 id="Mahalanobis-distance"><a href="#Mahalanobis-distance" class="headerlink" title="Mahalanobis distance"></a>Mahalanobis distance</h1><p>A distance with consideration on data distribution, more specifically on covarience and demention(量纲). Euclidean is Mahalanobis distance if you perform PCA and normalization on data. In other word, Euclidean distance is a special case of Mahalanobis distance.</p><script type="math/tex; mode=display">D(x,y)=\sqrt{(x−y)^TΣ^{−1}(x−y)}</script><p>where Σ is the covariance metrix of the two data.</p><h1 id="contrastive-loss-对比损失"><a href="#contrastive-loss-对比损失" class="headerlink" title="contrastive loss(对比损失)"></a>contrastive loss(对比损失)</h1><p>It’s created with the idea that we should pull as far as possible away for any data that do not belong to the same class and pull as close as possible for ones that belong to the same class.</p><script type="math/tex; mode=display">D(X_i,X_j)=y_{i,j}d^2_{i,j}+(1−y_{i,j})[α−d^2_{i,j}]</script><p>where $y<em>{i,j}$ is 1 if $X_i$ and $X_j$ is of same class, and 0 otherwise, $d</em>{i,j}$ is euclidean distance, and $α$ controls how aggressive you want different classes to be.</p><p>It can measure data that has never shown before, which cannot be done by classic methods.</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>YOLOv5 结果解析</title>
      <link href="/2020/09/16/yolov5_res/"/>
      <url>/2020/09/16/yolov5_res/</url>
      
        <content type="html"><![CDATA[<h1 id="Confusion-matrix"><a href="#Confusion-matrix" class="headerlink" title="Confusion matrix"></a>Confusion matrix</h1><p>以这种形式给出矩阵的值</p><div class="table-container"><table><thead><tr><th></th><th>$gt_{class1}$</th><th>$gt_{class2}$</th><th>$gt_{class3}$</th><th>background FP</th></tr></thead><tbody><tr><td>$pred_{class1}$</td></tr><tr><td>$pred_{class2}$     </td></tr><tr><td>$pred_{class3}$</td></tr><tr><td>background FN</td></tr></tbody></table></div><p><img src="https://img-blog.csdnimg.cn/36f1d7598d4141c3a6c9c0eed111df08.png" alt="在这里插入图片描述">若是分类的完美，则应当只有对角线是高峰，其余都是0（除了最后一行和最后一列）.<br>根据GitHub上的讨论，background也被列成单独一类，所以也有他的TP、FP、TN、FN等。</p><p><strong>最后一列和最后一行都是以background的类别pos的prediction的FN和FP</strong>。所以最右下角是没有意义的，没有值。</p><ul><li>由于最后一列是background的FP，本来不是背景的，被pred分成了背景，<strong>漏检了非背景物体</strong></li><li>由于最后一行是background的FN，本来是背景的，被pred分成了不是背景，<strong>虚检了本来没有的物体</strong>。</li></ul><blockquote><p>混淆矩阵最后一行和一列是背景类。上面我们知道列是模型预测的结果，行是标签的真实结果。而FP则是表示真实为假预测为真，FN表示真实为真预测为假。可以看到最后一行即backgroundFN出现数值，表示出现了漏检；最后一列即background FP出现数值，则表示出现了虚检<br>来自 <a href="https://blog.csdn.net/m0_66447617/article/details/124180032">https://blog.csdn.net/m0_66447617/article/details/124180032</a>, </p><p>另外可参考github上的讨论，background也被单独划分成了一个类别。<br>    <a href="https://github.com/kaanakan/object_detection_confusion_matrix/issues/12">https://github.com/kaanakan/object_detection_confusion_matrix/issues/12</a></p></blockquote><p>以上面的图为例子的话，可以看到background FN各类都比较高，虚检了很多物体；background FP- hat的相对较高，漏检了很多head类别的物体。而在非背景的类别中，可以看到对角线的值相对大，可见模型能够很好的分清楚这三类谁是谁。</p><h1 id="F1-curve"><a href="#F1-curve" class="headerlink" title="F1 curve"></a>F1 curve</h1><p><img src="https://img-blog.csdnimg.cn/48fdfad93ac2402599e7f189fd090c85.png" alt="在这里插入图片描述">横坐标是置信阈值。</p><script type="math/tex; mode=display">F1=2*\frac1{\frac1{precision}+\frac1{recall}}</script><p>此图能够看到什么阈值下什么类别能够达到最好的F1 score，比如绿线在0.27左右，海蓝色在0.8左右。</p><h1 id="labels"><a href="#labels" class="headerlink" title="labels"></a>labels</h1><p><img src="https://img-blog.csdnimg.cn/c36f8eac520d47978e91ed1374c06841.png" alt="在这里插入图片描述"><br>给所提供的label数据进行统计，是4个图，左上是各个物体的数量直方图，右上是中心对齐后各个物体的bounding box，左下角是中心点统计，右下角是方框长、宽统计</p><h1 id="results"><a href="#results" class="headerlink" title="results"></a>results</h1><p><img src="https://img-blog.csdnimg.cn/788a6a6fc6d947adbbf72974414ee040.png" alt="在这里插入图片描述">横坐标是epoch，标题比较直观的说了每个图的意思</p><h1 id="剩下一些不需要解释的图"><a href="#剩下一些不需要解释的图" class="headerlink" title="剩下一些不需要解释的图"></a>剩下一些不需要解释的图</h1><h2 id="常规曲线"><a href="#常规曲线" class="headerlink" title="常规曲线"></a>常规曲线</h2><p>P-R curve<br>P curve<br>R curve</p><h2 id="batch抽取的case-study"><a href="#batch抽取的case-study" class="headerlink" title="batch抽取的case study"></a>batch抽取的case study</h2><p><img src="https://img-blog.csdnimg.cn/985feb0454444956801d04e8798c5dd8.png" alt="在这里插入图片描述"><br>这些就是抽取个例查看。</p>]]></content>
      
      
      
        <tags>
            
            <tag> cv, object detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Xgboost LightGBM Demo</title>
      <link href="/2020/09/06/xgboost/"/>
      <url>/2020/09/06/xgboost/</url>
      
        <content type="html"><![CDATA[<h1 id="Xgboost"><a href="#Xgboost" class="headerlink" title="Xgboost"></a>Xgboost</h1><h2 id="Binary-Classification"><a href="#Binary-Classification" class="headerlink" title="Binary Classification"></a>Binary Classification</h2><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> StratifiedKFold</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_auc_score,precision_score</span><br><span class="line"><span class="keyword">import</span> xgboost <span class="keyword">as</span> xgb</span><br><span class="line"><span class="keyword">import</span> lightgbm <span class="keyword">as</span> lgb</span><br><span class="line"></span><br><span class="line">skfold=StratifiedKFold(n_splits=<span class="number">3</span>,random_state=<span class="number">2022</span>,shuffle=<span class="literal">True</span>)</span><br><span class="line"><span class="keyword">for</span> train_idx,val_idx <span class="keyword">in</span> skfold.split(all_data,labels):</span><br><span class="line">    <span class="comment"># xgboost划分数据集 训练</span></span><br><span class="line">    train_d=xgb.DMatrix(all_data[train_idx],labels[train_idx])</span><br><span class="line">    test_d=xgb.DMatrix(all_data[val_idx])</span><br><span class="line">    </span><br><span class="line">    params = &#123;</span><br><span class="line">        <span class="string">&#x27;booster&#x27;</span>:<span class="string">&#x27;gblinear&#x27;</span>, <span class="comment"># gbtree gblinear dart</span></span><br><span class="line">        <span class="string">&#x27;eta&#x27;</span>: <span class="number">0.1</span>,</span><br><span class="line">        <span class="comment"># &#x27;colsample_bytree&#x27;: 0.7,</span></span><br><span class="line">        <span class="comment"># &#x27;subsample&#x27;: 0.7,</span></span><br><span class="line">        <span class="comment"># &#x27;alpha&#x27;: 0.01, #L1 norm</span></span><br><span class="line">        <span class="comment"># &#x27;gamma&#x27;: 1,</span></span><br><span class="line">        <span class="string">&#x27;objective&#x27;</span>: <span class="string">&#x27;binary:logistic&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;seed&#x27;</span>: <span class="number">2022</span></span><br><span class="line">    &#125;</span><br><span class="line">    clf=xgb.train(params=params,evals=[(train_d,<span class="string">&#x27;Train&#x27;</span>)],dtrain=train_d,num_boost_round=<span class="number">10</span>) <span class="comment"># 0.65625</span></span><br><span class="line">    preds=clf.predict(test_d)</span><br><span class="line">    preds[preds &gt; <span class="number">0.5</span>] = <span class="number">0</span></span><br><span class="line">    preds[preds &lt;= <span class="number">0.5</span>] = <span class="number">1</span></span><br><span class="line">    <span class="built_in">print</span>(preds)</span><br><span class="line">    <span class="comment"># precision 85 auc 60</span></span><br><span class="line"></span><br><span class="line">    test_y=labels[val_idx]</span><br><span class="line">    score=precision_score(test_y,preds)</span><br><span class="line">    <span class="built_in">print</span>(score)</span><br><span class="line">    score = roc_auc_score(test_y, preds)</span><br><span class="line">    <span class="built_in">print</span>(score, end=<span class="string">&#x27;\n\n&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    </span><br></pre></td></tr></table></figure><h2 id="Regression"><a href="#Regression" class="headerlink" title="Regression"></a>Regression</h2><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> KFold</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_auc_score,mean_squared_error</span><br><span class="line"><span class="keyword">import</span> xgboost <span class="keyword">as</span> xgb</span><br><span class="line"><span class="keyword">import</span> lightgbm <span class="keyword">as</span> lgb</span><br><span class="line"></span><br><span class="line">skfold=KFold(n_splits=<span class="number">3</span>,random_state=<span class="number">2022</span>,shuffle=<span class="literal">True</span>)</span><br><span class="line"><span class="keyword">for</span> train_idx,val_idx <span class="keyword">in</span> skfold.split(all_data, labels):</span><br><span class="line">    <span class="comment"># xgboost划分数据集 训练</span></span><br><span class="line">    train_d=xgb.DMatrix(all_data[train_idx],labels[train_idx])</span><br><span class="line">    test_d=xgb.DMatrix(all_data[val_idx])</span><br><span class="line">    </span><br><span class="line">    params = &#123;</span><br><span class="line">        <span class="string">&#x27;booster&#x27;</span>:<span class="string">&#x27;gblinear&#x27;</span>, <span class="comment"># gbtree gblinear dart</span></span><br><span class="line">        <span class="string">&#x27;eta&#x27;</span>: <span class="number">1</span>,</span><br><span class="line">        <span class="comment"># &#x27;colsample_bytree&#x27;: 0.7,</span></span><br><span class="line">        <span class="comment"># &#x27;subsample&#x27;: 0.7,</span></span><br><span class="line">        <span class="string">&#x27;alpha&#x27;</span>: <span class="number">0.01</span>, <span class="comment">#L1 norm</span></span><br><span class="line">        <span class="comment"># &#x27;gamma&#x27;: 1,</span></span><br><span class="line">        <span class="string">&#x27;objective&#x27;</span>: <span class="string">&#x27;reg:squarederror&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;seed&#x27;</span>: <span class="number">2022</span></span><br><span class="line">    &#125;</span><br><span class="line">    clf=xgb.train(params=params,evals=[(train_d,<span class="string">&#x27;Train&#x27;</span>)],dtrain=train_d,num_boost_round=<span class="number">30</span>) <span class="comment"># 0.65625</span></span><br><span class="line">    preds=clf.predict(test_d)</span><br><span class="line"></span><br><span class="line">    test_y=labels[val_idx]</span><br><span class="line">    <span class="built_in">print</span>(preds)</span><br><span class="line">    <span class="built_in">print</span>(test_y)</span><br><span class="line">    <span class="comment"># test_y=test_y*labels.std(0)+labels.mean(0)</span></span><br><span class="line">    <span class="comment"># preds=preds*labels.std(0)+labels.mean(0)</span></span><br><span class="line">    score=mean_squared_error(test_y,preds)</span><br><span class="line">    <span class="built_in">print</span>(score, end=<span class="string">&#x27;\n\n&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id="Lightgbm"><a href="#Lightgbm" class="headerlink" title="Lightgbm"></a>Lightgbm</h1><h2 id="Binary-Classification-1"><a href="#Binary-Classification-1" class="headerlink" title="Binary Classification"></a>Binary Classification</h2><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> StratifiedKFold</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_auc_score,precision_score</span><br><span class="line"><span class="keyword">import</span> xgboost <span class="keyword">as</span> xgb</span><br><span class="line"><span class="keyword">import</span> lightgbm <span class="keyword">as</span> lgb</span><br><span class="line"></span><br><span class="line">skfold=StratifiedKFold(n_splits=<span class="number">3</span>,random_state=<span class="number">2022</span>,shuffle=<span class="literal">True</span>)</span><br><span class="line"><span class="keyword">for</span> train_idx,val_idx <span class="keyword">in</span> skfold.split(all_data,labels):</span><br><span class="line">    params=&#123;</span><br><span class="line">        <span class="string">&#x27;objective&#x27;</span> : <span class="string">&#x27;binary&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;learning_rate&#x27;</span>: <span class="number">1</span>,</span><br><span class="line">        <span class="string">&#x27;n_estimators&#x27;</span> : <span class="number">10</span>,</span><br><span class="line">    &#125;</span><br><span class="line">    gbm = lgb.LGBMClassifier(**params)</span><br><span class="line">    gbm.fit(all_data[train_idx], labels[train_idx], eval_set=[(all_data[train_idx], labels[train_idx])], eval_metric=<span class="string">&#x27;cross_entropy&#x27;</span>)</span><br><span class="line">    preds = gbm.predict(all_data[val_idx], num_iteration=gbm.best_iteration_)</span><br><span class="line">    <span class="comment"># precision 84 auc 59</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    test_y=labels[val_idx]</span><br><span class="line">    score=precision_score(test_y,preds)</span><br><span class="line">    <span class="built_in">print</span>(score)</span><br><span class="line">    score = roc_auc_score(test_y, preds)</span><br><span class="line">    <span class="built_in">print</span>(score, end=<span class="string">&#x27;\n\n&#x27;</span>)</span><br></pre></td></tr></table></figure><h2 id="Regression-1"><a href="#Regression-1" class="headerlink" title="Regression"></a>Regression</h2><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> StratifiedKFold</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_auc_score,precision_score</span><br><span class="line"><span class="keyword">import</span> xgboost <span class="keyword">as</span> xgb</span><br><span class="line"><span class="keyword">import</span> lightgbm <span class="keyword">as</span> lgb</span><br><span class="line"></span><br><span class="line">skfold=StratifiedKFold(n_splits=<span class="number">3</span>,random_state=<span class="number">2022</span>,shuffle=<span class="literal">True</span>)</span><br><span class="line"><span class="keyword">for</span> train_idx,val_idx <span class="keyword">in</span> skfold.split(all_data,labels):</span><br><span class="line">    params=&#123;</span><br><span class="line">        <span class="string">&#x27;objective&#x27;</span> : <span class="string">&#x27;regression&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;learning_rate&#x27;</span>: <span class="number">1</span>,</span><br><span class="line">        <span class="string">&#x27;n_estimators&#x27;</span> : <span class="number">40</span>,</span><br><span class="line">    &#125;</span><br><span class="line">    gbm = lgb.LGBMRegressor(**params)</span><br><span class="line">    gbm.fit(all_data[train_idx], labels_norm[train_idx], eval_set=[(all_data[train_idx], labels_norm[train_idx])])</span><br><span class="line">    preds = gbm.predict(all_data[val_idx], num_iteration=gbm.best_iteration_)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    test_y=labels[val_idx]</span><br><span class="line">    <span class="built_in">print</span>(preds)</span><br><span class="line">    <span class="built_in">print</span>(test_y)</span><br><span class="line">    test_y=test_y*labels.std(<span class="number">0</span>)+labels.mean(<span class="number">0</span>)</span><br><span class="line">    preds=preds*labels.std(<span class="number">0</span>)+labels.mean(<span class="number">0</span>)</span><br><span class="line">    score=mean_squared_error(test_y,preds)</span><br><span class="line">    <span class="built_in">print</span>(score, end=<span class="string">&#x27;\n\n&#x27;</span>)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>YOLOv5 quick start</title>
      <link href="/2020/09/04/yolov5_takeaway/"/>
      <url>/2020/09/04/yolov5_takeaway/</url>
      
        <content type="html"><![CDATA[<h1 id="Takeaways"><a href="#Takeaways" class="headerlink" title="Takeaways"></a>Takeaways</h1><p>需要规整两个文件<code>xx/images/</code>和<code>xx/labels</code>，其中里面堆放可以堆放指向文件的txt，分别都是<code>train.txt</code>和<code>val.txt</code>。</p><p>训练使用yolo项目中<code>train.py</code>，其命令中data选项需要yaml，进行数据集的指向和说明。一定要保证yaml的路径与我们处理的数据集的路径相同。</p><p>所有运行后的结果，都会在项目的runs文件夹中。</p><h1 id="快速上手-https-docs-ultralytics-com-quick-start"><a href="#快速上手-https-docs-ultralytics-com-quick-start" class="headerlink" title="快速上手^[https://docs.ultralytics.com/quick-start/]"></a>快速上手^[<a href="https://docs.ultralytics.com/quick-start/">https://docs.ultralytics.com/quick-start/</a>]</h1><p>总参考：<a href="https://docs.ultralytics.com/tutorials/training-tips-best-results/">https://docs.ultralytics.com/tutorials/training-tips-best-results/</a> </p><h1 id="Inference"><a href="#Inference" class="headerlink" title="Inference"></a>Inference</h1><ul><li>两种方法，一个是自行下载model源码，使用detect.py.  <figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python .\detect.py --weights <span class="string">&quot;weights/yolov5s.pt&quot;</span> --source <span class="string">&quot;data/images/bus.jpg&quot;</span></span><br></pre></td></tr></table></figure></li><li>另一个是通过<code>torch.hub</code>  <figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">    <span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="comment"># Model</span></span><br><span class="line">model = torch.hub.load(<span class="string">&#x27;ultralytics/yolov5&#x27;</span>, <span class="string">&#x27;yolov5s&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Images</span></span><br><span class="line"><span class="built_in">dir</span> = <span class="string">&#x27;https://github.com/ultralytics/yolov5/raw/master/data/images/&#x27;</span></span><br><span class="line">imgs = [<span class="built_in">dir</span> + f <span class="keyword">for</span> f <span class="keyword">in</span> (<span class="string">&#x27;zidane.jpg&#x27;</span>, <span class="string">&#x27;bus.jpg&#x27;</span>)]  <span class="comment"># batch of images</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Inference</span></span><br><span class="line">results = model(imgs)</span><br><span class="line">results.<span class="built_in">print</span>()  <span class="comment"># or .show(), .save()</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h1></li></ul><h2 id="编写yaml文件"><a href="#编写yaml文件" class="headerlink" title="编写yaml文件"></a>编写yaml文件</h2><p>首先需要一个yaml文件，放在<code>data</code>文件夹下，示例如下：<br>第一行其实是存放路径名的文件，文件的每一行可以有三种形式，注释已经给出。</p><ul><li>一种是直接把目录给出，目录里面放有图片+标签</li><li>一种是以txt形式给出，txt里面有图片/label的路径</li><li>一种是多种路径同时给出<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># train and val data as 1) directory: path/images/, 2) file: path/images.txt, or 3) list: [path1/images/, path2/images/]</span></span><br><span class="line"><span class="attr">train:</span> <span class="string">../coco128/images/train2017/</span></span><br><span class="line"><span class="attr">val:</span> <span class="string">../coco128/images/train2017/</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># number of classes</span></span><br><span class="line"><span class="attr">nc:</span> <span class="number">80</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># class names</span></span><br><span class="line"><span class="attr">names:</span> [<span class="string">&#x27;person&#x27;</span>, <span class="string">&#x27;bicycle&#x27;</span>, <span class="string">&#x27;car&#x27;</span>, <span class="string">&#x27;motorcycle&#x27;</span>, <span class="string">&#x27;airplane&#x27;</span>, <span class="string">&#x27;bus&#x27;</span>, <span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;truck&#x27;</span>, <span class="string">&#x27;boat&#x27;</span>, <span class="string">&#x27;traffic light&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;fire hydrant&#x27;</span>, <span class="string">&#x27;stop sign&#x27;</span>, <span class="string">&#x27;parking meter&#x27;</span>, <span class="string">&#x27;bench&#x27;</span>, <span class="string">&#x27;bird&#x27;</span>, <span class="string">&#x27;cat&#x27;</span>, <span class="string">&#x27;dog&#x27;</span>, <span class="string">&#x27;horse&#x27;</span>, <span class="string">&#x27;sheep&#x27;</span>, <span class="string">&#x27;cow&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;elephant&#x27;</span>, <span class="string">&#x27;bear&#x27;</span>, <span class="string">&#x27;zebra&#x27;</span>, <span class="string">&#x27;giraffe&#x27;</span>, <span class="string">&#x27;backpack&#x27;</span>, <span class="string">&#x27;umbrella&#x27;</span>, <span class="string">&#x27;handbag&#x27;</span>, <span class="string">&#x27;tie&#x27;</span>, <span class="string">&#x27;suitcase&#x27;</span>, <span class="string">&#x27;frisbee&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;skis&#x27;</span>, <span class="string">&#x27;snowboard&#x27;</span>, <span class="string">&#x27;sports ball&#x27;</span>, <span class="string">&#x27;kite&#x27;</span>, <span class="string">&#x27;baseball bat&#x27;</span>, <span class="string">&#x27;baseball glove&#x27;</span>, <span class="string">&#x27;skateboard&#x27;</span>, <span class="string">&#x27;surfboard&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;tennis racket&#x27;</span>, <span class="string">&#x27;bottle&#x27;</span>, <span class="string">&#x27;wine glass&#x27;</span>, <span class="string">&#x27;cup&#x27;</span>, <span class="string">&#x27;fork&#x27;</span>, <span class="string">&#x27;knife&#x27;</span>, <span class="string">&#x27;spoon&#x27;</span>, <span class="string">&#x27;bowl&#x27;</span>, <span class="string">&#x27;banana&#x27;</span>, <span class="string">&#x27;apple&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;sandwich&#x27;</span>, <span class="string">&#x27;orange&#x27;</span>, <span class="string">&#x27;broccoli&#x27;</span>, <span class="string">&#x27;carrot&#x27;</span>, <span class="string">&#x27;hot dog&#x27;</span>, <span class="string">&#x27;pizza&#x27;</span>, <span class="string">&#x27;donut&#x27;</span>, <span class="string">&#x27;cake&#x27;</span>, <span class="string">&#x27;chair&#x27;</span>, <span class="string">&#x27;couch&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;potted plant&#x27;</span>, <span class="string">&#x27;bed&#x27;</span>, <span class="string">&#x27;dining table&#x27;</span>, <span class="string">&#x27;toilet&#x27;</span>, <span class="string">&#x27;tv&#x27;</span>, <span class="string">&#x27;laptop&#x27;</span>, <span class="string">&#x27;mouse&#x27;</span>, <span class="string">&#x27;remote&#x27;</span>, <span class="string">&#x27;keyboard&#x27;</span>, </span><br><span class="line">        <span class="string">&#x27;cell phone&#x27;</span>, <span class="string">&#x27;microwave&#x27;</span>, <span class="string">&#x27;oven&#x27;</span>, <span class="string">&#x27;toaster&#x27;</span>, <span class="string">&#x27;sink&#x27;</span>, <span class="string">&#x27;refrigerator&#x27;</span>, <span class="string">&#x27;book&#x27;</span>, <span class="string">&#x27;clock&#x27;</span>, <span class="string">&#x27;vase&#x27;</span>, <span class="string">&#x27;scissors&#x27;</span>, </span><br><span class="line">        <span class="string">&#x27;teddy bear&#x27;</span>, <span class="string">&#x27;hair drier&#x27;</span>, <span class="string">&#x27;toothbrush&#x27;</span>]</span><br><span class="line"></span><br></pre></td></tr></table></figure></li></ul><h2 id="获得标签"><a href="#获得标签" class="headerlink" title="获得标签"></a>获得标签</h2><p>可以使用CVAT、 makesense.ai、 Labelbox、Labelimg等等工具打标。</p><h2 id="转化label格式（如果需要）"><a href="#转化label格式（如果需要）" class="headerlink" title="转化label格式（如果需要）"></a>转化label格式（如果需要）</h2><p>label格式一般有两种，一个是xml，一个是txt。<br>txt格式是：每一行都是一个object，以<code>class x_center y_center width height</code>表示，yolo系列使用的是txt格式。<br>xml格式实例：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">&lt;?xml version=&quot;1.0&quot; ?&gt;&lt;annotation&gt;</span><br><span class="line">  &lt;filename&gt;helmet_10827.jpg&lt;/filename&gt;</span><br><span class="line">  &lt;size&gt;</span><br><span class="line">    &lt;width&gt;1920&lt;/width&gt;</span><br><span class="line">    &lt;height&gt;1080&lt;/height&gt;</span><br><span class="line">    &lt;depth&gt;3&lt;/depth&gt;</span><br><span class="line">  &lt;/size&gt;</span><br><span class="line">  &lt;object&gt;</span><br><span class="line">    &lt;name&gt;hat&lt;/name&gt;</span><br><span class="line">    &lt;bndbox&gt;</span><br><span class="line">      &lt;xmin&gt;1227&lt;/xmin&gt;</span><br><span class="line">      &lt;ymin&gt;385&lt;/ymin&gt;</span><br><span class="line">      &lt;xmax&gt;1288&lt;/xmax&gt;</span><br><span class="line">      &lt;ymax&gt;446&lt;/ymax&gt;</span><br><span class="line">    &lt;/bndbox&gt;</span><br><span class="line">  &lt;/object&gt;</span><br><span class="line">  &lt;object&gt;</span><br><span class="line">    &lt;name&gt;person&lt;/name&gt;</span><br><span class="line">    &lt;bndbox&gt;</span><br><span class="line">      &lt;xmin&gt;1161&lt;/xmin&gt;</span><br><span class="line">      &lt;ymin&gt;377&lt;/ymin&gt;</span><br><span class="line">      &lt;xmax&gt;1324&lt;/xmax&gt;</span><br><span class="line">      &lt;ymax&gt;604&lt;/ymax&gt;</span><br><span class="line">    &lt;/bndbox&gt;</span><br><span class="line">  &lt;/object&gt;</span><br><span class="line">&lt;/annotation&gt;</span><br></pre></td></tr></table></figure></p><p>xml转txt可以用以下<strong>示例</strong>代码^[<a href="https://docs.cvmart.net/#/best_practice_for_newbie?id=jump1]转化：">https://docs.cvmart.net/#/best_practice_for_newbie?id=jump1]转化：</a><br>xml转txt<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> xml.etree.ElementTree <span class="keyword">as</span> ET</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> os <span class="keyword">import</span> listdir, getcwd</span><br><span class="line"><span class="keyword">from</span> os.path <span class="keyword">import</span> join</span><br><span class="line"></span><br><span class="line">sets=[<span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;val&#x27;</span>, <span class="string">&#x27;test&#x27;</span>]</span><br><span class="line">classes = [<span class="string">&#x27;person&#x27;</span>, <span class="string">&#x27;hat&#x27;</span>,<span class="string">&#x27;head&#x27;</span>]</span><br><span class="line"></span><br><span class="line">abs_path = os.getcwd()</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">convert</span>(<span class="params">size, box</span>):</span><br><span class="line">    dw = <span class="number">1.</span>/(size[<span class="number">0</span>])</span><br><span class="line">    dh = <span class="number">1.</span>/(size[<span class="number">1</span>])</span><br><span class="line">    x = (box[<span class="number">0</span>] + box[<span class="number">1</span>])/<span class="number">2.0</span> - <span class="number">1</span></span><br><span class="line">    y = (box[<span class="number">2</span>] + box[<span class="number">3</span>])/<span class="number">2.0</span> - <span class="number">1</span></span><br><span class="line">    w = box[<span class="number">1</span>] - box[<span class="number">0</span>]</span><br><span class="line">    h = box[<span class="number">3</span>] - box[<span class="number">2</span>]</span><br><span class="line">    x = x*dw</span><br><span class="line">    w = w*dw</span><br><span class="line">    y = y*dh</span><br><span class="line">    h = h*dh</span><br><span class="line">    <span class="keyword">return</span> (x,y,w,h)</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">convert_annotation</span>(<span class="params">image_id</span>):</span><br><span class="line">    in_file = <span class="built_in">open</span>(<span class="string">&#x27;/project/train/src_repo/dataset/Annotations/%s.xml&#x27;</span>%( image_id))</span><br><span class="line">    out_file = <span class="built_in">open</span>(<span class="string">&#x27;/project/train/src_repo/dataset/labels/%s.txt&#x27;</span>%(image_id), <span class="string">&#x27;w&#x27;</span>)</span><br><span class="line">    tree=ET.parse(in_file)</span><br><span class="line">    root = tree.getroot()</span><br><span class="line">    size = root.find(<span class="string">&#x27;size&#x27;</span>)</span><br><span class="line">    w = <span class="built_in">int</span>(size.find(<span class="string">&#x27;width&#x27;</span>).text)</span><br><span class="line">    h = <span class="built_in">int</span>(size.find(<span class="string">&#x27;height&#x27;</span>).text)</span><br><span class="line">    <span class="keyword">for</span> obj <span class="keyword">in</span> root.<span class="built_in">iter</span>(<span class="string">&#x27;object&#x27;</span>):</span><br><span class="line">        <span class="comment">#difficult = obj.find(&#x27;difficult&#x27;).text</span></span><br><span class="line">        cls = obj.find(<span class="string">&#x27;name&#x27;</span>).text</span><br><span class="line">        <span class="keyword">if</span> cls <span class="keyword">not</span> <span class="keyword">in</span> classes :</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        cls_id = classes.index(cls)</span><br><span class="line">        xmlbox = obj.find(<span class="string">&#x27;bndbox&#x27;</span>)</span><br><span class="line">        b = (<span class="built_in">float</span>(xmlbox.find(<span class="string">&#x27;xmin&#x27;</span>).text), <span class="built_in">float</span>(xmlbox.find(<span class="string">&#x27;xmax&#x27;</span>).text), <span class="built_in">float</span>(xmlbox.find(<span class="string">&#x27;ymin&#x27;</span>).text), <span class="built_in">float</span>(xmlbox.find(<span class="string">&#x27;ymax&#x27;</span>).text))</span><br><span class="line">        bb = convert((w,h), b)</span><br><span class="line">        out_file.write(<span class="built_in">str</span>(cls_id) + <span class="string">&quot; &quot;</span> + <span class="string">&quot; &quot;</span>.join([<span class="built_in">str</span>(a) <span class="keyword">for</span> a <span class="keyword">in</span> bb]) + <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> image_set <span class="keyword">in</span> sets:</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="string">&#x27;/project/train/src_repo/dataset/labels/&#x27;</span>):</span><br><span class="line">        os.makedirs(<span class="string">&#x27;/project/train/src_repo/dataset/labels/&#x27;</span>)</span><br><span class="line">    image_ids = <span class="built_in">open</span>(<span class="string">&#x27;/project/train/src_repo/dataset/ImageSets/Main/%s.txt&#x27;</span>%(image_set)).read().strip().split()</span><br><span class="line">    list_file = <span class="built_in">open</span>(<span class="string">&#x27;/project/train/src_repo/dataset/%s.txt&#x27;</span>%(image_set), <span class="string">&#x27;w&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> image_id <span class="keyword">in</span> image_ids:</span><br><span class="line">        list_file.write(<span class="string">&#x27;/project/train/src_repo/dataset/images/%s.jpg\n&#x27;</span>%(image_id))</span><br><span class="line">        convert_annotation(image_id)</span><br><span class="line">    list_file.close()</span><br></pre></td></tr></table></figure></p><h2 id="整理目录"><a href="#整理目录" class="headerlink" title="整理目录"></a>整理目录</h2><p>目录结构应该成这个样子：<br><img src="https://user-images.githubusercontent.com/26833433112467887-e18a0980-8d67-11eb-93af-6505620ff8aa.png" alt="这是图片"></p><p>dataset单独一个目录，目录下有images和labels两个目录，每个目录下有train和valid。</p><h2 id="Training-1"><a href="#Training-1" class="headerlink" title="Training"></a>Training</h2><p>在下载的源码里，有<code>train.py</code>。<br>只需按照示例：<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Train YOLOv5s on COCO128 for 5 epochs</span></span><br><span class="line">$ python train.py --img <span class="number">640</span> --batch <span class="number">16</span> --epochs <span class="number">5</span> --data coco128.yaml --weights yolov5s.pt</span><br></pre></td></tr></table></figure><br>训练结果会保存在项目的<code>runs/train/</code>。</p><h2 id="查看训练、可视化"><a href="#查看训练、可视化" class="headerlink" title="查看训练、可视化"></a>查看训练、可视化</h2><p>可以用wandb和tensorboard，教程推荐使用wandb。</p><h3 id="wandb"><a href="#wandb" class="headerlink" title="wandb"></a>wandb</h3><p>可以用wandb，<code>pip install wandb</code>，在训练过程中就可以在 <a href="https://wandb.ai">https://wandb.ai</a> 中看到结果。<br>使用这个工具，log会被默认的放在<code>runs/train</code>。</p><h3 id="tensorboard"><a href="#tensorboard" class="headerlink" title="tensorboard"></a>tensorboard</h3><p>这个需要自行修改代码，在合适的位置加入tb，记录数据。</p><h1 id="更高训练结果tips"><a href="#更高训练结果tips" class="headerlink" title="更高训练结果tips"></a>更高训练结果tips</h1><h2 id="数据集改进点"><a href="#数据集改进点" class="headerlink" title="数据集改进点"></a>数据集改进点</h2><ul><li>关于每类的图片：每一类最好是≥1.5k的图片。</li><li>每类物体最好是≥10k. 并且物体要具有代表性。真实场景下，推荐使用不同时间段、不同季节、不同角度、不同光照、不同天气、不同采集源的同一物体，做为训练数据。</li><li>Label consistency. All instances of all classes in all images must be labelled. Partial labelling will not work.</li><li>Label accuracy. Labels must closely enclose each object. No space should exist between an object and it’s bounding box. No objects should be missing a label.</li><li>Background images. Background images are images with no objects that are added to a dataset to reduce False Positives (FP). We recommend about 0-10% background images to help reduce FPs (COCO has 1000 background images for reference, 1% of the total).</li></ul><h2 id="模型选择"><a href="#模型选择" class="headerlink" title="模型选择"></a>模型选择</h2><p>yolo提供了多种不同大小的模型，大模型往往能更好的结果。<br><img src="https://user-images.githubusercontent.com/26833433/103595982-ab986000-4eb1-11eb-8c57-4726261b0a88.png" alt=""></p><ul><li>pretrain往往在中小型数据集上。  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">python train.py --data custom.yaml --weights yolov5s.pt</span><br><span class="line">                                         yolov5m.pt</span><br><span class="line">                                         yolov5l.pt</span><br><span class="line">                                         yolov5x.pt</span><br><span class="line">                                         custom_pretrained.pt</span><br><span class="line"></span><br></pre></td></tr></table></figure></li><li>train from scratch往往在大数据集上。  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">python train.py --data custom.yaml --weights &#x27;&#x27; --cfg yolov5s.yaml</span><br><span class="line">                                                  yolov5m.yaml</span><br><span class="line">                                                  yolov5l.yaml</span><br><span class="line">                                                  yolov5x.yaml</span><br><span class="line"></span><br></pre></td></tr></table></figure></li></ul><h2 id="训练参数"><a href="#训练参数" class="headerlink" title="训练参数"></a>训练参数</h2><p>Training Settings</p><p>Before modifying anything, first train with default settings to establish a performance baseline. A full list of train.py settings can be found in the train.py argparser.</p><ul><li><strong>Epochs</strong>. Start with 300 epochs. If this overfits early then you can reduce epochs. If overfitting does not occur after 300 epochs, train longer, i.e. 600, 1200 etc epochs.</li><li><strong>Image size</strong>. COCO trains at native resolution of <code>--img 640</code>, though due to the high amount of small objects in the dataset it can benefit from training at higher resolutions such as <code>--img 1280</code>. If there are many <strong>small objects</strong> then custom datasets will benefit from training at native or higher resolution. Best inference results are obtained at the same —img as the training was run at, i.e. if you train at <code>--img 1280</code> you should also test and detect at <code>--img 1280</code>.</li><li><strong>Batch size</strong>. Use the largest <code>--batch-size</code> that your hardware allows for. Small batch sizes produce poor batchnorm statistics and should be avoided.</li><li><strong>Hyperparameters</strong>. Default hyperparameters are in <a href="https://github.com/ultralytics/yolov5/blob/master/data/hyp.scratch.yaml">hyp.scratch.yaml</a>. We recommend you train with default hyperparameters first before thinking of modifying any. In general, <em>increasing augmentation hyperparameters will reduce and delay overfitting, allowing for longer trainings and higher final mAP</em>. Reduction in loss component gain hyperparameters like <code>hyp[&#39;obj&#39;]</code> will help reduce overfitting in those specific loss components. For an automated method of optimizing these hyperparameters, see our <a href="https://github.com/ultralytics/yolov5/issues/607">Hyperparameter Evolution Tutorial</a>.</li></ul><p>参考^[<a href="https://docs.ultralytics.com/tutorials/train-custom-datasets/">https://docs.ultralytics.com/tutorials/train-custom-datasets/</a>]</p>]]></content>
      
      
      
        <tags>
            
            <tag> cv, object detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>moving average</title>
      <link href="/2020/09/01/moving_average/"/>
      <url>/2020/09/01/moving_average/</url>
      
        <content type="html"><![CDATA[<h2 id="Exponentially-weighted-averages"><a href="#Exponentially-weighted-averages" class="headerlink" title="Exponentially weighted averages "></a>Exponentially weighted averages </h2><script type="math/tex; mode=display">Vt=βVt−1−(1−β)Vt</script><p>where β ranges from 0 to 1.<br>This equation enables you to make average of 11−β</p><p>days’ data, which will make the data plot much smoother.</p><p>example:<br><a href="https://www.bilibili.com/video/av49445369?p=60">https://www.bilibili.com/video/av49445369?p=60</a><br>result:<br>pic<br>where the red line is the smoother plot and the blue ones are the original data plot.</p><p><a href="https://zhuanlan.zhihu.com/p/29895933">https://zhuanlan.zhihu.com/p/29895933</a><br>So it’s just a weighted average, and it can perform smoothening.<br>Improvement–Bias correction</p><p>At early stage, if we use standard equation may get the purple line in the picture below, because it lack former data to be averaged.<br>pic<br>To eliminate this problem, perform the method in red rectangle on the picture in early stage.</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>measure the contribution:shaply value</title>
      <link href="/2020/09/01/shaply/"/>
      <url>/2020/09/01/shaply/</url>
      
        <content type="html"><![CDATA[<p>Measure Contribution of Participants in Federated Learning<br>2020-03-27</p><p><a href="https://arxiv.org/pdf/1909.08525v1.pdf">Paper link</a></p><h1 id="BASIC"><a href="#BASIC" class="headerlink" title="BASIC"></a>BASIC</h1><p>backgroud: federated learning<br>two measure methods exist, deletion <a href="https://www.ime.usp.br/~abe/lista/pdfWiH1zqnMHo.pdf">diagnostics</a> and <a href="https://arxiv.org/pdf/1703.04730.pdf">influence functions</a></p><h1 id="SHAPLEY-VALUE-amp-MARIGINAL-CONTRIBUTION"><a href="#SHAPLEY-VALUE-amp-MARIGINAL-CONTRIBUTION" class="headerlink" title="SHAPLEY VALUE &amp; MARIGINAL CONTRIBUTION"></a>SHAPLEY VALUE &amp; MARIGINAL CONTRIBUTION</h1><p>it’s used to split profit earned by all participants.</p><h2 id="Example"><a href="#Example" class="headerlink" title="Example:"></a>Example:</h2><p>We need to kill 500 monsters in total. A alone can kill 100; B alone can kill 125; C alone can kill 50. A and B together can kill 270; B and C together can kill 350; A and C together can kill 375; A and B and C together can kill 500 in total.<br>We denote what mentioned above as:<br>v(1)=100;</p><p>v(2)=125; v(3)=50;<br>v(1,2)=270; v(2,3)=350; v(1,3)=375;<br>v(1,2,3)=500;</p><p>Note that the task can only be accomplished by three people.<br>possible cases might be 6 in total:<br>A invites B to make a group S and then invites C.<br>A invites C to make a group S and then invites B.<br>etc etc.</p><h1 id="Marginal-Contribution"><a href="#Marginal-Contribution" class="headerlink" title="Marginal Contribution"></a>Marginal Contribution</h1><p>The marginal contribution splitted of this 6 cases should be calculated as this as shown in the table.<br>image<br>so the marginal contribution is formulated as: $δ_i(S)=v(S\cup i)−v(S)$<br>, where $δ$ denote the influence/contribution factor, $δ_i(S)$ denotes the ith participant’s contribution to group S.<br>From the discussion we can know that the order of the participants really matters in term of marginal contribution.</p><h1 id="Shapley-Value"><a href="#Shapley-Value" class="headerlink" title="Shapley Value"></a>Shapley Value</h1><p>shapley value takes high importance on marginal contribution(边际贡献 in chinese), which is formulated as</p><script type="math/tex; mode=display">Sh(S,i)=\frac{Σ_{r∈R}δ_i(r)}{|Ag|!}</script><p>where $|Ag|$ denotes the number of agants who participates; R denotes the set of all possible cases, r denotes one specific case that belong to whole set R;<br>According to the shapley value equation, we calculate agants’ value as followed:<br>1： 16(100+100+145+150+325+150)=9706<br>2： 16(170+125+125+125+125+300)=9706<br>3： 16(230+275+230+225+50+50)=10606</p><p>1 2 3 total is 500.<br>and then they can split the profit according to the shapley value.</p><h1 id="PAPER-METHOD"><a href="#PAPER-METHOD" class="headerlink" title="PAPER METHOD"></a>PAPER METHOD</h1><h2 id="Horizontal-Measurement"><a href="#Horizontal-Measurement" class="headerlink" title="Horizontal Measurement"></a>Horizontal Measurement</h2><p>Deletion diagnostics is intuitive. Retrain the model each time with an instance omitted from training dataset and measure how much the prediction of retrained model changes.</p><p>Suppose we omit the $i$th instance, or rather one piece of data, influence is formulated as:</p><script type="math/tex; mode=display">Influence(i)=\frac1nΣ^n_{j=i}|predj−pred−ij|</script><p>And any dataset had many instance, so the dataset influence can be discribed as:</p><script type="math/tex; mode=display">Influence(D)=Σ_{i∈D}Influence(D_i)</script><p>where $Di$ means the $i$th instance in dataset.</p><h2 id="Vertical-Measurement"><a href="#Vertical-Measurement" class="headerlink" title="Vertical Measurement"></a>Vertical Measurement</h2><p>coeffient<br>Questions tbd: what is situational importance?<br>It’s an ancient question coming up a long time ago, and there’re pretty many paper about this question. Most of them applied shapley value as measurement to get vertical FML contribution of each party.</p><p>We first take a easy example and then we generalize the situation.</p><h2 id="Individual-Feature-Shaley-Value"><a href="#Individual-Feature-Shaley-Value" class="headerlink" title="Individual Feature Shaley Value"></a>Individual Feature Shaley Value</h2><p>Note: we are now in INSTANCE level! We are talking about ONE SINGLE INSTANCE, one piece of data.<br>Consider an instance with total n features, what is the contribution of one specific feature value?<br>Suppose to calculate the contribution of the ith<br>feature, we go like this:</p><script type="math/tex; mode=display">ϕ_i(x)=Σ_{Q∈S∖i}\frac{|Q|!(|S|−|Q|−1)!}{|S|!}(Δ_{Q\cup i}−Δ_Q)</script><p>where S is the index set of all feature, Q is a index subset, |.| denotes the number of . .<br>By observation, we can see that right part of the equation is the influence difference between subset with ith and subset without ith</p><p>while the left part is just a coeffient to average the influence.</p><h2 id="Dataset-Feature-Shaley-Value"><a href="#Dataset-Feature-Shaley-Value" class="headerlink" title="Dataset Feature Shaley Value"></a>Dataset Feature Shaley Value</h2><p>We are coming into DATASET LEVEL.<br>Although the method mentioned above gives a strong sulotion to get contribution of individual feature, but with so many data in a dataset, computing has a exponential time complexity, making it infeasible to implement in practice.<br>An approximation with Monto-Carlo Sampling algorithm has been proposed in <a href="https://link.springer.com/article/10.1007/s10115-013-0679-x">this paper</a>:</p><script type="math/tex; mode=display">ϕ_i(x)=\frac1M\sum^M_{m=1}(f(x^m_{+i})−f(x^{m}_{−i}))</script><p>where $M$ is the iteration number, which is customized by user; $x^{m}<em>{−i}$ is subset with random feature replaced by randomly picked instance from dataset, and WITHOUT ith feature; $x^m</em>{+i}$ is everything the same as $x^{m}_{−i}$ but WITH ith feature.</p><p>To summarize, the sampling method helps simplify computing making it feasible to perform contribution algorithm in dataset level.</p><h2 id="Federated-Learning-Feature-Shaley-Value"><a href="#Federated-Learning-Feature-Shaley-Value" class="headerlink" title="Federated Learning Feature Shaley Value"></a>Federated Learning Feature Shaley Value</h2><p>This is the paper method proposed by the author.</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>yolo example</title>
      <link href="/2020/09/01/yolo/"/>
      <url>/2020/09/01/yolo/</url>
      
        <content type="html"><![CDATA[<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment">#cv2.rectangle 通过对角线来画矩形，左上到右下这个对角线。</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#load yolo</span></span><br><span class="line">base=<span class="string">r&quot;G:/Code/YOLO recognition/&quot;</span></span><br><span class="line">yolo_net = cv2.dnn.readNet(base + <span class="string">&quot;yolov3.weights&quot;</span>, base + <span class="string">&quot;yolov3.cfg&quot;</span>)</span><br><span class="line"><span class="comment">#load label</span></span><br><span class="line">classes=<span class="string">&#x27;whatever&#x27;</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(base+<span class="string">&quot;coco.names&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">     classes=[line.strip() <span class="keyword">for</span> line <span class="keyword">in</span> f]</span><br><span class="line"><span class="comment"># print(classes)</span></span><br><span class="line"></span><br><span class="line">layer_names = yolo_net.getLayerNames()</span><br><span class="line">output_layers = [layer_names[i[<span class="number">0</span>] - <span class="number">1</span>] <span class="keyword">for</span> i <span class="keyword">in</span> yolo_net.getUnconnectedOutLayers()]</span><br><span class="line">colors = np.random.uniform(<span class="number">0</span>, <span class="number">255</span>, size=(<span class="built_in">len</span>(classes), <span class="number">3</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#load image</span></span><br><span class="line">img=cv2.imread(base+<span class="string">&quot;2.jpg&quot;</span>)</span><br><span class="line"><span class="comment"># img=cv2.resize(img,None,fx=0.4,fy=0.4)</span></span><br><span class="line">img_height, img_width, channel=img.shape</span><br><span class="line">cv2.imshow(<span class="string">&quot;original&quot;</span>,img)</span><br><span class="line">blob=cv2.dnn.blobFromImage(img,<span class="number">0.00392</span>,(<span class="number">416</span>,<span class="number">416</span>),(<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>),<span class="literal">True</span>,crop=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># blob=blob.astype(np.uint8) this is for image show, if needed.</span></span><br><span class="line">yolo_net.setInput(blob)</span><br><span class="line">outs=yolo_net.forward(output_layers)</span><br><span class="line"><span class="comment">#except for confidence, what else does yolo output contain?</span></span><br><span class="line"><span class="comment">#for detection down below, detection[0] is centroid_x ratio, detection[1] is centroid_y ratio</span></span><br><span class="line"><span class="comment">#detection[2] is width ratio, detection[3] is height ratio.</span></span><br><span class="line"></span><br><span class="line">confidences=[]</span><br><span class="line">boxes=[]</span><br><span class="line">pred_indeces=[]</span><br><span class="line"><span class="comment">#show info on pic</span></span><br><span class="line"><span class="keyword">for</span> out <span class="keyword">in</span> outs:</span><br><span class="line">    <span class="keyword">for</span> detection <span class="keyword">in</span> out:</span><br><span class="line">        <span class="comment">#why after 5</span></span><br><span class="line">        scores=detection[<span class="number">5</span>:]</span><br><span class="line">        pred_index=np.argmax(scores)</span><br><span class="line">        confidence=scores[pred_index]</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> confidence &gt; <span class="number">0.5</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;there is one!&quot;</span>)</span><br><span class="line">            </span><br><span class="line">            center_x=<span class="built_in">int</span>(detection[<span class="number">0</span>] * img_width)</span><br><span class="line">            center_y=<span class="built_in">int</span>(detection[<span class="number">1</span>] * img_height)</span><br><span class="line">            rec_width= <span class="built_in">int</span>(detection[<span class="number">2</span>] * img_width)</span><br><span class="line">            rec_height= <span class="built_in">int</span>(detection[<span class="number">3</span>] * img_height)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># cv2.circle(img,(center_x,center_y),10,(0,0,255),2)</span></span><br><span class="line"></span><br><span class="line">            <span class="comment">#rectangle coordinates beginning at left top side.</span></span><br><span class="line">            left_top_x=<span class="built_in">int</span>(center_x - rec_width / <span class="number">2</span>)</span><br><span class="line">            left_top_y=<span class="built_in">int</span>(center_y - rec_height / <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">            boxes.append([left_top_x, left_top_y, rec_width, rec_height])</span><br><span class="line">            pred_indeces.append(pred_index)</span><br><span class="line">            confidences.append(<span class="built_in">float</span>(confidence))</span><br><span class="line">            <span class="comment"># cv2.rectangle(img,(x,y),(x+w,y+h),(0,0,255),2)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#NMSBoxes recieves only float type data, otherwise it returns nothing.</span></span><br><span class="line">indexes = cv2.dnn.NMSBoxes(boxes, confidences, <span class="number">0.5</span>, <span class="number">0.4</span>)</span><br><span class="line"></span><br><span class="line">font=cv2.FONT_HERSHEY_PLAIN</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(boxes)):</span><br><span class="line">    <span class="keyword">if</span> i <span class="keyword">in</span> indexes:</span><br><span class="line">        left_top_x, left_top_y, rec_width, rec_height=boxes[i]</span><br><span class="line">        label=classes[pred_indeces[i]]</span><br><span class="line">        color=colors[i]</span><br><span class="line">        cv2.rectangle(img, (left_top_x, left_top_y), (left_top_x + rec_width, left_top_y + rec_height), color, <span class="number">2</span>)</span><br><span class="line">        cv2.putText(img, label, (left_top_x, left_top_y + <span class="number">30</span>), font, <span class="number">1</span>, color, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">cv2.imshow(<span class="string">&quot;detection&quot;</span>,img)</span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br><span class="line">cv2.destroyAllWindows()</span><br><span class="line"></span><br><span class="line">exit()</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
